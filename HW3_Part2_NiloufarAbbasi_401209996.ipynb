{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# **Niloufar Abbasi | 401209996**\n",
        "# **Deep Learning | Homework 3 | Part 2**\n",
        "\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "AZ0iMLOZ6Rfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ÿß€åŸÜ ÿ™ŸÖÿ±€åŸÜ ÿ¥ÿßŸÖŸÑ ÿØŸà ÿ®ÿÆÿ¥ ŸÖ€å ÿ®ÿßÿ¥ÿØ. ŸáÿØŸÅ ÿ™ŸÖÿ±€åŸÜ ÿ¥ŸÜÿßÿÆÿ™ ⁄©ÿßŸÜŸàŸàŸÑŸàÿ¥ŸÜ ÿØ⁄Øÿ±ÿØ€åÿ≥ Ÿæÿ∞€åÿ± €åÿß ÿØŸÅÿ±ŸÖÿ®ŸÑ ÿßÿ≥ÿ™**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f6dfoXvQ6vWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "# **ÿ≥ŸàÿßŸÑÿßÿ™ ÿ™ÿ¶Ÿàÿ±€å ‚¨õ**\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "dTvAgF7p756a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for answering these 4 questions I read this paper below and I get some help from that :            \n",
        "\n",
        "      title={Deformable Convolutional Networks},\n",
        "      author={Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},\n",
        "      year={2017},\n",
        "      archivePrefix={arXiv}\n"
      ],
      "metadata": {
        "id": "6aZjvyfgbsUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "d5qARPbQLBed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OJXUHg6ZLIcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question A:**\n",
        "\n",
        "Compare the difference between normal convolutional networks and Deformable convolutional networks in terms of Grid Sampling"
      ],
      "metadata": {
        "id": "0nO_AKrhQOVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Answer:***\n",
        "\n",
        "in standard convulution , the sampling locations are fixed on a regular grid. he receptive field is rigid andd it can't adapt to the input features. this means that the network applies the same filters to all parts of the image, regardless of the content . this can limit the model‚Äôs ability to handle complex patterns and variations in the data. in deformable convolution, the sampling locations aren't fixed and can be learned from the data. this is achieved by adding 2D offset values to the regular grid sampling locations. this enables free form deformation of the sampling grid. the offsets are learned during the training process, allowing the model to adapt its receptive field to the input features . this makes the model more flexible and capable of handling complex patterns and variations in the data .\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "gZ0L_ytsRADh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question B:**\n",
        "\n",
        "how Deformable Grids create flexibility in geometric transformation in iimages?\n",
        "\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "deformable grids create flexibility in geometric transformations by allowing the network to adjust the grid sampling locations based on the content of the image. this iss achieved by predicting location offsets of vertices of a 2-dimensional grid, such that the edges of the deformed grid align with image boundaries. This allows the network to better align with the high-frequency image content, providing a more effective representation strategy. This is conceptually akin to superpixels but conforming to a regular topology with geometric constraints thus still easily amenable for use with deep convolutional networks for downstream tasks  .\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "_qxseJQFUE2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question C:**\n",
        "\n",
        "In your opinion, why do simple convolutional networks have serious problems when dealing with images where the image objects have a lot of spatial change or rotation ?"
      ],
      "metadata": {
        "id": "97_4-clDVVav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "I think there are several reasons. I am going to points out 3 of them in subsequent lines:\n",
        "\n",
        "\n",
        "\n",
        "*   **Lack of Scale Invariance**\n",
        "\n",
        "    The filters are not scale invariant, but it is highly likely that your CNN has learned a set of filters that fire when patterns exist at varying scales. If an object in an image is scaled in a way that the network hasn‚Äôt seen during training, it may fail to recognize the object.\n",
        "\n",
        "*   **Lack of Rotation Invariance**\n",
        "\n",
        "    individual fiilters in a CNN are not invariant to changes in how an image is rotated. CNN is not truly rotation invariant. This means that if an object in an image is rotated in a way that the network hasn‚Äôt seen during training, it may fail to recognize the object2.\n",
        "\n",
        "    \n",
        "\n",
        "*   **Good at Translation Invariance** but ...üòñ (how about corners of the images)\n",
        "\n",
        "    While CNNs excel at translation invariance due to the sliding window operation of the convolution, I think extreme translations or displacements (specially to the corners) might still pose a challenge\n",
        "\n",
        "\n",
        "\n",
        "at the end, while CNNs can learn to recognize patterns at different orientations and scales, they are not inherently invariant to these transformations. This can lead to difficulties . To overcome these challenges, techniques such as data augmentation and the use of more advanced architectures like Deformable Convolutional Networks can be employed.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "uBByLzsRVtY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question D:**\n",
        "\n",
        "How are the offsets in Deformable Convolution calculated?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "In Deformable Convolution, the offsets are calculated by adding 2D offsets to the regular grid sampling locations in the standard convolution. These offsets allow for free-form deformation of the sampling grid.\n",
        "\n",
        "The offsets are learned from the preceding feature maps via additional convolutional layers. This means that the deformation is conditioned on the input features in a local, dense, and adaptive manner. In other words, the network learns where to best sample the input based on the data it has seen before.\n",
        "\n",
        "Instead of predicting the raw offset (in pixels), the offsets are normalized by the width and height of the Region of Interest (RoI) to make them invariant to RoI size. This approach allows the network to adapt to the specific content of the input image, providing a more flexible and powerful model for handling complex geometric transformations.\n",
        "\n",
        "To illustrate this with a formula, let's denote the input feature map as $x$ and the output feature map as $y$. For each location $p_0$ in the output feature map $y$, the corresponding input feature locations are denoted as $p_n = p_0 + p_n^t$, where $p_n^t$ is the offset and $n$ is the index of the location in the convolution kernel.\n",
        "\n",
        "The output feature $y(p_0)$ is then calculated as a weighted sum of the input features $x(p_n)$ and the weights $w_n$ of the convolution kernel:\n",
        "\n",
        "$$y(p_0) = \\sum_{n} w_n \\cdot x(p_n)$$\n",
        "\n",
        "This formula shows how the offsets $p_n^t$ are used to calculate the output feature map $y$. The offsets are learned from the preceding feature maps, allowing the network to adapt to the specific content of the input image. This makes Deformable Convolution a powerful tool for handling complex geometric transformations."
      ],
      "metadata": {
        "id": "BP6S8t_1ZcU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "# **(From Scratch) Ÿæ€åÿßÿØŸá ÿ≥ÿßÿ≤€å ÿ¥ÿ®⁄©Ÿá ⁄©ÿßŸÜŸàŸÑŸàÿ¥ŸÜ€å‚¨õ**\n",
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "XqeV9VoW8V57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries:\n",
        "\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim         as optim\n",
        "from   torch.autograd      import Variable\n",
        "from   torchvision         import datasets, transforms"
      ],
      "metadata": {
        "id": "8ss9nSf-L_UU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the CIFAR-10 dataset among the options. The reason for my choice was that the MNIST dataset is overly simplistic, and naturally, the distinction between these two networks was not very apparent. (This is because MNIST images are in greyscale, and very easy, while CIFAR-10 images have three channels, adding a certain level of complexity.)"
      ],
      "metadata": {
        "id": "taaKwaMMFmna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])), batch_size=16, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PaiZnNTTFqE",
        "outputId": "e384665b-73d6-42f1-c1cb-91fdcb5cece6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170498071/170498071 [00:03<00:00, 42895527.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the specific case of CIFAR-10, the values (0.4914, 0.4822, 0.4465) represent the mean values for each channel (red, green, and blue), and (0.2023, 0.1994, 0.2010) represent the standard deviation values for each channel."
      ],
      "metadata": {
        "id": "pomp_OdPTdgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#----------------------------------------------------------------------\n",
        "def print_device(x):\n",
        "    if x.type == 'cpu':\n",
        "        return 'CPU'\n",
        "    else:\n",
        "        return 'GPU'\n",
        "#---------------------------------------------------------------------\n",
        "print('Device: {}'.format(print_device(device)))\n",
        "#---------------------------------------------------------------------\n",
        "DEVICE = device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfm-O7iLTxEN",
        "outputId": "328e5ca8-9fa8-4639-9fce-c7bd2850853c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter\n",
        "EPOCHS = 15"
      ],
      "metadata": {
        "id": "2-mXKqbVlhs5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeformableConv(nn.Module):\n",
        "\n",
        "    def __init__(self, inc, out_c, kernel_size=3, padding=1, bias=None):\n",
        "        \"\"\"\n",
        "        Custom Deformable Convolutional Layer Constructor.\n",
        "        Args:\n",
        "            inc         (int): Number of input channels\n",
        "            out_c       (int): Number of output channels\n",
        "            kernel_size (int): Size of the convolutional kernel. Default is 3\n",
        "            padding     (int): Amount of zero padding. Default is 1\n",
        "            bias       (bool): Whether to include bias in the convolutional layer. Default is None\n",
        "        \"\"\"\n",
        "        super(DeformableConv, self).__init__()\n",
        "        self.kernel_size  = kernel_size\n",
        "        self.padding      = padding\n",
        "        self.zero_padding = nn.ZeroPad2d(padding)\n",
        "        self.conv_kernel  = nn.Conv2d(inc, out_c, kernel_size=kernel_size, stride=kernel_size, bias=bias)\n",
        "    #-------------------------------------------------------------------------------\n",
        "    def forward(self, x, offset):\n",
        "        \"\"\"\n",
        "        Forward pass of the Deformable Convolutional Layer.\n",
        "        Args:\n",
        "            x (torch.Tensor)     : Input tensor.\n",
        "            offset (torch.Tensor): Offset tensor.\n",
        "        Returns:\n",
        "            torch.Tensor         : Output tensor\n",
        "        \"\"\"\n",
        "\n",
        "        data_type         = offset.data.type()\n",
        "        kernel_size       = self.kernel_size\n",
        "        n                 = offset.size(1) // 2\n",
        "\n",
        "        # Extract necessary indices from the offset tensor\n",
        "        offset_index = Variable(torch.cat([torch.arange(0, 2 * n, 2),torch.arange(1, 2 * n + 1, 2)]), requires_grad=False).type_as(x).long()\n",
        "        offset_index = offset_index.unsqueeze(dim=0).unsqueeze(dim=-1).unsqueeze(dim=-1).expand(*offset.size())\n",
        "        offset       = torch.gather(offset, dim=1, index=offset_index)\n",
        "\n",
        "        # Zero padding if required\n",
        "        if self.padding:\n",
        "            x = self.zero_padding(x)\n",
        "\n",
        "        # Calculate indices for the interpolation\n",
        "        p = self.get_p(offset, data_type)\n",
        "        p = p.contiguous().permute(0, 2, 3, 1)\n",
        "\n",
        "        # Compute the bounding box coordinates\n",
        "        q_lt = Variable(p.data, requires_grad=False).floor()\n",
        "        q_rb = q_lt + 1\n",
        "\n",
        "        # Clamp the bounding box coordinates to the valid range\n",
        "        q_lt = torch.cat([torch.clamp(q_lt[..., :n], 0, x.size(2) - 1), torch.clamp(q_lt[..., n:], 0, x.size(3) - 1)], dim=-1).long()\n",
        "        q_rb = torch.cat([torch.clamp(q_rb[..., :n], 0, x.size(2) - 1), torch.clamp(q_rb[..., n:], 0, x.size(3) - 1)], dim=-1).long()\n",
        "        q_lb = torch.cat([q_lt[..., :n], q_rb[..., n:]], -1)\n",
        "        q_rt = torch.cat([q_rb[..., :n], q_lt[..., n:]], -1)\n",
        "\n",
        "        # Create a mask to handle boundary cases\n",
        "        mask = torch.cat([p[..., :n].lt(self.padding) + p[..., :n].gt(x.size(2) - 1 - self.padding),\n",
        "                          p[..., n:].lt(self.padding) + p[..., n:].gt(x.size(3) - 1 - self.padding)], dim=-1).type_as(p)\n",
        "\n",
        "        mask = mask.detach()\n",
        "        floor_p = p - (p - torch.floor(p))\n",
        "        p       = p * (1 - mask) + floor_p * mask\n",
        "        p       = torch.cat([torch.clamp(p[..., :n], 0, x.size(2) - 1), torch.clamp(p[..., n:], 0, x.size(3) - 1)], dim=-1)\n",
        "\n",
        "        # Compute interpolation weights\n",
        "        g_lt = (1 + (q_lt[..., :n].type_as(p) - p[..., :n])) * (1 + (q_lt[..., n:].type_as(p) - p[..., n:]))\n",
        "        g_rb = (1 - (q_rb[..., :n].type_as(p) - p[..., :n])) * (1 - (q_rb[..., n:].type_as(p) - p[..., n:]))\n",
        "        g_lb = (1 + (q_lb[..., :n].type_as(p) - p[..., :n])) * (1 - (q_lb[..., n:].type_as(p) - p[..., n:]))\n",
        "        g_rt = (1 - (q_rt[..., :n].type_as(p) - p[..., :n])) * (1 + (q_rt[..., n:].type_as(p) - p[..., n:]))\n",
        "\n",
        "        # Get the interpolated values based on the computed indices\n",
        "        x_q_lt = self.get_xq(x, q_lt, n)\n",
        "        x_q_rb = self.get_xq(x, q_rb, n)\n",
        "        x_q_lb = self.get_xq(x, q_lb, n)\n",
        "        x_q_rt = self.get_xq(x, q_rt, n)\n",
        "\n",
        "        # Compute the deformed offset using the interpolation weights\n",
        "        x_offset = (g_lt.unsqueeze(dim=1) * x_q_lt) + (g_rb.unsqueeze(dim=1) * x_q_rb) + (g_lb.unsqueeze(dim=1) * x_q_lb) + (g_rt.unsqueeze(dim=1) * x_q_rt)\n",
        "\n",
        "        # Reshape the offset for convolutional operation\n",
        "        x_offset = self.reshape_the_offset(x_offset, kernel_size)\n",
        "\n",
        "        # Perform the convolution with the deformed offset\n",
        "        out_x    = self.conv_kernel(x_offset)\n",
        "\n",
        "        return out_x\n",
        "    #-------------------------------------------------------------------------------\n",
        "    def get_pn(self, n, data_type):\n",
        "        \"\"\"\n",
        "        Get the grid of spatial coordinates for interpolation.\n",
        "        Args:\n",
        "             n (int)                : Number of channels in the offset tensor.\n",
        "             data_type (torch.dtype): Data type for the resulting tensor.\n",
        "\n",
        "        Returns:\n",
        "             torch.Tensor           : Grid of spatial coordinates for interpolation.\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate a meshgrid of spatial coordinates\n",
        "        p_n_x, p_n_y = np.meshgrid(range(-(self.kernel_size - 1) // 2, (self.kernel_size - 1) // 2 + 1),\n",
        "                                   range(-(self.kernel_size - 1) // 2, (self.kernel_size - 1) // 2 + 1),\n",
        "                                   indexing='ij')\n",
        "\n",
        "        # Flatten and concatenate the coordinates\n",
        "        p_n = np.concatenate((p_n_x.flatten(), p_n_y.flatten()))  # (2n, 1)\n",
        "        # eeshape to the required format\n",
        "        p_n = np.reshape(p_n, (1, 2 * n, 1, 1))\n",
        "        #convert to a PyTorch variable with the specified data type\n",
        "        p_n = Variable(torch.from_numpy(p_n).type(data_type), requires_grad=False)\n",
        "        return p_n\n",
        "    #-------------------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def get_p0(h, w, n, data_type):\n",
        "        \"\"\"\n",
        "        Get the initial grid of spatial coordinates.\n",
        "        Args:\n",
        "            h (int): Height of the spatial grid.\n",
        "            w (int): Width of the spatial grid.\n",
        "            n (int): Number of channels in the offset tensor.\n",
        "            data_type (torch.dtype): Data type for the resulting tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Initial grid of spatial coordinates.\n",
        "        \"\"\"\n",
        "        p0_x, p0_y = np.meshgrid(range(1, h + 1), range(1, w + 1), indexing='ij')\n",
        "        p0_x = p0_x.flatten().reshape(1, 1, h, w).repeat(n, axis=1)\n",
        "        p0_y = p0_y.flatten().reshape(1, 1, h, w).repeat(n, axis=1)\n",
        "        p_0  = np.concatenate((p0_x, p0_y), axis=1)\n",
        "        p_0  = Variable(torch.from_numpy(p_0).type(data_type), requires_grad=False)\n",
        "        return p_0\n",
        "    #---------------------------------------------------------------------------\n",
        "    def get_p(self, offset, data_type):\n",
        "        n, h, w = offset.size(1) // 2, offset.size(2), offset.size(3)\n",
        "        p_n     = self.get_pn(n, data_type)        # (1, 2n, 1, 1)\n",
        "        p_0     = self.get_p0(h, w, n, data_type)  # (1, 2n, h, w)\n",
        "        p       = p_0 + p_n + offset\n",
        "        return p\n",
        "    #---------------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def get_xq(x, q, n):\n",
        "        b, h, w, _ = q.size()\n",
        "        padded_w   = x.size(3)\n",
        "        c          = x.size(1)\n",
        "        x          = x.contiguous().view(b, c, -1)  # (b, c, h*w)\n",
        "\n",
        "        # (b, h, w, n)\n",
        "        index = q[..., :n] * padded_w + q[..., n:]  # offset_x*w + offset_y\n",
        "        # (b, c, h*w*n)\n",
        "        index = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\n",
        "\n",
        "        x_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, n)\n",
        "\n",
        "        return x_offset\n",
        "    #---------------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def reshape_the_offset(x_offset, kernel_size):\n",
        "        b, c, h, w, n = x_offset.size()\n",
        "        x_offset = torch.cat([x_offset[..., s:s + kernel_size].contiguous().view(b, c, h, w * kernel_size) for s in\n",
        "                              range(0, n, kernel_size)],\n",
        "                             dim=-1)\n",
        "        x_offset = x_offset.contiguous().view(b, c, h * kernel_size, w * kernel_size)\n",
        "\n",
        "        return x_offset\n",
        "\n",
        "#=========================================================================================================================\n",
        "\n",
        "class DCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DCN, self).__init__()\n",
        "        self.conv1      = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1        = nn.BatchNorm2d(32)\n",
        "        self.conv2      = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2        = nn.BatchNorm2d(64)\n",
        "        self.offset1    = nn.Conv2d(64, 18, kernel_size=3, padding=1)\n",
        "        self.conv3      = DeformableConv(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3        = nn.BatchNorm2d(128)\n",
        "        self.offset2    = nn.Conv2d(128, 18, kernel_size=3, padding=1)\n",
        "        self.conv4      = DeformableConv(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn4        = nn.BatchNorm2d(128)\n",
        "        self.pool       = nn.AdaptiveAvgPool2d((1, 1))  # Add this line\n",
        "        self.classifier = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.conv3(x, self.offset1(x)))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.conv4(x, self.offset2(x)))\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "model     = DCN().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "total_training_time = 0.0  # Initialize total training time\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    global total_training_time  # Use the global variable\n",
        "    model.train()\n",
        "    start_time = time.time()  # Record the start time\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output       = model(data)\n",
        "        loss         = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 30 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "    end_time = time.time()  # Record the end time\n",
        "    elapsed_time = end_time - start_time\n",
        "    total_training_time += elapsed_time  # Update total training time\n",
        "    print('---------------------------------------')\n",
        "    print(f\"Training time for epoch {epoch}: {elapsed_time:.2f} seconds\")\n",
        "    print('---------------------------------------')\n",
        "\n",
        "\n",
        "DCNN_ACC= []\n",
        "\n",
        "def test(model, device, test_loader, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct   = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output       = model(data)\n",
        "            test_loss   += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred         = output.max(1, keepdim=True)[1]\n",
        "            correct     += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('-------------------------------------------------------')\n",
        "    print('\\nTest set (epoch{}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        epoch, test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "    print('-------------------------------------------------------')\n",
        "\n",
        "    DCNN_ACC.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
        "    test(model, DEVICE, test_loader, epoch)\n",
        "\n",
        "print('============================================')\n",
        "print(f\"Total training time for {EPOCHS} epochs: {total_training_time:.2f} seconds\")\n",
        "print('============================================')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkMvh9cbc8pc",
        "outputId": "9df8d426-4c45-4f14-9dc4-f4ab32539700"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [464/50000 (1%)]\tLoss: 2.222517\n",
            "Train Epoch: 1 [944/50000 (2%)]\tLoss: 1.880545\n",
            "Train Epoch: 1 [1424/50000 (3%)]\tLoss: 1.995821\n",
            "Train Epoch: 1 [1904/50000 (4%)]\tLoss: 1.962782\n",
            "Train Epoch: 1 [2384/50000 (5%)]\tLoss: 1.984912\n",
            "Train Epoch: 1 [2864/50000 (6%)]\tLoss: 1.892387\n",
            "Train Epoch: 1 [3344/50000 (7%)]\tLoss: 1.603630\n",
            "Train Epoch: 1 [3824/50000 (8%)]\tLoss: 1.794303\n",
            "Train Epoch: 1 [4304/50000 (9%)]\tLoss: 1.529336\n",
            "Train Epoch: 1 [4784/50000 (10%)]\tLoss: 1.857877\n",
            "Train Epoch: 1 [5264/50000 (11%)]\tLoss: 1.822172\n",
            "Train Epoch: 1 [5744/50000 (11%)]\tLoss: 1.672806\n",
            "Train Epoch: 1 [6224/50000 (12%)]\tLoss: 1.720643\n",
            "Train Epoch: 1 [6704/50000 (13%)]\tLoss: 1.899622\n",
            "Train Epoch: 1 [7184/50000 (14%)]\tLoss: 1.489749\n",
            "Train Epoch: 1 [7664/50000 (15%)]\tLoss: 2.047864\n",
            "Train Epoch: 1 [8144/50000 (16%)]\tLoss: 1.968067\n",
            "Train Epoch: 1 [8624/50000 (17%)]\tLoss: 1.728338\n",
            "Train Epoch: 1 [9104/50000 (18%)]\tLoss: 1.671801\n",
            "Train Epoch: 1 [9584/50000 (19%)]\tLoss: 1.752852\n",
            "Train Epoch: 1 [10064/50000 (20%)]\tLoss: 1.977562\n",
            "Train Epoch: 1 [10544/50000 (21%)]\tLoss: 1.938534\n",
            "Train Epoch: 1 [11024/50000 (22%)]\tLoss: 1.793046\n",
            "Train Epoch: 1 [11504/50000 (23%)]\tLoss: 1.830495\n",
            "Train Epoch: 1 [11984/50000 (24%)]\tLoss: 1.598808\n",
            "Train Epoch: 1 [12464/50000 (25%)]\tLoss: 1.834575\n",
            "Train Epoch: 1 [12944/50000 (26%)]\tLoss: 1.810437\n",
            "Train Epoch: 1 [13424/50000 (27%)]\tLoss: 1.491645\n",
            "Train Epoch: 1 [13904/50000 (28%)]\tLoss: 1.451017\n",
            "Train Epoch: 1 [14384/50000 (29%)]\tLoss: 1.876426\n",
            "Train Epoch: 1 [14864/50000 (30%)]\tLoss: 1.672733\n",
            "Train Epoch: 1 [15344/50000 (31%)]\tLoss: 1.223894\n",
            "Train Epoch: 1 [15824/50000 (32%)]\tLoss: 1.301220\n",
            "Train Epoch: 1 [16304/50000 (33%)]\tLoss: 1.340942\n",
            "Train Epoch: 1 [16784/50000 (34%)]\tLoss: 1.691969\n",
            "Train Epoch: 1 [17264/50000 (35%)]\tLoss: 1.397697\n",
            "Train Epoch: 1 [17744/50000 (35%)]\tLoss: 1.851023\n",
            "Train Epoch: 1 [18224/50000 (36%)]\tLoss: 1.514876\n",
            "Train Epoch: 1 [18704/50000 (37%)]\tLoss: 1.571841\n",
            "Train Epoch: 1 [19184/50000 (38%)]\tLoss: 1.829427\n",
            "Train Epoch: 1 [19664/50000 (39%)]\tLoss: 1.583352\n",
            "Train Epoch: 1 [20144/50000 (40%)]\tLoss: 1.661330\n",
            "Train Epoch: 1 [20624/50000 (41%)]\tLoss: 1.473823\n",
            "Train Epoch: 1 [21104/50000 (42%)]\tLoss: 1.552044\n",
            "Train Epoch: 1 [21584/50000 (43%)]\tLoss: 1.392158\n",
            "Train Epoch: 1 [22064/50000 (44%)]\tLoss: 1.245695\n",
            "Train Epoch: 1 [22544/50000 (45%)]\tLoss: 1.639032\n",
            "Train Epoch: 1 [23024/50000 (46%)]\tLoss: 1.523428\n",
            "Train Epoch: 1 [23504/50000 (47%)]\tLoss: 1.855212\n",
            "Train Epoch: 1 [23984/50000 (48%)]\tLoss: 1.471230\n",
            "Train Epoch: 1 [24464/50000 (49%)]\tLoss: 1.763169\n",
            "Train Epoch: 1 [24944/50000 (50%)]\tLoss: 1.158466\n",
            "Train Epoch: 1 [25424/50000 (51%)]\tLoss: 1.501615\n",
            "Train Epoch: 1 [25904/50000 (52%)]\tLoss: 1.507689\n",
            "Train Epoch: 1 [26384/50000 (53%)]\tLoss: 1.151633\n",
            "Train Epoch: 1 [26864/50000 (54%)]\tLoss: 1.320769\n",
            "Train Epoch: 1 [27344/50000 (55%)]\tLoss: 1.705096\n",
            "Train Epoch: 1 [27824/50000 (56%)]\tLoss: 1.581457\n",
            "Train Epoch: 1 [28304/50000 (57%)]\tLoss: 2.054372\n",
            "Train Epoch: 1 [28784/50000 (58%)]\tLoss: 1.443069\n",
            "Train Epoch: 1 [29264/50000 (59%)]\tLoss: 1.581727\n",
            "Train Epoch: 1 [29744/50000 (59%)]\tLoss: 1.376668\n",
            "Train Epoch: 1 [30224/50000 (60%)]\tLoss: 1.838722\n",
            "Train Epoch: 1 [30704/50000 (61%)]\tLoss: 1.138305\n",
            "Train Epoch: 1 [31184/50000 (62%)]\tLoss: 1.325643\n",
            "Train Epoch: 1 [31664/50000 (63%)]\tLoss: 1.306317\n",
            "Train Epoch: 1 [32144/50000 (64%)]\tLoss: 1.674620\n",
            "Train Epoch: 1 [32624/50000 (65%)]\tLoss: 1.262280\n",
            "Train Epoch: 1 [33104/50000 (66%)]\tLoss: 1.295087\n",
            "Train Epoch: 1 [33584/50000 (67%)]\tLoss: 1.539359\n",
            "Train Epoch: 1 [34064/50000 (68%)]\tLoss: 1.105600\n",
            "Train Epoch: 1 [34544/50000 (69%)]\tLoss: 0.868942\n",
            "Train Epoch: 1 [35024/50000 (70%)]\tLoss: 1.526238\n",
            "Train Epoch: 1 [35504/50000 (71%)]\tLoss: 1.531953\n",
            "Train Epoch: 1 [35984/50000 (72%)]\tLoss: 1.120653\n",
            "Train Epoch: 1 [36464/50000 (73%)]\tLoss: 1.437023\n",
            "Train Epoch: 1 [36944/50000 (74%)]\tLoss: 1.542618\n",
            "Train Epoch: 1 [37424/50000 (75%)]\tLoss: 1.572366\n",
            "Train Epoch: 1 [37904/50000 (76%)]\tLoss: 1.421858\n",
            "Train Epoch: 1 [38384/50000 (77%)]\tLoss: 0.922369\n",
            "Train Epoch: 1 [38864/50000 (78%)]\tLoss: 1.123622\n",
            "Train Epoch: 1 [39344/50000 (79%)]\tLoss: 1.614952\n",
            "Train Epoch: 1 [39824/50000 (80%)]\tLoss: 1.153038\n",
            "Train Epoch: 1 [40304/50000 (81%)]\tLoss: 1.397751\n",
            "Train Epoch: 1 [40784/50000 (82%)]\tLoss: 1.346461\n",
            "Train Epoch: 1 [41264/50000 (83%)]\tLoss: 1.236499\n",
            "Train Epoch: 1 [41744/50000 (83%)]\tLoss: 1.276483\n",
            "Train Epoch: 1 [42224/50000 (84%)]\tLoss: 1.544696\n",
            "Train Epoch: 1 [42704/50000 (85%)]\tLoss: 1.234294\n",
            "Train Epoch: 1 [43184/50000 (86%)]\tLoss: 1.199400\n",
            "Train Epoch: 1 [43664/50000 (87%)]\tLoss: 1.983068\n",
            "Train Epoch: 1 [44144/50000 (88%)]\tLoss: 1.643275\n",
            "Train Epoch: 1 [44624/50000 (89%)]\tLoss: 1.282514\n",
            "Train Epoch: 1 [45104/50000 (90%)]\tLoss: 1.196795\n",
            "Train Epoch: 1 [45584/50000 (91%)]\tLoss: 1.853997\n",
            "Train Epoch: 1 [46064/50000 (92%)]\tLoss: 1.880754\n",
            "Train Epoch: 1 [46544/50000 (93%)]\tLoss: 1.412611\n",
            "Train Epoch: 1 [47024/50000 (94%)]\tLoss: 1.106789\n",
            "Train Epoch: 1 [47504/50000 (95%)]\tLoss: 1.912407\n",
            "Train Epoch: 1 [47984/50000 (96%)]\tLoss: 1.318066\n",
            "Train Epoch: 1 [48464/50000 (97%)]\tLoss: 1.075080\n",
            "Train Epoch: 1 [48944/50000 (98%)]\tLoss: 1.677400\n",
            "Train Epoch: 1 [49424/50000 (99%)]\tLoss: 1.391891\n",
            "Train Epoch: 1 [49904/50000 (100%)]\tLoss: 1.103876\n",
            "---------------------------------------\n",
            "Training time for epoch 1: 205.38 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch1): Average loss: 1.1926, Accuracy: 5819/10000 (58%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 2 [464/50000 (1%)]\tLoss: 1.505761\n",
            "Train Epoch: 2 [944/50000 (2%)]\tLoss: 1.493994\n",
            "Train Epoch: 2 [1424/50000 (3%)]\tLoss: 1.061632\n",
            "Train Epoch: 2 [1904/50000 (4%)]\tLoss: 1.607140\n",
            "Train Epoch: 2 [2384/50000 (5%)]\tLoss: 1.481148\n",
            "Train Epoch: 2 [2864/50000 (6%)]\tLoss: 1.485301\n",
            "Train Epoch: 2 [3344/50000 (7%)]\tLoss: 1.006037\n",
            "Train Epoch: 2 [3824/50000 (8%)]\tLoss: 1.333585\n",
            "Train Epoch: 2 [4304/50000 (9%)]\tLoss: 0.866538\n",
            "Train Epoch: 2 [4784/50000 (10%)]\tLoss: 1.408255\n",
            "Train Epoch: 2 [5264/50000 (11%)]\tLoss: 1.546429\n",
            "Train Epoch: 2 [5744/50000 (11%)]\tLoss: 1.130923\n",
            "Train Epoch: 2 [6224/50000 (12%)]\tLoss: 1.530319\n",
            "Train Epoch: 2 [6704/50000 (13%)]\tLoss: 1.267918\n",
            "Train Epoch: 2 [7184/50000 (14%)]\tLoss: 1.180902\n",
            "Train Epoch: 2 [7664/50000 (15%)]\tLoss: 1.347101\n",
            "Train Epoch: 2 [8144/50000 (16%)]\tLoss: 1.318432\n",
            "Train Epoch: 2 [8624/50000 (17%)]\tLoss: 1.106662\n",
            "Train Epoch: 2 [9104/50000 (18%)]\tLoss: 1.656295\n",
            "Train Epoch: 2 [9584/50000 (19%)]\tLoss: 1.139285\n",
            "Train Epoch: 2 [10064/50000 (20%)]\tLoss: 1.162779\n",
            "Train Epoch: 2 [10544/50000 (21%)]\tLoss: 1.278513\n",
            "Train Epoch: 2 [11024/50000 (22%)]\tLoss: 0.974572\n",
            "Train Epoch: 2 [11504/50000 (23%)]\tLoss: 1.288599\n",
            "Train Epoch: 2 [11984/50000 (24%)]\tLoss: 1.265213\n",
            "Train Epoch: 2 [12464/50000 (25%)]\tLoss: 1.239731\n",
            "Train Epoch: 2 [12944/50000 (26%)]\tLoss: 1.436927\n",
            "Train Epoch: 2 [13424/50000 (27%)]\tLoss: 1.165180\n",
            "Train Epoch: 2 [13904/50000 (28%)]\tLoss: 1.515014\n",
            "Train Epoch: 2 [14384/50000 (29%)]\tLoss: 0.964134\n",
            "Train Epoch: 2 [14864/50000 (30%)]\tLoss: 1.289202\n",
            "Train Epoch: 2 [15344/50000 (31%)]\tLoss: 1.105547\n",
            "Train Epoch: 2 [15824/50000 (32%)]\tLoss: 1.175693\n",
            "Train Epoch: 2 [16304/50000 (33%)]\tLoss: 1.460108\n",
            "Train Epoch: 2 [16784/50000 (34%)]\tLoss: 1.214683\n",
            "Train Epoch: 2 [17264/50000 (35%)]\tLoss: 1.393033\n",
            "Train Epoch: 2 [17744/50000 (35%)]\tLoss: 1.245428\n",
            "Train Epoch: 2 [18224/50000 (36%)]\tLoss: 1.029692\n",
            "Train Epoch: 2 [18704/50000 (37%)]\tLoss: 1.819022\n",
            "Train Epoch: 2 [19184/50000 (38%)]\tLoss: 0.892690\n",
            "Train Epoch: 2 [19664/50000 (39%)]\tLoss: 1.141826\n",
            "Train Epoch: 2 [20144/50000 (40%)]\tLoss: 1.225490\n",
            "Train Epoch: 2 [20624/50000 (41%)]\tLoss: 1.545785\n",
            "Train Epoch: 2 [21104/50000 (42%)]\tLoss: 0.931911\n",
            "Train Epoch: 2 [21584/50000 (43%)]\tLoss: 1.642475\n",
            "Train Epoch: 2 [22064/50000 (44%)]\tLoss: 0.827974\n",
            "Train Epoch: 2 [22544/50000 (45%)]\tLoss: 1.611534\n",
            "Train Epoch: 2 [23024/50000 (46%)]\tLoss: 1.011103\n",
            "Train Epoch: 2 [23504/50000 (47%)]\tLoss: 1.135100\n",
            "Train Epoch: 2 [23984/50000 (48%)]\tLoss: 1.122005\n",
            "Train Epoch: 2 [24464/50000 (49%)]\tLoss: 0.882610\n",
            "Train Epoch: 2 [24944/50000 (50%)]\tLoss: 0.944520\n",
            "Train Epoch: 2 [25424/50000 (51%)]\tLoss: 1.520626\n",
            "Train Epoch: 2 [25904/50000 (52%)]\tLoss: 1.291047\n",
            "Train Epoch: 2 [26384/50000 (53%)]\tLoss: 1.371025\n",
            "Train Epoch: 2 [26864/50000 (54%)]\tLoss: 1.329804\n",
            "Train Epoch: 2 [27344/50000 (55%)]\tLoss: 1.064151\n",
            "Train Epoch: 2 [27824/50000 (56%)]\tLoss: 1.122032\n",
            "Train Epoch: 2 [28304/50000 (57%)]\tLoss: 1.007710\n",
            "Train Epoch: 2 [28784/50000 (58%)]\tLoss: 0.824865\n",
            "Train Epoch: 2 [29264/50000 (59%)]\tLoss: 1.241354\n",
            "Train Epoch: 2 [29744/50000 (59%)]\tLoss: 1.120212\n",
            "Train Epoch: 2 [30224/50000 (60%)]\tLoss: 1.416448\n",
            "Train Epoch: 2 [30704/50000 (61%)]\tLoss: 1.542321\n",
            "Train Epoch: 2 [31184/50000 (62%)]\tLoss: 1.421981\n",
            "Train Epoch: 2 [31664/50000 (63%)]\tLoss: 0.999254\n",
            "Train Epoch: 2 [32144/50000 (64%)]\tLoss: 1.080725\n",
            "Train Epoch: 2 [32624/50000 (65%)]\tLoss: 1.012798\n",
            "Train Epoch: 2 [33104/50000 (66%)]\tLoss: 0.857601\n",
            "Train Epoch: 2 [33584/50000 (67%)]\tLoss: 1.223182\n",
            "Train Epoch: 2 [34064/50000 (68%)]\tLoss: 1.369051\n",
            "Train Epoch: 2 [34544/50000 (69%)]\tLoss: 1.245463\n",
            "Train Epoch: 2 [35024/50000 (70%)]\tLoss: 1.364665\n",
            "Train Epoch: 2 [35504/50000 (71%)]\tLoss: 1.352867\n",
            "Train Epoch: 2 [35984/50000 (72%)]\tLoss: 1.004869\n",
            "Train Epoch: 2 [36464/50000 (73%)]\tLoss: 1.353087\n",
            "Train Epoch: 2 [36944/50000 (74%)]\tLoss: 1.092909\n",
            "Train Epoch: 2 [37424/50000 (75%)]\tLoss: 1.347204\n",
            "Train Epoch: 2 [37904/50000 (76%)]\tLoss: 0.847897\n",
            "Train Epoch: 2 [38384/50000 (77%)]\tLoss: 1.102204\n",
            "Train Epoch: 2 [38864/50000 (78%)]\tLoss: 0.705250\n",
            "Train Epoch: 2 [39344/50000 (79%)]\tLoss: 1.047257\n",
            "Train Epoch: 2 [39824/50000 (80%)]\tLoss: 1.213152\n",
            "Train Epoch: 2 [40304/50000 (81%)]\tLoss: 1.299617\n",
            "Train Epoch: 2 [40784/50000 (82%)]\tLoss: 1.079909\n",
            "Train Epoch: 2 [41264/50000 (83%)]\tLoss: 1.266890\n",
            "Train Epoch: 2 [41744/50000 (83%)]\tLoss: 1.141226\n",
            "Train Epoch: 2 [42224/50000 (84%)]\tLoss: 1.152999\n",
            "Train Epoch: 2 [42704/50000 (85%)]\tLoss: 0.819628\n",
            "Train Epoch: 2 [43184/50000 (86%)]\tLoss: 1.643559\n",
            "Train Epoch: 2 [43664/50000 (87%)]\tLoss: 1.121508\n",
            "Train Epoch: 2 [44144/50000 (88%)]\tLoss: 1.130187\n",
            "Train Epoch: 2 [44624/50000 (89%)]\tLoss: 1.253976\n",
            "Train Epoch: 2 [45104/50000 (90%)]\tLoss: 1.151253\n",
            "Train Epoch: 2 [45584/50000 (91%)]\tLoss: 0.862563\n",
            "Train Epoch: 2 [46064/50000 (92%)]\tLoss: 0.930838\n",
            "Train Epoch: 2 [46544/50000 (93%)]\tLoss: 1.170258\n",
            "Train Epoch: 2 [47024/50000 (94%)]\tLoss: 1.728504\n",
            "Train Epoch: 2 [47504/50000 (95%)]\tLoss: 1.427590\n",
            "Train Epoch: 2 [47984/50000 (96%)]\tLoss: 1.204590\n",
            "Train Epoch: 2 [48464/50000 (97%)]\tLoss: 1.218631\n",
            "Train Epoch: 2 [48944/50000 (98%)]\tLoss: 1.225347\n",
            "Train Epoch: 2 [49424/50000 (99%)]\tLoss: 1.318340\n",
            "Train Epoch: 2 [49904/50000 (100%)]\tLoss: 1.032206\n",
            "---------------------------------------\n",
            "Training time for epoch 2: 201.66 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch2): Average loss: 1.0029, Accuracy: 6448/10000 (64%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 3 [464/50000 (1%)]\tLoss: 1.146614\n",
            "Train Epoch: 3 [944/50000 (2%)]\tLoss: 0.916356\n",
            "Train Epoch: 3 [1424/50000 (3%)]\tLoss: 1.546263\n",
            "Train Epoch: 3 [1904/50000 (4%)]\tLoss: 1.342896\n",
            "Train Epoch: 3 [2384/50000 (5%)]\tLoss: 1.038352\n",
            "Train Epoch: 3 [2864/50000 (6%)]\tLoss: 0.965173\n",
            "Train Epoch: 3 [3344/50000 (7%)]\tLoss: 1.240852\n",
            "Train Epoch: 3 [3824/50000 (8%)]\tLoss: 0.911802\n",
            "Train Epoch: 3 [4304/50000 (9%)]\tLoss: 0.926537\n",
            "Train Epoch: 3 [4784/50000 (10%)]\tLoss: 1.113198\n",
            "Train Epoch: 3 [5264/50000 (11%)]\tLoss: 0.674561\n",
            "Train Epoch: 3 [5744/50000 (11%)]\tLoss: 0.994854\n",
            "Train Epoch: 3 [6224/50000 (12%)]\tLoss: 1.057590\n",
            "Train Epoch: 3 [6704/50000 (13%)]\tLoss: 0.652313\n",
            "Train Epoch: 3 [7184/50000 (14%)]\tLoss: 1.002530\n",
            "Train Epoch: 3 [7664/50000 (15%)]\tLoss: 1.469934\n",
            "Train Epoch: 3 [8144/50000 (16%)]\tLoss: 0.746684\n",
            "Train Epoch: 3 [8624/50000 (17%)]\tLoss: 0.755544\n",
            "Train Epoch: 3 [9104/50000 (18%)]\tLoss: 1.261629\n",
            "Train Epoch: 3 [9584/50000 (19%)]\tLoss: 0.624476\n",
            "Train Epoch: 3 [10064/50000 (20%)]\tLoss: 1.306089\n",
            "Train Epoch: 3 [10544/50000 (21%)]\tLoss: 1.202369\n",
            "Train Epoch: 3 [11024/50000 (22%)]\tLoss: 0.864347\n",
            "Train Epoch: 3 [11504/50000 (23%)]\tLoss: 0.997461\n",
            "Train Epoch: 3 [11984/50000 (24%)]\tLoss: 0.924288\n",
            "Train Epoch: 3 [12464/50000 (25%)]\tLoss: 1.093910\n",
            "Train Epoch: 3 [12944/50000 (26%)]\tLoss: 1.202454\n",
            "Train Epoch: 3 [13424/50000 (27%)]\tLoss: 1.436807\n",
            "Train Epoch: 3 [13904/50000 (28%)]\tLoss: 0.539154\n",
            "Train Epoch: 3 [14384/50000 (29%)]\tLoss: 0.774511\n",
            "Train Epoch: 3 [14864/50000 (30%)]\tLoss: 1.131250\n",
            "Train Epoch: 3 [15344/50000 (31%)]\tLoss: 1.004932\n",
            "Train Epoch: 3 [15824/50000 (32%)]\tLoss: 0.765391\n",
            "Train Epoch: 3 [16304/50000 (33%)]\tLoss: 0.880966\n",
            "Train Epoch: 3 [16784/50000 (34%)]\tLoss: 1.283902\n",
            "Train Epoch: 3 [17264/50000 (35%)]\tLoss: 1.209079\n",
            "Train Epoch: 3 [17744/50000 (35%)]\tLoss: 0.891345\n",
            "Train Epoch: 3 [18224/50000 (36%)]\tLoss: 0.844568\n",
            "Train Epoch: 3 [18704/50000 (37%)]\tLoss: 1.240812\n",
            "Train Epoch: 3 [19184/50000 (38%)]\tLoss: 1.133189\n",
            "Train Epoch: 3 [19664/50000 (39%)]\tLoss: 1.508454\n",
            "Train Epoch: 3 [20144/50000 (40%)]\tLoss: 1.152753\n",
            "Train Epoch: 3 [20624/50000 (41%)]\tLoss: 1.334633\n",
            "Train Epoch: 3 [21104/50000 (42%)]\tLoss: 1.151180\n",
            "Train Epoch: 3 [21584/50000 (43%)]\tLoss: 1.120577\n",
            "Train Epoch: 3 [22064/50000 (44%)]\tLoss: 0.811414\n",
            "Train Epoch: 3 [22544/50000 (45%)]\tLoss: 0.502551\n",
            "Train Epoch: 3 [23024/50000 (46%)]\tLoss: 0.711421\n",
            "Train Epoch: 3 [23504/50000 (47%)]\tLoss: 0.913975\n",
            "Train Epoch: 3 [23984/50000 (48%)]\tLoss: 1.054124\n",
            "Train Epoch: 3 [24464/50000 (49%)]\tLoss: 1.376157\n",
            "Train Epoch: 3 [24944/50000 (50%)]\tLoss: 1.300834\n",
            "Train Epoch: 3 [25424/50000 (51%)]\tLoss: 1.558520\n",
            "Train Epoch: 3 [25904/50000 (52%)]\tLoss: 1.223580\n",
            "Train Epoch: 3 [26384/50000 (53%)]\tLoss: 1.063422\n",
            "Train Epoch: 3 [26864/50000 (54%)]\tLoss: 1.220792\n",
            "Train Epoch: 3 [27344/50000 (55%)]\tLoss: 1.032554\n",
            "Train Epoch: 3 [27824/50000 (56%)]\tLoss: 0.946243\n",
            "Train Epoch: 3 [28304/50000 (57%)]\tLoss: 1.425328\n",
            "Train Epoch: 3 [28784/50000 (58%)]\tLoss: 1.055857\n",
            "Train Epoch: 3 [29264/50000 (59%)]\tLoss: 0.785172\n",
            "Train Epoch: 3 [29744/50000 (59%)]\tLoss: 1.201831\n",
            "Train Epoch: 3 [30224/50000 (60%)]\tLoss: 0.852190\n",
            "Train Epoch: 3 [30704/50000 (61%)]\tLoss: 1.206216\n",
            "Train Epoch: 3 [31184/50000 (62%)]\tLoss: 0.761326\n",
            "Train Epoch: 3 [31664/50000 (63%)]\tLoss: 0.810294\n",
            "Train Epoch: 3 [32144/50000 (64%)]\tLoss: 1.287910\n",
            "Train Epoch: 3 [32624/50000 (65%)]\tLoss: 1.306166\n",
            "Train Epoch: 3 [33104/50000 (66%)]\tLoss: 0.769206\n",
            "Train Epoch: 3 [33584/50000 (67%)]\tLoss: 1.123032\n",
            "Train Epoch: 3 [34064/50000 (68%)]\tLoss: 1.142274\n",
            "Train Epoch: 3 [34544/50000 (69%)]\tLoss: 1.454981\n",
            "Train Epoch: 3 [35024/50000 (70%)]\tLoss: 1.240077\n",
            "Train Epoch: 3 [35504/50000 (71%)]\tLoss: 0.900871\n",
            "Train Epoch: 3 [35984/50000 (72%)]\tLoss: 0.796997\n",
            "Train Epoch: 3 [36464/50000 (73%)]\tLoss: 1.098436\n",
            "Train Epoch: 3 [36944/50000 (74%)]\tLoss: 1.341485\n",
            "Train Epoch: 3 [37424/50000 (75%)]\tLoss: 0.765574\n",
            "Train Epoch: 3 [37904/50000 (76%)]\tLoss: 1.269575\n",
            "Train Epoch: 3 [38384/50000 (77%)]\tLoss: 0.995553\n",
            "Train Epoch: 3 [38864/50000 (78%)]\tLoss: 0.968974\n",
            "Train Epoch: 3 [39344/50000 (79%)]\tLoss: 0.701071\n",
            "Train Epoch: 3 [39824/50000 (80%)]\tLoss: 1.567680\n",
            "Train Epoch: 3 [40304/50000 (81%)]\tLoss: 0.844562\n",
            "Train Epoch: 3 [40784/50000 (82%)]\tLoss: 1.120134\n",
            "Train Epoch: 3 [41264/50000 (83%)]\tLoss: 0.435049\n",
            "Train Epoch: 3 [41744/50000 (83%)]\tLoss: 0.755660\n",
            "Train Epoch: 3 [42224/50000 (84%)]\tLoss: 1.201129\n",
            "Train Epoch: 3 [42704/50000 (85%)]\tLoss: 1.108794\n",
            "Train Epoch: 3 [43184/50000 (86%)]\tLoss: 1.366503\n",
            "Train Epoch: 3 [43664/50000 (87%)]\tLoss: 0.774237\n",
            "Train Epoch: 3 [44144/50000 (88%)]\tLoss: 1.015242\n",
            "Train Epoch: 3 [44624/50000 (89%)]\tLoss: 1.205594\n",
            "Train Epoch: 3 [45104/50000 (90%)]\tLoss: 0.998778\n",
            "Train Epoch: 3 [45584/50000 (91%)]\tLoss: 0.740846\n",
            "Train Epoch: 3 [46064/50000 (92%)]\tLoss: 1.121894\n",
            "Train Epoch: 3 [46544/50000 (93%)]\tLoss: 1.125010\n",
            "Train Epoch: 3 [47024/50000 (94%)]\tLoss: 1.208159\n",
            "Train Epoch: 3 [47504/50000 (95%)]\tLoss: 1.254032\n",
            "Train Epoch: 3 [47984/50000 (96%)]\tLoss: 0.713435\n",
            "Train Epoch: 3 [48464/50000 (97%)]\tLoss: 1.045789\n",
            "Train Epoch: 3 [48944/50000 (98%)]\tLoss: 1.113007\n",
            "Train Epoch: 3 [49424/50000 (99%)]\tLoss: 0.931252\n",
            "Train Epoch: 3 [49904/50000 (100%)]\tLoss: 0.604842\n",
            "---------------------------------------\n",
            "Training time for epoch 3: 198.88 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch3): Average loss: 0.8984, Accuracy: 6839/10000 (68%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 4 [464/50000 (1%)]\tLoss: 0.799563\n",
            "Train Epoch: 4 [944/50000 (2%)]\tLoss: 1.021045\n",
            "Train Epoch: 4 [1424/50000 (3%)]\tLoss: 1.197400\n",
            "Train Epoch: 4 [1904/50000 (4%)]\tLoss: 1.555106\n",
            "Train Epoch: 4 [2384/50000 (5%)]\tLoss: 0.708666\n",
            "Train Epoch: 4 [2864/50000 (6%)]\tLoss: 0.646523\n",
            "Train Epoch: 4 [3344/50000 (7%)]\tLoss: 1.197855\n",
            "Train Epoch: 4 [3824/50000 (8%)]\tLoss: 1.009174\n",
            "Train Epoch: 4 [4304/50000 (9%)]\tLoss: 0.673161\n",
            "Train Epoch: 4 [4784/50000 (10%)]\tLoss: 1.040830\n",
            "Train Epoch: 4 [5264/50000 (11%)]\tLoss: 0.829787\n",
            "Train Epoch: 4 [5744/50000 (11%)]\tLoss: 0.916756\n",
            "Train Epoch: 4 [6224/50000 (12%)]\tLoss: 0.539721\n",
            "Train Epoch: 4 [6704/50000 (13%)]\tLoss: 0.938978\n",
            "Train Epoch: 4 [7184/50000 (14%)]\tLoss: 0.537182\n",
            "Train Epoch: 4 [7664/50000 (15%)]\tLoss: 1.046481\n",
            "Train Epoch: 4 [8144/50000 (16%)]\tLoss: 0.780845\n",
            "Train Epoch: 4 [8624/50000 (17%)]\tLoss: 1.426529\n",
            "Train Epoch: 4 [9104/50000 (18%)]\tLoss: 0.748748\n",
            "Train Epoch: 4 [9584/50000 (19%)]\tLoss: 0.767321\n",
            "Train Epoch: 4 [10064/50000 (20%)]\tLoss: 0.848014\n",
            "Train Epoch: 4 [10544/50000 (21%)]\tLoss: 0.597821\n",
            "Train Epoch: 4 [11024/50000 (22%)]\tLoss: 0.567855\n",
            "Train Epoch: 4 [11504/50000 (23%)]\tLoss: 0.653671\n",
            "Train Epoch: 4 [11984/50000 (24%)]\tLoss: 1.301283\n",
            "Train Epoch: 4 [12464/50000 (25%)]\tLoss: 1.153659\n",
            "Train Epoch: 4 [12944/50000 (26%)]\tLoss: 0.711203\n",
            "Train Epoch: 4 [13424/50000 (27%)]\tLoss: 0.645264\n",
            "Train Epoch: 4 [13904/50000 (28%)]\tLoss: 0.858368\n",
            "Train Epoch: 4 [14384/50000 (29%)]\tLoss: 1.059869\n",
            "Train Epoch: 4 [14864/50000 (30%)]\tLoss: 0.997665\n",
            "Train Epoch: 4 [15344/50000 (31%)]\tLoss: 0.382742\n",
            "Train Epoch: 4 [15824/50000 (32%)]\tLoss: 0.379322\n",
            "Train Epoch: 4 [16304/50000 (33%)]\tLoss: 0.973888\n",
            "Train Epoch: 4 [16784/50000 (34%)]\tLoss: 0.893621\n",
            "Train Epoch: 4 [17264/50000 (35%)]\tLoss: 0.873492\n",
            "Train Epoch: 4 [17744/50000 (35%)]\tLoss: 1.291098\n",
            "Train Epoch: 4 [18224/50000 (36%)]\tLoss: 0.610399\n",
            "Train Epoch: 4 [18704/50000 (37%)]\tLoss: 1.014157\n",
            "Train Epoch: 4 [19184/50000 (38%)]\tLoss: 1.313105\n",
            "Train Epoch: 4 [19664/50000 (39%)]\tLoss: 0.850272\n",
            "Train Epoch: 4 [20144/50000 (40%)]\tLoss: 1.071344\n",
            "Train Epoch: 4 [20624/50000 (41%)]\tLoss: 1.254638\n",
            "Train Epoch: 4 [21104/50000 (42%)]\tLoss: 0.850982\n",
            "Train Epoch: 4 [21584/50000 (43%)]\tLoss: 1.042324\n",
            "Train Epoch: 4 [22064/50000 (44%)]\tLoss: 1.450812\n",
            "Train Epoch: 4 [22544/50000 (45%)]\tLoss: 0.971648\n",
            "Train Epoch: 4 [23024/50000 (46%)]\tLoss: 0.614343\n",
            "Train Epoch: 4 [23504/50000 (47%)]\tLoss: 0.828084\n",
            "Train Epoch: 4 [23984/50000 (48%)]\tLoss: 0.718768\n",
            "Train Epoch: 4 [24464/50000 (49%)]\tLoss: 0.834769\n",
            "Train Epoch: 4 [24944/50000 (50%)]\tLoss: 1.086448\n",
            "Train Epoch: 4 [25424/50000 (51%)]\tLoss: 1.270129\n",
            "Train Epoch: 4 [25904/50000 (52%)]\tLoss: 1.319625\n",
            "Train Epoch: 4 [26384/50000 (53%)]\tLoss: 0.984802\n",
            "Train Epoch: 4 [26864/50000 (54%)]\tLoss: 1.062089\n",
            "Train Epoch: 4 [27344/50000 (55%)]\tLoss: 0.965153\n",
            "Train Epoch: 4 [27824/50000 (56%)]\tLoss: 0.736642\n",
            "Train Epoch: 4 [28304/50000 (57%)]\tLoss: 0.894344\n",
            "Train Epoch: 4 [28784/50000 (58%)]\tLoss: 0.941582\n",
            "Train Epoch: 4 [29264/50000 (59%)]\tLoss: 0.838128\n",
            "Train Epoch: 4 [29744/50000 (59%)]\tLoss: 0.811926\n",
            "Train Epoch: 4 [30224/50000 (60%)]\tLoss: 0.934822\n",
            "Train Epoch: 4 [30704/50000 (61%)]\tLoss: 0.697746\n",
            "Train Epoch: 4 [31184/50000 (62%)]\tLoss: 0.796790\n",
            "Train Epoch: 4 [31664/50000 (63%)]\tLoss: 1.208288\n",
            "Train Epoch: 4 [32144/50000 (64%)]\tLoss: 0.743873\n",
            "Train Epoch: 4 [32624/50000 (65%)]\tLoss: 1.009084\n",
            "Train Epoch: 4 [33104/50000 (66%)]\tLoss: 1.174031\n",
            "Train Epoch: 4 [33584/50000 (67%)]\tLoss: 0.684940\n",
            "Train Epoch: 4 [34064/50000 (68%)]\tLoss: 0.795748\n",
            "Train Epoch: 4 [34544/50000 (69%)]\tLoss: 1.580967\n",
            "Train Epoch: 4 [35024/50000 (70%)]\tLoss: 0.848076\n",
            "Train Epoch: 4 [35504/50000 (71%)]\tLoss: 0.906945\n",
            "Train Epoch: 4 [35984/50000 (72%)]\tLoss: 1.116719\n",
            "Train Epoch: 4 [36464/50000 (73%)]\tLoss: 0.482581\n",
            "Train Epoch: 4 [36944/50000 (74%)]\tLoss: 0.609109\n",
            "Train Epoch: 4 [37424/50000 (75%)]\tLoss: 0.479733\n",
            "Train Epoch: 4 [37904/50000 (76%)]\tLoss: 0.960558\n",
            "Train Epoch: 4 [38384/50000 (77%)]\tLoss: 0.695299\n",
            "Train Epoch: 4 [38864/50000 (78%)]\tLoss: 1.095509\n",
            "Train Epoch: 4 [39344/50000 (79%)]\tLoss: 1.082513\n",
            "Train Epoch: 4 [39824/50000 (80%)]\tLoss: 0.415080\n",
            "Train Epoch: 4 [40304/50000 (81%)]\tLoss: 0.694793\n",
            "Train Epoch: 4 [40784/50000 (82%)]\tLoss: 1.323721\n",
            "Train Epoch: 4 [41264/50000 (83%)]\tLoss: 0.925409\n",
            "Train Epoch: 4 [41744/50000 (83%)]\tLoss: 0.775050\n",
            "Train Epoch: 4 [42224/50000 (84%)]\tLoss: 0.792791\n",
            "Train Epoch: 4 [42704/50000 (85%)]\tLoss: 1.409493\n",
            "Train Epoch: 4 [43184/50000 (86%)]\tLoss: 0.741641\n",
            "Train Epoch: 4 [43664/50000 (87%)]\tLoss: 0.675709\n",
            "Train Epoch: 4 [44144/50000 (88%)]\tLoss: 0.763864\n",
            "Train Epoch: 4 [44624/50000 (89%)]\tLoss: 0.695834\n",
            "Train Epoch: 4 [45104/50000 (90%)]\tLoss: 1.161818\n",
            "Train Epoch: 4 [45584/50000 (91%)]\tLoss: 0.792755\n",
            "Train Epoch: 4 [46064/50000 (92%)]\tLoss: 0.970843\n",
            "Train Epoch: 4 [46544/50000 (93%)]\tLoss: 1.159377\n",
            "Train Epoch: 4 [47024/50000 (94%)]\tLoss: 0.989056\n",
            "Train Epoch: 4 [47504/50000 (95%)]\tLoss: 0.968255\n",
            "Train Epoch: 4 [47984/50000 (96%)]\tLoss: 1.353774\n",
            "Train Epoch: 4 [48464/50000 (97%)]\tLoss: 0.992078\n",
            "Train Epoch: 4 [48944/50000 (98%)]\tLoss: 1.100185\n",
            "Train Epoch: 4 [49424/50000 (99%)]\tLoss: 1.036703\n",
            "Train Epoch: 4 [49904/50000 (100%)]\tLoss: 0.866071\n",
            "---------------------------------------\n",
            "Training time for epoch 4: 199.14 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch4): Average loss: 0.8114, Accuracy: 7158/10000 (72%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 5 [464/50000 (1%)]\tLoss: 0.652204\n",
            "Train Epoch: 5 [944/50000 (2%)]\tLoss: 0.638927\n",
            "Train Epoch: 5 [1424/50000 (3%)]\tLoss: 0.856738\n",
            "Train Epoch: 5 [1904/50000 (4%)]\tLoss: 0.460151\n",
            "Train Epoch: 5 [2384/50000 (5%)]\tLoss: 0.696943\n",
            "Train Epoch: 5 [2864/50000 (6%)]\tLoss: 0.463823\n",
            "Train Epoch: 5 [3344/50000 (7%)]\tLoss: 0.743412\n",
            "Train Epoch: 5 [3824/50000 (8%)]\tLoss: 0.935477\n",
            "Train Epoch: 5 [4304/50000 (9%)]\tLoss: 0.783229\n",
            "Train Epoch: 5 [4784/50000 (10%)]\tLoss: 0.967053\n",
            "Train Epoch: 5 [5264/50000 (11%)]\tLoss: 0.530021\n",
            "Train Epoch: 5 [5744/50000 (11%)]\tLoss: 0.597950\n",
            "Train Epoch: 5 [6224/50000 (12%)]\tLoss: 0.844641\n",
            "Train Epoch: 5 [6704/50000 (13%)]\tLoss: 0.790013\n",
            "Train Epoch: 5 [7184/50000 (14%)]\tLoss: 0.748464\n",
            "Train Epoch: 5 [7664/50000 (15%)]\tLoss: 1.062156\n",
            "Train Epoch: 5 [8144/50000 (16%)]\tLoss: 0.463740\n",
            "Train Epoch: 5 [8624/50000 (17%)]\tLoss: 0.454528\n",
            "Train Epoch: 5 [9104/50000 (18%)]\tLoss: 0.751484\n",
            "Train Epoch: 5 [9584/50000 (19%)]\tLoss: 0.468175\n",
            "Train Epoch: 5 [10064/50000 (20%)]\tLoss: 1.072909\n",
            "Train Epoch: 5 [10544/50000 (21%)]\tLoss: 0.571926\n",
            "Train Epoch: 5 [11024/50000 (22%)]\tLoss: 0.774950\n",
            "Train Epoch: 5 [11504/50000 (23%)]\tLoss: 0.737742\n",
            "Train Epoch: 5 [11984/50000 (24%)]\tLoss: 1.236529\n",
            "Train Epoch: 5 [12464/50000 (25%)]\tLoss: 0.503636\n",
            "Train Epoch: 5 [12944/50000 (26%)]\tLoss: 0.804612\n",
            "Train Epoch: 5 [13424/50000 (27%)]\tLoss: 0.769038\n",
            "Train Epoch: 5 [13904/50000 (28%)]\tLoss: 1.042496\n",
            "Train Epoch: 5 [14384/50000 (29%)]\tLoss: 1.294077\n",
            "Train Epoch: 5 [14864/50000 (30%)]\tLoss: 0.914437\n",
            "Train Epoch: 5 [15344/50000 (31%)]\tLoss: 1.282193\n",
            "Train Epoch: 5 [15824/50000 (32%)]\tLoss: 0.955925\n",
            "Train Epoch: 5 [16304/50000 (33%)]\tLoss: 0.632734\n",
            "Train Epoch: 5 [16784/50000 (34%)]\tLoss: 1.006290\n",
            "Train Epoch: 5 [17264/50000 (35%)]\tLoss: 0.987780\n",
            "Train Epoch: 5 [17744/50000 (35%)]\tLoss: 0.966722\n",
            "Train Epoch: 5 [18224/50000 (36%)]\tLoss: 0.577712\n",
            "Train Epoch: 5 [18704/50000 (37%)]\tLoss: 0.535079\n",
            "Train Epoch: 5 [19184/50000 (38%)]\tLoss: 0.678375\n",
            "Train Epoch: 5 [19664/50000 (39%)]\tLoss: 0.601917\n",
            "Train Epoch: 5 [20144/50000 (40%)]\tLoss: 0.646111\n",
            "Train Epoch: 5 [20624/50000 (41%)]\tLoss: 0.823339\n",
            "Train Epoch: 5 [21104/50000 (42%)]\tLoss: 0.724014\n",
            "Train Epoch: 5 [21584/50000 (43%)]\tLoss: 1.263195\n",
            "Train Epoch: 5 [22064/50000 (44%)]\tLoss: 0.898459\n",
            "Train Epoch: 5 [22544/50000 (45%)]\tLoss: 1.033504\n",
            "Train Epoch: 5 [23024/50000 (46%)]\tLoss: 1.058399\n",
            "Train Epoch: 5 [23504/50000 (47%)]\tLoss: 0.851587\n",
            "Train Epoch: 5 [23984/50000 (48%)]\tLoss: 0.536536\n",
            "Train Epoch: 5 [24464/50000 (49%)]\tLoss: 1.178110\n",
            "Train Epoch: 5 [24944/50000 (50%)]\tLoss: 0.787035\n",
            "Train Epoch: 5 [25424/50000 (51%)]\tLoss: 0.367575\n",
            "Train Epoch: 5 [25904/50000 (52%)]\tLoss: 0.641887\n",
            "Train Epoch: 5 [26384/50000 (53%)]\tLoss: 0.612607\n",
            "Train Epoch: 5 [26864/50000 (54%)]\tLoss: 0.361806\n",
            "Train Epoch: 5 [27344/50000 (55%)]\tLoss: 0.717789\n",
            "Train Epoch: 5 [27824/50000 (56%)]\tLoss: 0.795929\n",
            "Train Epoch: 5 [28304/50000 (57%)]\tLoss: 0.517598\n",
            "Train Epoch: 5 [28784/50000 (58%)]\tLoss: 1.102778\n",
            "Train Epoch: 5 [29264/50000 (59%)]\tLoss: 0.895946\n",
            "Train Epoch: 5 [29744/50000 (59%)]\tLoss: 0.713206\n",
            "Train Epoch: 5 [30224/50000 (60%)]\tLoss: 1.137640\n",
            "Train Epoch: 5 [30704/50000 (61%)]\tLoss: 1.150049\n",
            "Train Epoch: 5 [31184/50000 (62%)]\tLoss: 0.567068\n",
            "Train Epoch: 5 [31664/50000 (63%)]\tLoss: 0.977703\n",
            "Train Epoch: 5 [32144/50000 (64%)]\tLoss: 0.891528\n",
            "Train Epoch: 5 [32624/50000 (65%)]\tLoss: 1.127714\n",
            "Train Epoch: 5 [33104/50000 (66%)]\tLoss: 0.680088\n",
            "Train Epoch: 5 [33584/50000 (67%)]\tLoss: 0.595917\n",
            "Train Epoch: 5 [34064/50000 (68%)]\tLoss: 1.232240\n",
            "Train Epoch: 5 [34544/50000 (69%)]\tLoss: 0.689437\n",
            "Train Epoch: 5 [35024/50000 (70%)]\tLoss: 1.138757\n",
            "Train Epoch: 5 [35504/50000 (71%)]\tLoss: 1.057665\n",
            "Train Epoch: 5 [35984/50000 (72%)]\tLoss: 0.917079\n",
            "Train Epoch: 5 [36464/50000 (73%)]\tLoss: 0.785470\n",
            "Train Epoch: 5 [36944/50000 (74%)]\tLoss: 0.745903\n",
            "Train Epoch: 5 [37424/50000 (75%)]\tLoss: 0.999800\n",
            "Train Epoch: 5 [37904/50000 (76%)]\tLoss: 0.756292\n",
            "Train Epoch: 5 [38384/50000 (77%)]\tLoss: 0.668716\n",
            "Train Epoch: 5 [38864/50000 (78%)]\tLoss: 0.815788\n",
            "Train Epoch: 5 [39344/50000 (79%)]\tLoss: 1.027262\n",
            "Train Epoch: 5 [39824/50000 (80%)]\tLoss: 1.034125\n",
            "Train Epoch: 5 [40304/50000 (81%)]\tLoss: 0.527998\n",
            "Train Epoch: 5 [40784/50000 (82%)]\tLoss: 1.259762\n",
            "Train Epoch: 5 [41264/50000 (83%)]\tLoss: 1.112084\n",
            "Train Epoch: 5 [41744/50000 (83%)]\tLoss: 0.667189\n",
            "Train Epoch: 5 [42224/50000 (84%)]\tLoss: 0.706048\n",
            "Train Epoch: 5 [42704/50000 (85%)]\tLoss: 1.540252\n",
            "Train Epoch: 5 [43184/50000 (86%)]\tLoss: 0.489202\n",
            "Train Epoch: 5 [43664/50000 (87%)]\tLoss: 1.945535\n",
            "Train Epoch: 5 [44144/50000 (88%)]\tLoss: 0.891134\n",
            "Train Epoch: 5 [44624/50000 (89%)]\tLoss: 0.872128\n",
            "Train Epoch: 5 [45104/50000 (90%)]\tLoss: 0.990580\n",
            "Train Epoch: 5 [45584/50000 (91%)]\tLoss: 1.345341\n",
            "Train Epoch: 5 [46064/50000 (92%)]\tLoss: 0.823948\n",
            "Train Epoch: 5 [46544/50000 (93%)]\tLoss: 0.924797\n",
            "Train Epoch: 5 [47024/50000 (94%)]\tLoss: 0.884440\n",
            "Train Epoch: 5 [47504/50000 (95%)]\tLoss: 0.832050\n",
            "Train Epoch: 5 [47984/50000 (96%)]\tLoss: 1.536222\n",
            "Train Epoch: 5 [48464/50000 (97%)]\tLoss: 0.894598\n",
            "Train Epoch: 5 [48944/50000 (98%)]\tLoss: 1.223948\n",
            "Train Epoch: 5 [49424/50000 (99%)]\tLoss: 1.121839\n",
            "Train Epoch: 5 [49904/50000 (100%)]\tLoss: 0.619912\n",
            "---------------------------------------\n",
            "Training time for epoch 5: 199.50 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch5): Average loss: 0.7590, Accuracy: 7343/10000 (73%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 6 [464/50000 (1%)]\tLoss: 1.062792\n",
            "Train Epoch: 6 [944/50000 (2%)]\tLoss: 0.638181\n",
            "Train Epoch: 6 [1424/50000 (3%)]\tLoss: 0.614174\n",
            "Train Epoch: 6 [1904/50000 (4%)]\tLoss: 0.805320\n",
            "Train Epoch: 6 [2384/50000 (5%)]\tLoss: 1.180633\n",
            "Train Epoch: 6 [2864/50000 (6%)]\tLoss: 0.831809\n",
            "Train Epoch: 6 [3344/50000 (7%)]\tLoss: 0.452727\n",
            "Train Epoch: 6 [3824/50000 (8%)]\tLoss: 0.510322\n",
            "Train Epoch: 6 [4304/50000 (9%)]\tLoss: 1.249274\n",
            "Train Epoch: 6 [4784/50000 (10%)]\tLoss: 0.764181\n",
            "Train Epoch: 6 [5264/50000 (11%)]\tLoss: 0.693812\n",
            "Train Epoch: 6 [5744/50000 (11%)]\tLoss: 1.342392\n",
            "Train Epoch: 6 [6224/50000 (12%)]\tLoss: 0.809150\n",
            "Train Epoch: 6 [6704/50000 (13%)]\tLoss: 0.303644\n",
            "Train Epoch: 6 [7184/50000 (14%)]\tLoss: 0.761506\n",
            "Train Epoch: 6 [7664/50000 (15%)]\tLoss: 1.341332\n",
            "Train Epoch: 6 [8144/50000 (16%)]\tLoss: 0.566044\n",
            "Train Epoch: 6 [8624/50000 (17%)]\tLoss: 1.050788\n",
            "Train Epoch: 6 [9104/50000 (18%)]\tLoss: 0.913723\n",
            "Train Epoch: 6 [9584/50000 (19%)]\tLoss: 1.073733\n",
            "Train Epoch: 6 [10064/50000 (20%)]\tLoss: 0.552572\n",
            "Train Epoch: 6 [10544/50000 (21%)]\tLoss: 0.986534\n",
            "Train Epoch: 6 [11024/50000 (22%)]\tLoss: 1.139889\n",
            "Train Epoch: 6 [11504/50000 (23%)]\tLoss: 0.960461\n",
            "Train Epoch: 6 [11984/50000 (24%)]\tLoss: 1.078059\n",
            "Train Epoch: 6 [12464/50000 (25%)]\tLoss: 0.896390\n",
            "Train Epoch: 6 [12944/50000 (26%)]\tLoss: 1.210787\n",
            "Train Epoch: 6 [13424/50000 (27%)]\tLoss: 0.642561\n",
            "Train Epoch: 6 [13904/50000 (28%)]\tLoss: 0.638821\n",
            "Train Epoch: 6 [14384/50000 (29%)]\tLoss: 0.575350\n",
            "Train Epoch: 6 [14864/50000 (30%)]\tLoss: 0.851634\n",
            "Train Epoch: 6 [15344/50000 (31%)]\tLoss: 0.385953\n",
            "Train Epoch: 6 [15824/50000 (32%)]\tLoss: 0.493237\n",
            "Train Epoch: 6 [16304/50000 (33%)]\tLoss: 0.815318\n",
            "Train Epoch: 6 [16784/50000 (34%)]\tLoss: 0.804175\n",
            "Train Epoch: 6 [17264/50000 (35%)]\tLoss: 0.277764\n",
            "Train Epoch: 6 [17744/50000 (35%)]\tLoss: 0.611334\n",
            "Train Epoch: 6 [18224/50000 (36%)]\tLoss: 0.681828\n",
            "Train Epoch: 6 [18704/50000 (37%)]\tLoss: 0.687907\n",
            "Train Epoch: 6 [19184/50000 (38%)]\tLoss: 1.044778\n",
            "Train Epoch: 6 [19664/50000 (39%)]\tLoss: 0.845873\n",
            "Train Epoch: 6 [20144/50000 (40%)]\tLoss: 1.135879\n",
            "Train Epoch: 6 [20624/50000 (41%)]\tLoss: 0.679922\n",
            "Train Epoch: 6 [21104/50000 (42%)]\tLoss: 0.651785\n",
            "Train Epoch: 6 [21584/50000 (43%)]\tLoss: 0.528953\n",
            "Train Epoch: 6 [22064/50000 (44%)]\tLoss: 0.559687\n",
            "Train Epoch: 6 [22544/50000 (45%)]\tLoss: 0.701348\n",
            "Train Epoch: 6 [23024/50000 (46%)]\tLoss: 0.662201\n",
            "Train Epoch: 6 [23504/50000 (47%)]\tLoss: 0.570530\n",
            "Train Epoch: 6 [23984/50000 (48%)]\tLoss: 0.677553\n",
            "Train Epoch: 6 [24464/50000 (49%)]\tLoss: 0.712534\n",
            "Train Epoch: 6 [24944/50000 (50%)]\tLoss: 1.138389\n",
            "Train Epoch: 6 [25424/50000 (51%)]\tLoss: 1.029359\n",
            "Train Epoch: 6 [25904/50000 (52%)]\tLoss: 0.530479\n",
            "Train Epoch: 6 [26384/50000 (53%)]\tLoss: 0.954268\n",
            "Train Epoch: 6 [26864/50000 (54%)]\tLoss: 0.726169\n",
            "Train Epoch: 6 [27344/50000 (55%)]\tLoss: 0.728734\n",
            "Train Epoch: 6 [27824/50000 (56%)]\tLoss: 0.764409\n",
            "Train Epoch: 6 [28304/50000 (57%)]\tLoss: 0.975508\n",
            "Train Epoch: 6 [28784/50000 (58%)]\tLoss: 1.090269\n",
            "Train Epoch: 6 [29264/50000 (59%)]\tLoss: 1.124044\n",
            "Train Epoch: 6 [29744/50000 (59%)]\tLoss: 0.795654\n",
            "Train Epoch: 6 [30224/50000 (60%)]\tLoss: 0.733410\n",
            "Train Epoch: 6 [30704/50000 (61%)]\tLoss: 0.493931\n",
            "Train Epoch: 6 [31184/50000 (62%)]\tLoss: 0.574598\n",
            "Train Epoch: 6 [31664/50000 (63%)]\tLoss: 1.189931\n",
            "Train Epoch: 6 [32144/50000 (64%)]\tLoss: 0.970025\n",
            "Train Epoch: 6 [32624/50000 (65%)]\tLoss: 0.619112\n",
            "Train Epoch: 6 [33104/50000 (66%)]\tLoss: 0.551177\n",
            "Train Epoch: 6 [33584/50000 (67%)]\tLoss: 0.929403\n",
            "Train Epoch: 6 [34064/50000 (68%)]\tLoss: 0.586816\n",
            "Train Epoch: 6 [34544/50000 (69%)]\tLoss: 0.600052\n",
            "Train Epoch: 6 [35024/50000 (70%)]\tLoss: 0.458780\n",
            "Train Epoch: 6 [35504/50000 (71%)]\tLoss: 0.548974\n",
            "Train Epoch: 6 [35984/50000 (72%)]\tLoss: 0.950469\n",
            "Train Epoch: 6 [36464/50000 (73%)]\tLoss: 0.919848\n",
            "Train Epoch: 6 [36944/50000 (74%)]\tLoss: 1.053821\n",
            "Train Epoch: 6 [37424/50000 (75%)]\tLoss: 1.202580\n",
            "Train Epoch: 6 [37904/50000 (76%)]\tLoss: 1.077276\n",
            "Train Epoch: 6 [38384/50000 (77%)]\tLoss: 0.918335\n",
            "Train Epoch: 6 [38864/50000 (78%)]\tLoss: 0.447965\n",
            "Train Epoch: 6 [39344/50000 (79%)]\tLoss: 0.558811\n",
            "Train Epoch: 6 [39824/50000 (80%)]\tLoss: 0.482196\n",
            "Train Epoch: 6 [40304/50000 (81%)]\tLoss: 0.484335\n",
            "Train Epoch: 6 [40784/50000 (82%)]\tLoss: 0.776331\n",
            "Train Epoch: 6 [41264/50000 (83%)]\tLoss: 0.698633\n",
            "Train Epoch: 6 [41744/50000 (83%)]\tLoss: 0.965988\n",
            "Train Epoch: 6 [42224/50000 (84%)]\tLoss: 0.994528\n",
            "Train Epoch: 6 [42704/50000 (85%)]\tLoss: 1.166853\n",
            "Train Epoch: 6 [43184/50000 (86%)]\tLoss: 0.324709\n",
            "Train Epoch: 6 [43664/50000 (87%)]\tLoss: 0.470475\n",
            "Train Epoch: 6 [44144/50000 (88%)]\tLoss: 0.512191\n",
            "Train Epoch: 6 [44624/50000 (89%)]\tLoss: 0.653855\n",
            "Train Epoch: 6 [45104/50000 (90%)]\tLoss: 0.750888\n",
            "Train Epoch: 6 [45584/50000 (91%)]\tLoss: 0.672150\n",
            "Train Epoch: 6 [46064/50000 (92%)]\tLoss: 0.625182\n",
            "Train Epoch: 6 [46544/50000 (93%)]\tLoss: 0.503716\n",
            "Train Epoch: 6 [47024/50000 (94%)]\tLoss: 1.028579\n",
            "Train Epoch: 6 [47504/50000 (95%)]\tLoss: 1.069198\n",
            "Train Epoch: 6 [47984/50000 (96%)]\tLoss: 0.460525\n",
            "Train Epoch: 6 [48464/50000 (97%)]\tLoss: 0.993653\n",
            "Train Epoch: 6 [48944/50000 (98%)]\tLoss: 0.693101\n",
            "Train Epoch: 6 [49424/50000 (99%)]\tLoss: 0.514150\n",
            "Train Epoch: 6 [49904/50000 (100%)]\tLoss: 0.791525\n",
            "---------------------------------------\n",
            "Training time for epoch 6: 199.53 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch6): Average loss: 0.7100, Accuracy: 7496/10000 (75%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 7 [464/50000 (1%)]\tLoss: 0.466687\n",
            "Train Epoch: 7 [944/50000 (2%)]\tLoss: 0.501158\n",
            "Train Epoch: 7 [1424/50000 (3%)]\tLoss: 0.674053\n",
            "Train Epoch: 7 [1904/50000 (4%)]\tLoss: 1.100428\n",
            "Train Epoch: 7 [2384/50000 (5%)]\tLoss: 0.950658\n",
            "Train Epoch: 7 [2864/50000 (6%)]\tLoss: 0.711669\n",
            "Train Epoch: 7 [3344/50000 (7%)]\tLoss: 1.183687\n",
            "Train Epoch: 7 [3824/50000 (8%)]\tLoss: 1.059185\n",
            "Train Epoch: 7 [4304/50000 (9%)]\tLoss: 0.636166\n",
            "Train Epoch: 7 [4784/50000 (10%)]\tLoss: 0.471977\n",
            "Train Epoch: 7 [5264/50000 (11%)]\tLoss: 0.833290\n",
            "Train Epoch: 7 [5744/50000 (11%)]\tLoss: 0.841168\n",
            "Train Epoch: 7 [6224/50000 (12%)]\tLoss: 0.697585\n",
            "Train Epoch: 7 [6704/50000 (13%)]\tLoss: 0.695399\n",
            "Train Epoch: 7 [7184/50000 (14%)]\tLoss: 0.778567\n",
            "Train Epoch: 7 [7664/50000 (15%)]\tLoss: 0.544164\n",
            "Train Epoch: 7 [8144/50000 (16%)]\tLoss: 0.709861\n",
            "Train Epoch: 7 [8624/50000 (17%)]\tLoss: 0.534281\n",
            "Train Epoch: 7 [9104/50000 (18%)]\tLoss: 0.427189\n",
            "Train Epoch: 7 [9584/50000 (19%)]\tLoss: 1.108741\n",
            "Train Epoch: 7 [10064/50000 (20%)]\tLoss: 0.675193\n",
            "Train Epoch: 7 [10544/50000 (21%)]\tLoss: 0.604421\n",
            "Train Epoch: 7 [11024/50000 (22%)]\tLoss: 0.783174\n",
            "Train Epoch: 7 [11504/50000 (23%)]\tLoss: 0.566705\n",
            "Train Epoch: 7 [11984/50000 (24%)]\tLoss: 0.419259\n",
            "Train Epoch: 7 [12464/50000 (25%)]\tLoss: 0.874282\n",
            "Train Epoch: 7 [12944/50000 (26%)]\tLoss: 0.537695\n",
            "Train Epoch: 7 [13424/50000 (27%)]\tLoss: 0.299178\n",
            "Train Epoch: 7 [13904/50000 (28%)]\tLoss: 0.484224\n",
            "Train Epoch: 7 [14384/50000 (29%)]\tLoss: 0.759857\n",
            "Train Epoch: 7 [14864/50000 (30%)]\tLoss: 0.942450\n",
            "Train Epoch: 7 [15344/50000 (31%)]\tLoss: 0.655670\n",
            "Train Epoch: 7 [15824/50000 (32%)]\tLoss: 0.861407\n",
            "Train Epoch: 7 [16304/50000 (33%)]\tLoss: 0.548067\n",
            "Train Epoch: 7 [16784/50000 (34%)]\tLoss: 0.714591\n",
            "Train Epoch: 7 [17264/50000 (35%)]\tLoss: 0.506482\n",
            "Train Epoch: 7 [17744/50000 (35%)]\tLoss: 1.108225\n",
            "Train Epoch: 7 [18224/50000 (36%)]\tLoss: 0.808369\n",
            "Train Epoch: 7 [18704/50000 (37%)]\tLoss: 0.589998\n",
            "Train Epoch: 7 [19184/50000 (38%)]\tLoss: 0.808188\n",
            "Train Epoch: 7 [19664/50000 (39%)]\tLoss: 0.926266\n",
            "Train Epoch: 7 [20144/50000 (40%)]\tLoss: 0.627003\n",
            "Train Epoch: 7 [20624/50000 (41%)]\tLoss: 0.775027\n",
            "Train Epoch: 7 [21104/50000 (42%)]\tLoss: 0.634784\n",
            "Train Epoch: 7 [21584/50000 (43%)]\tLoss: 0.342865\n",
            "Train Epoch: 7 [22064/50000 (44%)]\tLoss: 0.643551\n",
            "Train Epoch: 7 [22544/50000 (45%)]\tLoss: 0.743237\n",
            "Train Epoch: 7 [23024/50000 (46%)]\tLoss: 0.578187\n",
            "Train Epoch: 7 [23504/50000 (47%)]\tLoss: 0.999377\n",
            "Train Epoch: 7 [23984/50000 (48%)]\tLoss: 0.464661\n",
            "Train Epoch: 7 [24464/50000 (49%)]\tLoss: 0.443198\n",
            "Train Epoch: 7 [24944/50000 (50%)]\tLoss: 0.575390\n",
            "Train Epoch: 7 [25424/50000 (51%)]\tLoss: 0.535874\n",
            "Train Epoch: 7 [25904/50000 (52%)]\tLoss: 0.610905\n",
            "Train Epoch: 7 [26384/50000 (53%)]\tLoss: 0.804786\n",
            "Train Epoch: 7 [26864/50000 (54%)]\tLoss: 0.757143\n",
            "Train Epoch: 7 [27344/50000 (55%)]\tLoss: 0.639210\n",
            "Train Epoch: 7 [27824/50000 (56%)]\tLoss: 0.473249\n",
            "Train Epoch: 7 [28304/50000 (57%)]\tLoss: 1.011200\n",
            "Train Epoch: 7 [28784/50000 (58%)]\tLoss: 0.750264\n",
            "Train Epoch: 7 [29264/50000 (59%)]\tLoss: 0.516045\n",
            "Train Epoch: 7 [29744/50000 (59%)]\tLoss: 0.721749\n",
            "Train Epoch: 7 [30224/50000 (60%)]\tLoss: 0.760752\n",
            "Train Epoch: 7 [30704/50000 (61%)]\tLoss: 0.849730\n",
            "Train Epoch: 7 [31184/50000 (62%)]\tLoss: 0.672834\n",
            "Train Epoch: 7 [31664/50000 (63%)]\tLoss: 0.841761\n",
            "Train Epoch: 7 [32144/50000 (64%)]\tLoss: 0.509020\n",
            "Train Epoch: 7 [32624/50000 (65%)]\tLoss: 0.714983\n",
            "Train Epoch: 7 [33104/50000 (66%)]\tLoss: 0.421432\n",
            "Train Epoch: 7 [33584/50000 (67%)]\tLoss: 0.521669\n",
            "Train Epoch: 7 [34064/50000 (68%)]\tLoss: 1.041016\n",
            "Train Epoch: 7 [34544/50000 (69%)]\tLoss: 0.895459\n",
            "Train Epoch: 7 [35024/50000 (70%)]\tLoss: 0.411260\n",
            "Train Epoch: 7 [35504/50000 (71%)]\tLoss: 0.435425\n",
            "Train Epoch: 7 [35984/50000 (72%)]\tLoss: 0.606867\n",
            "Train Epoch: 7 [36464/50000 (73%)]\tLoss: 0.767190\n",
            "Train Epoch: 7 [36944/50000 (74%)]\tLoss: 0.725228\n",
            "Train Epoch: 7 [37424/50000 (75%)]\tLoss: 0.973979\n",
            "Train Epoch: 7 [37904/50000 (76%)]\tLoss: 1.088366\n",
            "Train Epoch: 7 [38384/50000 (77%)]\tLoss: 0.930866\n",
            "Train Epoch: 7 [38864/50000 (78%)]\tLoss: 0.892363\n",
            "Train Epoch: 7 [39344/50000 (79%)]\tLoss: 0.452565\n",
            "Train Epoch: 7 [39824/50000 (80%)]\tLoss: 0.765375\n",
            "Train Epoch: 7 [40304/50000 (81%)]\tLoss: 0.911833\n",
            "Train Epoch: 7 [40784/50000 (82%)]\tLoss: 0.876151\n",
            "Train Epoch: 7 [41264/50000 (83%)]\tLoss: 0.896452\n",
            "Train Epoch: 7 [41744/50000 (83%)]\tLoss: 0.880065\n",
            "Train Epoch: 7 [42224/50000 (84%)]\tLoss: 0.804620\n",
            "Train Epoch: 7 [42704/50000 (85%)]\tLoss: 1.556738\n",
            "Train Epoch: 7 [43184/50000 (86%)]\tLoss: 0.737030\n",
            "Train Epoch: 7 [43664/50000 (87%)]\tLoss: 1.085891\n",
            "Train Epoch: 7 [44144/50000 (88%)]\tLoss: 0.630365\n",
            "Train Epoch: 7 [44624/50000 (89%)]\tLoss: 0.891946\n",
            "Train Epoch: 7 [45104/50000 (90%)]\tLoss: 1.109121\n",
            "Train Epoch: 7 [45584/50000 (91%)]\tLoss: 0.621739\n",
            "Train Epoch: 7 [46064/50000 (92%)]\tLoss: 1.552788\n",
            "Train Epoch: 7 [46544/50000 (93%)]\tLoss: 0.297182\n",
            "Train Epoch: 7 [47024/50000 (94%)]\tLoss: 1.307647\n",
            "Train Epoch: 7 [47504/50000 (95%)]\tLoss: 0.437547\n",
            "Train Epoch: 7 [47984/50000 (96%)]\tLoss: 0.354893\n",
            "Train Epoch: 7 [48464/50000 (97%)]\tLoss: 0.328593\n",
            "Train Epoch: 7 [48944/50000 (98%)]\tLoss: 1.049857\n",
            "Train Epoch: 7 [49424/50000 (99%)]\tLoss: 0.635504\n",
            "Train Epoch: 7 [49904/50000 (100%)]\tLoss: 0.702756\n",
            "---------------------------------------\n",
            "Training time for epoch 7: 199.03 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch7): Average loss: 0.6945, Accuracy: 7651/10000 (77%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 8 [464/50000 (1%)]\tLoss: 0.537615\n",
            "Train Epoch: 8 [944/50000 (2%)]\tLoss: 1.257295\n",
            "Train Epoch: 8 [1424/50000 (3%)]\tLoss: 0.694318\n",
            "Train Epoch: 8 [1904/50000 (4%)]\tLoss: 0.875219\n",
            "Train Epoch: 8 [2384/50000 (5%)]\tLoss: 0.915347\n",
            "Train Epoch: 8 [2864/50000 (6%)]\tLoss: 0.816953\n",
            "Train Epoch: 8 [3344/50000 (7%)]\tLoss: 0.614233\n",
            "Train Epoch: 8 [3824/50000 (8%)]\tLoss: 1.131577\n",
            "Train Epoch: 8 [4304/50000 (9%)]\tLoss: 0.812229\n",
            "Train Epoch: 8 [4784/50000 (10%)]\tLoss: 0.504288\n",
            "Train Epoch: 8 [5264/50000 (11%)]\tLoss: 0.438812\n",
            "Train Epoch: 8 [5744/50000 (11%)]\tLoss: 0.399058\n",
            "Train Epoch: 8 [6224/50000 (12%)]\tLoss: 0.737892\n",
            "Train Epoch: 8 [6704/50000 (13%)]\tLoss: 0.684892\n",
            "Train Epoch: 8 [7184/50000 (14%)]\tLoss: 0.548015\n",
            "Train Epoch: 8 [7664/50000 (15%)]\tLoss: 1.140756\n",
            "Train Epoch: 8 [8144/50000 (16%)]\tLoss: 0.712711\n",
            "Train Epoch: 8 [8624/50000 (17%)]\tLoss: 1.084965\n",
            "Train Epoch: 8 [9104/50000 (18%)]\tLoss: 0.500130\n",
            "Train Epoch: 8 [9584/50000 (19%)]\tLoss: 0.667112\n",
            "Train Epoch: 8 [10064/50000 (20%)]\tLoss: 0.523306\n",
            "Train Epoch: 8 [10544/50000 (21%)]\tLoss: 0.535825\n",
            "Train Epoch: 8 [11024/50000 (22%)]\tLoss: 0.390800\n",
            "Train Epoch: 8 [11504/50000 (23%)]\tLoss: 0.848209\n",
            "Train Epoch: 8 [11984/50000 (24%)]\tLoss: 0.629240\n",
            "Train Epoch: 8 [12464/50000 (25%)]\tLoss: 0.388662\n",
            "Train Epoch: 8 [12944/50000 (26%)]\tLoss: 1.076516\n",
            "Train Epoch: 8 [13424/50000 (27%)]\tLoss: 0.894866\n",
            "Train Epoch: 8 [13904/50000 (28%)]\tLoss: 0.605389\n",
            "Train Epoch: 8 [14384/50000 (29%)]\tLoss: 0.736914\n",
            "Train Epoch: 8 [14864/50000 (30%)]\tLoss: 0.571724\n",
            "Train Epoch: 8 [15344/50000 (31%)]\tLoss: 0.614168\n",
            "Train Epoch: 8 [15824/50000 (32%)]\tLoss: 0.428073\n",
            "Train Epoch: 8 [16304/50000 (33%)]\tLoss: 0.656003\n",
            "Train Epoch: 8 [16784/50000 (34%)]\tLoss: 0.567093\n",
            "Train Epoch: 8 [17264/50000 (35%)]\tLoss: 0.485879\n",
            "Train Epoch: 8 [17744/50000 (35%)]\tLoss: 0.614589\n",
            "Train Epoch: 8 [18224/50000 (36%)]\tLoss: 0.957849\n",
            "Train Epoch: 8 [18704/50000 (37%)]\tLoss: 0.470905\n",
            "Train Epoch: 8 [19184/50000 (38%)]\tLoss: 0.511130\n",
            "Train Epoch: 8 [19664/50000 (39%)]\tLoss: 0.982954\n",
            "Train Epoch: 8 [20144/50000 (40%)]\tLoss: 0.780384\n",
            "Train Epoch: 8 [20624/50000 (41%)]\tLoss: 0.703833\n",
            "Train Epoch: 8 [21104/50000 (42%)]\tLoss: 0.924798\n",
            "Train Epoch: 8 [21584/50000 (43%)]\tLoss: 0.492223\n",
            "Train Epoch: 8 [22064/50000 (44%)]\tLoss: 0.513348\n",
            "Train Epoch: 8 [22544/50000 (45%)]\tLoss: 0.592465\n",
            "Train Epoch: 8 [23024/50000 (46%)]\tLoss: 0.793152\n",
            "Train Epoch: 8 [23504/50000 (47%)]\tLoss: 0.543946\n",
            "Train Epoch: 8 [23984/50000 (48%)]\tLoss: 0.697659\n",
            "Train Epoch: 8 [24464/50000 (49%)]\tLoss: 0.670182\n",
            "Train Epoch: 8 [24944/50000 (50%)]\tLoss: 1.166937\n",
            "Train Epoch: 8 [25424/50000 (51%)]\tLoss: 1.178845\n",
            "Train Epoch: 8 [25904/50000 (52%)]\tLoss: 0.414846\n",
            "Train Epoch: 8 [26384/50000 (53%)]\tLoss: 0.459963\n",
            "Train Epoch: 8 [26864/50000 (54%)]\tLoss: 0.670752\n",
            "Train Epoch: 8 [27344/50000 (55%)]\tLoss: 0.634966\n",
            "Train Epoch: 8 [27824/50000 (56%)]\tLoss: 0.886232\n",
            "Train Epoch: 8 [28304/50000 (57%)]\tLoss: 0.596919\n",
            "Train Epoch: 8 [28784/50000 (58%)]\tLoss: 0.911387\n",
            "Train Epoch: 8 [29264/50000 (59%)]\tLoss: 0.776141\n",
            "Train Epoch: 8 [29744/50000 (59%)]\tLoss: 0.955126\n",
            "Train Epoch: 8 [30224/50000 (60%)]\tLoss: 0.412893\n",
            "Train Epoch: 8 [30704/50000 (61%)]\tLoss: 0.775588\n",
            "Train Epoch: 8 [31184/50000 (62%)]\tLoss: 0.766298\n",
            "Train Epoch: 8 [31664/50000 (63%)]\tLoss: 0.899846\n",
            "Train Epoch: 8 [32144/50000 (64%)]\tLoss: 0.446551\n",
            "Train Epoch: 8 [32624/50000 (65%)]\tLoss: 0.729832\n",
            "Train Epoch: 8 [33104/50000 (66%)]\tLoss: 0.427133\n",
            "Train Epoch: 8 [33584/50000 (67%)]\tLoss: 0.779220\n",
            "Train Epoch: 8 [34064/50000 (68%)]\tLoss: 0.734697\n",
            "Train Epoch: 8 [34544/50000 (69%)]\tLoss: 0.424257\n",
            "Train Epoch: 8 [35024/50000 (70%)]\tLoss: 0.715516\n",
            "Train Epoch: 8 [35504/50000 (71%)]\tLoss: 0.518570\n",
            "Train Epoch: 8 [35984/50000 (72%)]\tLoss: 0.337676\n",
            "Train Epoch: 8 [36464/50000 (73%)]\tLoss: 0.529119\n",
            "Train Epoch: 8 [36944/50000 (74%)]\tLoss: 0.907034\n",
            "Train Epoch: 8 [37424/50000 (75%)]\tLoss: 0.589687\n",
            "Train Epoch: 8 [37904/50000 (76%)]\tLoss: 0.509347\n",
            "Train Epoch: 8 [38384/50000 (77%)]\tLoss: 0.819512\n",
            "Train Epoch: 8 [38864/50000 (78%)]\tLoss: 0.629862\n",
            "Train Epoch: 8 [39344/50000 (79%)]\tLoss: 1.207360\n",
            "Train Epoch: 8 [39824/50000 (80%)]\tLoss: 0.889956\n",
            "Train Epoch: 8 [40304/50000 (81%)]\tLoss: 0.388800\n",
            "Train Epoch: 8 [40784/50000 (82%)]\tLoss: 0.572557\n",
            "Train Epoch: 8 [41264/50000 (83%)]\tLoss: 0.432295\n",
            "Train Epoch: 8 [41744/50000 (83%)]\tLoss: 0.950073\n",
            "Train Epoch: 8 [42224/50000 (84%)]\tLoss: 0.751178\n",
            "Train Epoch: 8 [42704/50000 (85%)]\tLoss: 0.553382\n",
            "Train Epoch: 8 [43184/50000 (86%)]\tLoss: 0.864488\n",
            "Train Epoch: 8 [43664/50000 (87%)]\tLoss: 0.636949\n",
            "Train Epoch: 8 [44144/50000 (88%)]\tLoss: 0.718738\n",
            "Train Epoch: 8 [44624/50000 (89%)]\tLoss: 0.666396\n",
            "Train Epoch: 8 [45104/50000 (90%)]\tLoss: 0.835202\n",
            "Train Epoch: 8 [45584/50000 (91%)]\tLoss: 0.459467\n",
            "Train Epoch: 8 [46064/50000 (92%)]\tLoss: 0.965452\n",
            "Train Epoch: 8 [46544/50000 (93%)]\tLoss: 0.928021\n",
            "Train Epoch: 8 [47024/50000 (94%)]\tLoss: 0.766952\n",
            "Train Epoch: 8 [47504/50000 (95%)]\tLoss: 0.927854\n",
            "Train Epoch: 8 [47984/50000 (96%)]\tLoss: 0.578083\n",
            "Train Epoch: 8 [48464/50000 (97%)]\tLoss: 1.004596\n",
            "Train Epoch: 8 [48944/50000 (98%)]\tLoss: 0.949414\n",
            "Train Epoch: 8 [49424/50000 (99%)]\tLoss: 0.208062\n",
            "Train Epoch: 8 [49904/50000 (100%)]\tLoss: 0.862921\n",
            "---------------------------------------\n",
            "Training time for epoch 8: 198.64 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch8): Average loss: 0.6396, Accuracy: 7813/10000 (78%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 9 [464/50000 (1%)]\tLoss: 0.686397\n",
            "Train Epoch: 9 [944/50000 (2%)]\tLoss: 0.719745\n",
            "Train Epoch: 9 [1424/50000 (3%)]\tLoss: 0.832179\n",
            "Train Epoch: 9 [1904/50000 (4%)]\tLoss: 0.833761\n",
            "Train Epoch: 9 [2384/50000 (5%)]\tLoss: 1.021023\n",
            "Train Epoch: 9 [2864/50000 (6%)]\tLoss: 0.271478\n",
            "Train Epoch: 9 [3344/50000 (7%)]\tLoss: 0.356459\n",
            "Train Epoch: 9 [3824/50000 (8%)]\tLoss: 1.005375\n",
            "Train Epoch: 9 [4304/50000 (9%)]\tLoss: 0.425866\n",
            "Train Epoch: 9 [4784/50000 (10%)]\tLoss: 0.708997\n",
            "Train Epoch: 9 [5264/50000 (11%)]\tLoss: 0.392659\n",
            "Train Epoch: 9 [5744/50000 (11%)]\tLoss: 0.863500\n",
            "Train Epoch: 9 [6224/50000 (12%)]\tLoss: 0.671893\n",
            "Train Epoch: 9 [6704/50000 (13%)]\tLoss: 0.400388\n",
            "Train Epoch: 9 [7184/50000 (14%)]\tLoss: 0.964213\n",
            "Train Epoch: 9 [7664/50000 (15%)]\tLoss: 0.548632\n",
            "Train Epoch: 9 [8144/50000 (16%)]\tLoss: 0.653402\n",
            "Train Epoch: 9 [8624/50000 (17%)]\tLoss: 0.477026\n",
            "Train Epoch: 9 [9104/50000 (18%)]\tLoss: 0.546375\n",
            "Train Epoch: 9 [9584/50000 (19%)]\tLoss: 0.781341\n",
            "Train Epoch: 9 [10064/50000 (20%)]\tLoss: 0.379165\n",
            "Train Epoch: 9 [10544/50000 (21%)]\tLoss: 0.513455\n",
            "Train Epoch: 9 [11024/50000 (22%)]\tLoss: 0.340758\n",
            "Train Epoch: 9 [11504/50000 (23%)]\tLoss: 0.869105\n",
            "Train Epoch: 9 [11984/50000 (24%)]\tLoss: 0.323590\n",
            "Train Epoch: 9 [12464/50000 (25%)]\tLoss: 0.835055\n",
            "Train Epoch: 9 [12944/50000 (26%)]\tLoss: 0.734669\n",
            "Train Epoch: 9 [13424/50000 (27%)]\tLoss: 0.767825\n",
            "Train Epoch: 9 [13904/50000 (28%)]\tLoss: 0.307366\n",
            "Train Epoch: 9 [14384/50000 (29%)]\tLoss: 0.958193\n",
            "Train Epoch: 9 [14864/50000 (30%)]\tLoss: 0.227639\n",
            "Train Epoch: 9 [15344/50000 (31%)]\tLoss: 0.782713\n",
            "Train Epoch: 9 [15824/50000 (32%)]\tLoss: 1.109109\n",
            "Train Epoch: 9 [16304/50000 (33%)]\tLoss: 0.588676\n",
            "Train Epoch: 9 [16784/50000 (34%)]\tLoss: 0.436367\n",
            "Train Epoch: 9 [17264/50000 (35%)]\tLoss: 0.917492\n",
            "Train Epoch: 9 [17744/50000 (35%)]\tLoss: 0.325411\n",
            "Train Epoch: 9 [18224/50000 (36%)]\tLoss: 0.282817\n",
            "Train Epoch: 9 [18704/50000 (37%)]\tLoss: 0.584818\n",
            "Train Epoch: 9 [19184/50000 (38%)]\tLoss: 0.549846\n",
            "Train Epoch: 9 [19664/50000 (39%)]\tLoss: 0.176138\n",
            "Train Epoch: 9 [20144/50000 (40%)]\tLoss: 0.744122\n",
            "Train Epoch: 9 [20624/50000 (41%)]\tLoss: 0.545361\n",
            "Train Epoch: 9 [21104/50000 (42%)]\tLoss: 0.638777\n",
            "Train Epoch: 9 [21584/50000 (43%)]\tLoss: 0.493555\n",
            "Train Epoch: 9 [22064/50000 (44%)]\tLoss: 0.459210\n",
            "Train Epoch: 9 [22544/50000 (45%)]\tLoss: 0.713463\n",
            "Train Epoch: 9 [23024/50000 (46%)]\tLoss: 0.843643\n",
            "Train Epoch: 9 [23504/50000 (47%)]\tLoss: 0.465676\n",
            "Train Epoch: 9 [23984/50000 (48%)]\tLoss: 0.353434\n",
            "Train Epoch: 9 [24464/50000 (49%)]\tLoss: 0.656994\n",
            "Train Epoch: 9 [24944/50000 (50%)]\tLoss: 0.314496\n",
            "Train Epoch: 9 [25424/50000 (51%)]\tLoss: 0.490396\n",
            "Train Epoch: 9 [25904/50000 (52%)]\tLoss: 0.720828\n",
            "Train Epoch: 9 [26384/50000 (53%)]\tLoss: 0.769281\n",
            "Train Epoch: 9 [26864/50000 (54%)]\tLoss: 0.561730\n",
            "Train Epoch: 9 [27344/50000 (55%)]\tLoss: 0.515284\n",
            "Train Epoch: 9 [27824/50000 (56%)]\tLoss: 0.456931\n",
            "Train Epoch: 9 [28304/50000 (57%)]\tLoss: 0.708298\n",
            "Train Epoch: 9 [28784/50000 (58%)]\tLoss: 0.764066\n",
            "Train Epoch: 9 [29264/50000 (59%)]\tLoss: 0.503919\n",
            "Train Epoch: 9 [29744/50000 (59%)]\tLoss: 0.662395\n",
            "Train Epoch: 9 [30224/50000 (60%)]\tLoss: 0.334029\n",
            "Train Epoch: 9 [30704/50000 (61%)]\tLoss: 0.282128\n",
            "Train Epoch: 9 [31184/50000 (62%)]\tLoss: 0.921648\n",
            "Train Epoch: 9 [31664/50000 (63%)]\tLoss: 0.795064\n",
            "Train Epoch: 9 [32144/50000 (64%)]\tLoss: 0.635790\n",
            "Train Epoch: 9 [32624/50000 (65%)]\tLoss: 0.977026\n",
            "Train Epoch: 9 [33104/50000 (66%)]\tLoss: 0.351768\n",
            "Train Epoch: 9 [33584/50000 (67%)]\tLoss: 0.602551\n",
            "Train Epoch: 9 [34064/50000 (68%)]\tLoss: 0.824431\n",
            "Train Epoch: 9 [34544/50000 (69%)]\tLoss: 0.756659\n",
            "Train Epoch: 9 [35024/50000 (70%)]\tLoss: 0.984763\n",
            "Train Epoch: 9 [35504/50000 (71%)]\tLoss: 0.615155\n",
            "Train Epoch: 9 [35984/50000 (72%)]\tLoss: 0.785704\n",
            "Train Epoch: 9 [36464/50000 (73%)]\tLoss: 0.514638\n",
            "Train Epoch: 9 [36944/50000 (74%)]\tLoss: 0.256322\n",
            "Train Epoch: 9 [37424/50000 (75%)]\tLoss: 0.977579\n",
            "Train Epoch: 9 [37904/50000 (76%)]\tLoss: 0.535113\n",
            "Train Epoch: 9 [38384/50000 (77%)]\tLoss: 0.550457\n",
            "Train Epoch: 9 [38864/50000 (78%)]\tLoss: 0.432391\n",
            "Train Epoch: 9 [39344/50000 (79%)]\tLoss: 0.643858\n",
            "Train Epoch: 9 [39824/50000 (80%)]\tLoss: 0.408266\n",
            "Train Epoch: 9 [40304/50000 (81%)]\tLoss: 0.629752\n",
            "Train Epoch: 9 [40784/50000 (82%)]\tLoss: 0.697351\n",
            "Train Epoch: 9 [41264/50000 (83%)]\tLoss: 0.844279\n",
            "Train Epoch: 9 [41744/50000 (83%)]\tLoss: 0.571296\n",
            "Train Epoch: 9 [42224/50000 (84%)]\tLoss: 0.832974\n",
            "Train Epoch: 9 [42704/50000 (85%)]\tLoss: 0.924725\n",
            "Train Epoch: 9 [43184/50000 (86%)]\tLoss: 0.617337\n",
            "Train Epoch: 9 [43664/50000 (87%)]\tLoss: 1.162975\n",
            "Train Epoch: 9 [44144/50000 (88%)]\tLoss: 0.607490\n",
            "Train Epoch: 9 [44624/50000 (89%)]\tLoss: 0.571466\n",
            "Train Epoch: 9 [45104/50000 (90%)]\tLoss: 0.527798\n",
            "Train Epoch: 9 [45584/50000 (91%)]\tLoss: 0.340446\n",
            "Train Epoch: 9 [46064/50000 (92%)]\tLoss: 0.338814\n",
            "Train Epoch: 9 [46544/50000 (93%)]\tLoss: 0.730579\n",
            "Train Epoch: 9 [47024/50000 (94%)]\tLoss: 0.258516\n",
            "Train Epoch: 9 [47504/50000 (95%)]\tLoss: 0.796915\n",
            "Train Epoch: 9 [47984/50000 (96%)]\tLoss: 0.507424\n",
            "Train Epoch: 9 [48464/50000 (97%)]\tLoss: 0.744159\n",
            "Train Epoch: 9 [48944/50000 (98%)]\tLoss: 0.576417\n",
            "Train Epoch: 9 [49424/50000 (99%)]\tLoss: 0.826586\n",
            "Train Epoch: 9 [49904/50000 (100%)]\tLoss: 0.406421\n",
            "---------------------------------------\n",
            "Training time for epoch 9: 198.86 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch9): Average loss: 0.6258, Accuracy: 7844/10000 (78%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 10 [464/50000 (1%)]\tLoss: 0.398166\n",
            "Train Epoch: 10 [944/50000 (2%)]\tLoss: 0.330690\n",
            "Train Epoch: 10 [1424/50000 (3%)]\tLoss: 0.534104\n",
            "Train Epoch: 10 [1904/50000 (4%)]\tLoss: 0.651753\n",
            "Train Epoch: 10 [2384/50000 (5%)]\tLoss: 0.582822\n",
            "Train Epoch: 10 [2864/50000 (6%)]\tLoss: 0.322490\n",
            "Train Epoch: 10 [3344/50000 (7%)]\tLoss: 0.456383\n",
            "Train Epoch: 10 [3824/50000 (8%)]\tLoss: 1.176725\n",
            "Train Epoch: 10 [4304/50000 (9%)]\tLoss: 0.412581\n",
            "Train Epoch: 10 [4784/50000 (10%)]\tLoss: 0.885647\n",
            "Train Epoch: 10 [5264/50000 (11%)]\tLoss: 0.376404\n",
            "Train Epoch: 10 [5744/50000 (11%)]\tLoss: 1.152015\n",
            "Train Epoch: 10 [6224/50000 (12%)]\tLoss: 0.618526\n",
            "Train Epoch: 10 [6704/50000 (13%)]\tLoss: 0.596007\n",
            "Train Epoch: 10 [7184/50000 (14%)]\tLoss: 0.654046\n",
            "Train Epoch: 10 [7664/50000 (15%)]\tLoss: 0.497018\n",
            "Train Epoch: 10 [8144/50000 (16%)]\tLoss: 0.567583\n",
            "Train Epoch: 10 [8624/50000 (17%)]\tLoss: 0.780915\n",
            "Train Epoch: 10 [9104/50000 (18%)]\tLoss: 0.177877\n",
            "Train Epoch: 10 [9584/50000 (19%)]\tLoss: 1.138858\n",
            "Train Epoch: 10 [10064/50000 (20%)]\tLoss: 0.418181\n",
            "Train Epoch: 10 [10544/50000 (21%)]\tLoss: 1.570816\n",
            "Train Epoch: 10 [11024/50000 (22%)]\tLoss: 0.533088\n",
            "Train Epoch: 10 [11504/50000 (23%)]\tLoss: 0.868089\n",
            "Train Epoch: 10 [11984/50000 (24%)]\tLoss: 0.720859\n",
            "Train Epoch: 10 [12464/50000 (25%)]\tLoss: 0.846619\n",
            "Train Epoch: 10 [12944/50000 (26%)]\tLoss: 0.773380\n",
            "Train Epoch: 10 [13424/50000 (27%)]\tLoss: 0.194178\n",
            "Train Epoch: 10 [13904/50000 (28%)]\tLoss: 0.779806\n",
            "Train Epoch: 10 [14384/50000 (29%)]\tLoss: 0.260236\n",
            "Train Epoch: 10 [14864/50000 (30%)]\tLoss: 0.669632\n",
            "Train Epoch: 10 [15344/50000 (31%)]\tLoss: 0.253276\n",
            "Train Epoch: 10 [15824/50000 (32%)]\tLoss: 0.419373\n",
            "Train Epoch: 10 [16304/50000 (33%)]\tLoss: 0.630675\n",
            "Train Epoch: 10 [16784/50000 (34%)]\tLoss: 0.660776\n",
            "Train Epoch: 10 [17264/50000 (35%)]\tLoss: 0.559910\n",
            "Train Epoch: 10 [17744/50000 (35%)]\tLoss: 0.788206\n",
            "Train Epoch: 10 [18224/50000 (36%)]\tLoss: 0.631881\n",
            "Train Epoch: 10 [18704/50000 (37%)]\tLoss: 0.543427\n",
            "Train Epoch: 10 [19184/50000 (38%)]\tLoss: 1.153562\n",
            "Train Epoch: 10 [19664/50000 (39%)]\tLoss: 0.331549\n",
            "Train Epoch: 10 [20144/50000 (40%)]\tLoss: 0.439718\n",
            "Train Epoch: 10 [20624/50000 (41%)]\tLoss: 0.541197\n",
            "Train Epoch: 10 [21104/50000 (42%)]\tLoss: 0.377915\n",
            "Train Epoch: 10 [21584/50000 (43%)]\tLoss: 0.949125\n",
            "Train Epoch: 10 [22064/50000 (44%)]\tLoss: 0.785231\n",
            "Train Epoch: 10 [22544/50000 (45%)]\tLoss: 0.461987\n",
            "Train Epoch: 10 [23024/50000 (46%)]\tLoss: 0.890692\n",
            "Train Epoch: 10 [23504/50000 (47%)]\tLoss: 0.407570\n",
            "Train Epoch: 10 [23984/50000 (48%)]\tLoss: 0.546150\n",
            "Train Epoch: 10 [24464/50000 (49%)]\tLoss: 0.312937\n",
            "Train Epoch: 10 [24944/50000 (50%)]\tLoss: 0.688615\n",
            "Train Epoch: 10 [25424/50000 (51%)]\tLoss: 0.485423\n",
            "Train Epoch: 10 [25904/50000 (52%)]\tLoss: 0.437781\n",
            "Train Epoch: 10 [26384/50000 (53%)]\tLoss: 0.710971\n",
            "Train Epoch: 10 [26864/50000 (54%)]\tLoss: 0.333232\n",
            "Train Epoch: 10 [27344/50000 (55%)]\tLoss: 0.477766\n",
            "Train Epoch: 10 [27824/50000 (56%)]\tLoss: 0.204906\n",
            "Train Epoch: 10 [28304/50000 (57%)]\tLoss: 0.861645\n",
            "Train Epoch: 10 [28784/50000 (58%)]\tLoss: 0.438142\n",
            "Train Epoch: 10 [29264/50000 (59%)]\tLoss: 0.376978\n",
            "Train Epoch: 10 [29744/50000 (59%)]\tLoss: 0.874347\n",
            "Train Epoch: 10 [30224/50000 (60%)]\tLoss: 0.953472\n",
            "Train Epoch: 10 [30704/50000 (61%)]\tLoss: 1.076734\n",
            "Train Epoch: 10 [31184/50000 (62%)]\tLoss: 0.491060\n",
            "Train Epoch: 10 [31664/50000 (63%)]\tLoss: 0.402179\n",
            "Train Epoch: 10 [32144/50000 (64%)]\tLoss: 0.925547\n",
            "Train Epoch: 10 [32624/50000 (65%)]\tLoss: 1.090641\n",
            "Train Epoch: 10 [33104/50000 (66%)]\tLoss: 0.568550\n",
            "Train Epoch: 10 [33584/50000 (67%)]\tLoss: 0.518757\n",
            "Train Epoch: 10 [34064/50000 (68%)]\tLoss: 0.328134\n",
            "Train Epoch: 10 [34544/50000 (69%)]\tLoss: 0.493390\n",
            "Train Epoch: 10 [35024/50000 (70%)]\tLoss: 0.633497\n",
            "Train Epoch: 10 [35504/50000 (71%)]\tLoss: 0.579849\n",
            "Train Epoch: 10 [35984/50000 (72%)]\tLoss: 0.575184\n",
            "Train Epoch: 10 [36464/50000 (73%)]\tLoss: 1.194069\n",
            "Train Epoch: 10 [36944/50000 (74%)]\tLoss: 0.381499\n",
            "Train Epoch: 10 [37424/50000 (75%)]\tLoss: 0.488668\n",
            "Train Epoch: 10 [37904/50000 (76%)]\tLoss: 0.440352\n",
            "Train Epoch: 10 [38384/50000 (77%)]\tLoss: 0.646641\n",
            "Train Epoch: 10 [38864/50000 (78%)]\tLoss: 0.957015\n",
            "Train Epoch: 10 [39344/50000 (79%)]\tLoss: 0.686309\n",
            "Train Epoch: 10 [39824/50000 (80%)]\tLoss: 0.573237\n",
            "Train Epoch: 10 [40304/50000 (81%)]\tLoss: 0.326675\n",
            "Train Epoch: 10 [40784/50000 (82%)]\tLoss: 0.212841\n",
            "Train Epoch: 10 [41264/50000 (83%)]\tLoss: 0.393468\n",
            "Train Epoch: 10 [41744/50000 (83%)]\tLoss: 0.407229\n",
            "Train Epoch: 10 [42224/50000 (84%)]\tLoss: 0.666792\n",
            "Train Epoch: 10 [42704/50000 (85%)]\tLoss: 0.628482\n",
            "Train Epoch: 10 [43184/50000 (86%)]\tLoss: 0.323180\n",
            "Train Epoch: 10 [43664/50000 (87%)]\tLoss: 0.652374\n",
            "Train Epoch: 10 [44144/50000 (88%)]\tLoss: 0.731874\n",
            "Train Epoch: 10 [44624/50000 (89%)]\tLoss: 0.530696\n",
            "Train Epoch: 10 [45104/50000 (90%)]\tLoss: 0.618123\n",
            "Train Epoch: 10 [45584/50000 (91%)]\tLoss: 0.374364\n",
            "Train Epoch: 10 [46064/50000 (92%)]\tLoss: 0.518228\n",
            "Train Epoch: 10 [46544/50000 (93%)]\tLoss: 0.955783\n",
            "Train Epoch: 10 [47024/50000 (94%)]\tLoss: 0.628452\n",
            "Train Epoch: 10 [47504/50000 (95%)]\tLoss: 0.804134\n",
            "Train Epoch: 10 [47984/50000 (96%)]\tLoss: 1.009061\n",
            "Train Epoch: 10 [48464/50000 (97%)]\tLoss: 0.855426\n",
            "Train Epoch: 10 [48944/50000 (98%)]\tLoss: 0.700895\n",
            "Train Epoch: 10 [49424/50000 (99%)]\tLoss: 0.916275\n",
            "Train Epoch: 10 [49904/50000 (100%)]\tLoss: 0.210406\n",
            "---------------------------------------\n",
            "Training time for epoch 10: 198.72 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch10): Average loss: 0.6037, Accuracy: 7981/10000 (80%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 11 [464/50000 (1%)]\tLoss: 0.344452\n",
            "Train Epoch: 11 [944/50000 (2%)]\tLoss: 0.400876\n",
            "Train Epoch: 11 [1424/50000 (3%)]\tLoss: 0.531477\n",
            "Train Epoch: 11 [1904/50000 (4%)]\tLoss: 0.600391\n",
            "Train Epoch: 11 [2384/50000 (5%)]\tLoss: 0.905964\n",
            "Train Epoch: 11 [2864/50000 (6%)]\tLoss: 0.631625\n",
            "Train Epoch: 11 [3344/50000 (7%)]\tLoss: 0.422133\n",
            "Train Epoch: 11 [3824/50000 (8%)]\tLoss: 0.630715\n",
            "Train Epoch: 11 [4304/50000 (9%)]\tLoss: 0.687221\n",
            "Train Epoch: 11 [4784/50000 (10%)]\tLoss: 0.104180\n",
            "Train Epoch: 11 [5264/50000 (11%)]\tLoss: 0.487415\n",
            "Train Epoch: 11 [5744/50000 (11%)]\tLoss: 0.494522\n",
            "Train Epoch: 11 [6224/50000 (12%)]\tLoss: 0.281275\n",
            "Train Epoch: 11 [6704/50000 (13%)]\tLoss: 0.627984\n",
            "Train Epoch: 11 [7184/50000 (14%)]\tLoss: 0.745655\n",
            "Train Epoch: 11 [7664/50000 (15%)]\tLoss: 0.684780\n",
            "Train Epoch: 11 [8144/50000 (16%)]\tLoss: 0.601360\n",
            "Train Epoch: 11 [8624/50000 (17%)]\tLoss: 0.764442\n",
            "Train Epoch: 11 [9104/50000 (18%)]\tLoss: 0.498237\n",
            "Train Epoch: 11 [9584/50000 (19%)]\tLoss: 0.797782\n",
            "Train Epoch: 11 [10064/50000 (20%)]\tLoss: 0.447485\n",
            "Train Epoch: 11 [10544/50000 (21%)]\tLoss: 0.822370\n",
            "Train Epoch: 11 [11024/50000 (22%)]\tLoss: 0.710635\n",
            "Train Epoch: 11 [11504/50000 (23%)]\tLoss: 0.772316\n",
            "Train Epoch: 11 [11984/50000 (24%)]\tLoss: 0.353085\n",
            "Train Epoch: 11 [12464/50000 (25%)]\tLoss: 0.409973\n",
            "Train Epoch: 11 [12944/50000 (26%)]\tLoss: 0.858909\n",
            "Train Epoch: 11 [13424/50000 (27%)]\tLoss: 0.544404\n",
            "Train Epoch: 11 [13904/50000 (28%)]\tLoss: 0.194407\n",
            "Train Epoch: 11 [14384/50000 (29%)]\tLoss: 1.048731\n",
            "Train Epoch: 11 [14864/50000 (30%)]\tLoss: 0.522889\n",
            "Train Epoch: 11 [15344/50000 (31%)]\tLoss: 0.534837\n",
            "Train Epoch: 11 [15824/50000 (32%)]\tLoss: 0.870302\n",
            "Train Epoch: 11 [16304/50000 (33%)]\tLoss: 0.552968\n",
            "Train Epoch: 11 [16784/50000 (34%)]\tLoss: 0.870097\n",
            "Train Epoch: 11 [17264/50000 (35%)]\tLoss: 0.775908\n",
            "Train Epoch: 11 [17744/50000 (35%)]\tLoss: 0.447660\n",
            "Train Epoch: 11 [18224/50000 (36%)]\tLoss: 0.815536\n",
            "Train Epoch: 11 [18704/50000 (37%)]\tLoss: 0.349094\n",
            "Train Epoch: 11 [19184/50000 (38%)]\tLoss: 0.955459\n",
            "Train Epoch: 11 [19664/50000 (39%)]\tLoss: 0.458827\n",
            "Train Epoch: 11 [20144/50000 (40%)]\tLoss: 0.457399\n",
            "Train Epoch: 11 [20624/50000 (41%)]\tLoss: 0.893393\n",
            "Train Epoch: 11 [21104/50000 (42%)]\tLoss: 0.671096\n",
            "Train Epoch: 11 [21584/50000 (43%)]\tLoss: 0.437685\n",
            "Train Epoch: 11 [22064/50000 (44%)]\tLoss: 0.673023\n",
            "Train Epoch: 11 [22544/50000 (45%)]\tLoss: 0.691261\n",
            "Train Epoch: 11 [23024/50000 (46%)]\tLoss: 0.461387\n",
            "Train Epoch: 11 [23504/50000 (47%)]\tLoss: 0.583797\n",
            "Train Epoch: 11 [23984/50000 (48%)]\tLoss: 0.481984\n",
            "Train Epoch: 11 [24464/50000 (49%)]\tLoss: 0.341756\n",
            "Train Epoch: 11 [24944/50000 (50%)]\tLoss: 0.390080\n",
            "Train Epoch: 11 [25424/50000 (51%)]\tLoss: 0.704892\n",
            "Train Epoch: 11 [25904/50000 (52%)]\tLoss: 0.727424\n",
            "Train Epoch: 11 [26384/50000 (53%)]\tLoss: 0.607933\n",
            "Train Epoch: 11 [26864/50000 (54%)]\tLoss: 0.585138\n",
            "Train Epoch: 11 [27344/50000 (55%)]\tLoss: 1.098034\n",
            "Train Epoch: 11 [27824/50000 (56%)]\tLoss: 0.273162\n",
            "Train Epoch: 11 [28304/50000 (57%)]\tLoss: 0.434968\n",
            "Train Epoch: 11 [28784/50000 (58%)]\tLoss: 0.964627\n",
            "Train Epoch: 11 [29264/50000 (59%)]\tLoss: 0.954209\n",
            "Train Epoch: 11 [29744/50000 (59%)]\tLoss: 1.190861\n",
            "Train Epoch: 11 [30224/50000 (60%)]\tLoss: 0.680372\n",
            "Train Epoch: 11 [30704/50000 (61%)]\tLoss: 0.320834\n",
            "Train Epoch: 11 [31184/50000 (62%)]\tLoss: 0.287962\n",
            "Train Epoch: 11 [31664/50000 (63%)]\tLoss: 0.892358\n",
            "Train Epoch: 11 [32144/50000 (64%)]\tLoss: 0.458811\n",
            "Train Epoch: 11 [32624/50000 (65%)]\tLoss: 0.768091\n",
            "Train Epoch: 11 [33104/50000 (66%)]\tLoss: 0.335933\n",
            "Train Epoch: 11 [33584/50000 (67%)]\tLoss: 0.406772\n",
            "Train Epoch: 11 [34064/50000 (68%)]\tLoss: 0.412212\n",
            "Train Epoch: 11 [34544/50000 (69%)]\tLoss: 0.559523\n",
            "Train Epoch: 11 [35024/50000 (70%)]\tLoss: 0.524356\n",
            "Train Epoch: 11 [35504/50000 (71%)]\tLoss: 0.861873\n",
            "Train Epoch: 11 [35984/50000 (72%)]\tLoss: 0.472922\n",
            "Train Epoch: 11 [36464/50000 (73%)]\tLoss: 0.328802\n",
            "Train Epoch: 11 [36944/50000 (74%)]\tLoss: 0.379619\n",
            "Train Epoch: 11 [37424/50000 (75%)]\tLoss: 0.469788\n",
            "Train Epoch: 11 [37904/50000 (76%)]\tLoss: 0.576123\n",
            "Train Epoch: 11 [38384/50000 (77%)]\tLoss: 0.572612\n",
            "Train Epoch: 11 [38864/50000 (78%)]\tLoss: 0.849096\n",
            "Train Epoch: 11 [39344/50000 (79%)]\tLoss: 0.606216\n",
            "Train Epoch: 11 [39824/50000 (80%)]\tLoss: 0.348828\n",
            "Train Epoch: 11 [40304/50000 (81%)]\tLoss: 0.652628\n",
            "Train Epoch: 11 [40784/50000 (82%)]\tLoss: 0.885877\n",
            "Train Epoch: 11 [41264/50000 (83%)]\tLoss: 0.426847\n",
            "Train Epoch: 11 [41744/50000 (83%)]\tLoss: 0.417737\n",
            "Train Epoch: 11 [42224/50000 (84%)]\tLoss: 0.633095\n",
            "Train Epoch: 11 [42704/50000 (85%)]\tLoss: 0.748749\n",
            "Train Epoch: 11 [43184/50000 (86%)]\tLoss: 1.159207\n",
            "Train Epoch: 11 [43664/50000 (87%)]\tLoss: 0.510229\n",
            "Train Epoch: 11 [44144/50000 (88%)]\tLoss: 0.383095\n",
            "Train Epoch: 11 [44624/50000 (89%)]\tLoss: 0.354953\n",
            "Train Epoch: 11 [45104/50000 (90%)]\tLoss: 0.349212\n",
            "Train Epoch: 11 [45584/50000 (91%)]\tLoss: 0.619132\n",
            "Train Epoch: 11 [46064/50000 (92%)]\tLoss: 0.717828\n",
            "Train Epoch: 11 [46544/50000 (93%)]\tLoss: 0.210181\n",
            "Train Epoch: 11 [47024/50000 (94%)]\tLoss: 0.592653\n",
            "Train Epoch: 11 [47504/50000 (95%)]\tLoss: 0.395905\n",
            "Train Epoch: 11 [47984/50000 (96%)]\tLoss: 0.516884\n",
            "Train Epoch: 11 [48464/50000 (97%)]\tLoss: 0.378561\n",
            "Train Epoch: 11 [48944/50000 (98%)]\tLoss: 0.435898\n",
            "Train Epoch: 11 [49424/50000 (99%)]\tLoss: 0.351709\n",
            "Train Epoch: 11 [49904/50000 (100%)]\tLoss: 0.476439\n",
            "---------------------------------------\n",
            "Training time for epoch 11: 199.35 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch11): Average loss: 0.5837, Accuracy: 7991/10000 (80%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 12 [464/50000 (1%)]\tLoss: 0.371231\n",
            "Train Epoch: 12 [944/50000 (2%)]\tLoss: 0.419657\n",
            "Train Epoch: 12 [1424/50000 (3%)]\tLoss: 0.376624\n",
            "Train Epoch: 12 [1904/50000 (4%)]\tLoss: 0.437791\n",
            "Train Epoch: 12 [2384/50000 (5%)]\tLoss: 0.626708\n",
            "Train Epoch: 12 [2864/50000 (6%)]\tLoss: 1.217298\n",
            "Train Epoch: 12 [3344/50000 (7%)]\tLoss: 0.661518\n",
            "Train Epoch: 12 [3824/50000 (8%)]\tLoss: 0.380478\n",
            "Train Epoch: 12 [4304/50000 (9%)]\tLoss: 0.401663\n",
            "Train Epoch: 12 [4784/50000 (10%)]\tLoss: 0.603038\n",
            "Train Epoch: 12 [5264/50000 (11%)]\tLoss: 0.570662\n",
            "Train Epoch: 12 [5744/50000 (11%)]\tLoss: 0.286768\n",
            "Train Epoch: 12 [6224/50000 (12%)]\tLoss: 0.102229\n",
            "Train Epoch: 12 [6704/50000 (13%)]\tLoss: 0.798189\n",
            "Train Epoch: 12 [7184/50000 (14%)]\tLoss: 0.591293\n",
            "Train Epoch: 12 [7664/50000 (15%)]\tLoss: 0.964152\n",
            "Train Epoch: 12 [8144/50000 (16%)]\tLoss: 0.839374\n",
            "Train Epoch: 12 [8624/50000 (17%)]\tLoss: 0.370826\n",
            "Train Epoch: 12 [9104/50000 (18%)]\tLoss: 0.644089\n",
            "Train Epoch: 12 [9584/50000 (19%)]\tLoss: 0.447173\n",
            "Train Epoch: 12 [10064/50000 (20%)]\tLoss: 0.606495\n",
            "Train Epoch: 12 [10544/50000 (21%)]\tLoss: 0.304462\n",
            "Train Epoch: 12 [11024/50000 (22%)]\tLoss: 0.356646\n",
            "Train Epoch: 12 [11504/50000 (23%)]\tLoss: 0.515503\n",
            "Train Epoch: 12 [11984/50000 (24%)]\tLoss: 0.346772\n",
            "Train Epoch: 12 [12464/50000 (25%)]\tLoss: 1.104370\n",
            "Train Epoch: 12 [12944/50000 (26%)]\tLoss: 0.697940\n",
            "Train Epoch: 12 [13424/50000 (27%)]\tLoss: 0.412434\n",
            "Train Epoch: 12 [13904/50000 (28%)]\tLoss: 0.565224\n",
            "Train Epoch: 12 [14384/50000 (29%)]\tLoss: 0.642200\n",
            "Train Epoch: 12 [14864/50000 (30%)]\tLoss: 0.704873\n",
            "Train Epoch: 12 [15344/50000 (31%)]\tLoss: 0.201681\n",
            "Train Epoch: 12 [15824/50000 (32%)]\tLoss: 0.731762\n",
            "Train Epoch: 12 [16304/50000 (33%)]\tLoss: 0.555388\n",
            "Train Epoch: 12 [16784/50000 (34%)]\tLoss: 0.658489\n",
            "Train Epoch: 12 [17264/50000 (35%)]\tLoss: 0.239970\n",
            "Train Epoch: 12 [17744/50000 (35%)]\tLoss: 0.513639\n",
            "Train Epoch: 12 [18224/50000 (36%)]\tLoss: 0.217076\n",
            "Train Epoch: 12 [18704/50000 (37%)]\tLoss: 0.845125\n",
            "Train Epoch: 12 [19184/50000 (38%)]\tLoss: 0.593816\n",
            "Train Epoch: 12 [19664/50000 (39%)]\tLoss: 0.730246\n",
            "Train Epoch: 12 [20144/50000 (40%)]\tLoss: 0.446840\n",
            "Train Epoch: 12 [20624/50000 (41%)]\tLoss: 0.534419\n",
            "Train Epoch: 12 [21104/50000 (42%)]\tLoss: 0.559390\n",
            "Train Epoch: 12 [21584/50000 (43%)]\tLoss: 0.198655\n",
            "Train Epoch: 12 [22064/50000 (44%)]\tLoss: 0.809705\n",
            "Train Epoch: 12 [22544/50000 (45%)]\tLoss: 0.884111\n",
            "Train Epoch: 12 [23024/50000 (46%)]\tLoss: 0.846260\n",
            "Train Epoch: 12 [23504/50000 (47%)]\tLoss: 0.562140\n",
            "Train Epoch: 12 [23984/50000 (48%)]\tLoss: 0.465619\n",
            "Train Epoch: 12 [24464/50000 (49%)]\tLoss: 0.969832\n",
            "Train Epoch: 12 [24944/50000 (50%)]\tLoss: 0.805770\n",
            "Train Epoch: 12 [25424/50000 (51%)]\tLoss: 0.744513\n",
            "Train Epoch: 12 [25904/50000 (52%)]\tLoss: 0.657277\n",
            "Train Epoch: 12 [26384/50000 (53%)]\tLoss: 0.667720\n",
            "Train Epoch: 12 [26864/50000 (54%)]\tLoss: 0.196134\n",
            "Train Epoch: 12 [27344/50000 (55%)]\tLoss: 0.294585\n",
            "Train Epoch: 12 [27824/50000 (56%)]\tLoss: 0.639939\n",
            "Train Epoch: 12 [28304/50000 (57%)]\tLoss: 0.491944\n",
            "Train Epoch: 12 [28784/50000 (58%)]\tLoss: 0.402877\n",
            "Train Epoch: 12 [29264/50000 (59%)]\tLoss: 0.516001\n",
            "Train Epoch: 12 [29744/50000 (59%)]\tLoss: 0.559796\n",
            "Train Epoch: 12 [30224/50000 (60%)]\tLoss: 0.710073\n",
            "Train Epoch: 12 [30704/50000 (61%)]\tLoss: 0.748120\n",
            "Train Epoch: 12 [31184/50000 (62%)]\tLoss: 0.603808\n",
            "Train Epoch: 12 [31664/50000 (63%)]\tLoss: 0.495513\n",
            "Train Epoch: 12 [32144/50000 (64%)]\tLoss: 0.330227\n",
            "Train Epoch: 12 [32624/50000 (65%)]\tLoss: 0.718839\n",
            "Train Epoch: 12 [33104/50000 (66%)]\tLoss: 0.444936\n",
            "Train Epoch: 12 [33584/50000 (67%)]\tLoss: 0.497466\n",
            "Train Epoch: 12 [34064/50000 (68%)]\tLoss: 0.539627\n",
            "Train Epoch: 12 [34544/50000 (69%)]\tLoss: 0.345763\n",
            "Train Epoch: 12 [35024/50000 (70%)]\tLoss: 0.743704\n",
            "Train Epoch: 12 [35504/50000 (71%)]\tLoss: 0.433743\n",
            "Train Epoch: 12 [35984/50000 (72%)]\tLoss: 0.381745\n",
            "Train Epoch: 12 [36464/50000 (73%)]\tLoss: 0.161660\n",
            "Train Epoch: 12 [36944/50000 (74%)]\tLoss: 0.538406\n",
            "Train Epoch: 12 [37424/50000 (75%)]\tLoss: 0.917339\n",
            "Train Epoch: 12 [37904/50000 (76%)]\tLoss: 0.393121\n",
            "Train Epoch: 12 [38384/50000 (77%)]\tLoss: 0.488328\n",
            "Train Epoch: 12 [38864/50000 (78%)]\tLoss: 0.595708\n",
            "Train Epoch: 12 [39344/50000 (79%)]\tLoss: 0.315708\n",
            "Train Epoch: 12 [39824/50000 (80%)]\tLoss: 0.461202\n",
            "Train Epoch: 12 [40304/50000 (81%)]\tLoss: 0.597318\n",
            "Train Epoch: 12 [40784/50000 (82%)]\tLoss: 0.376731\n",
            "Train Epoch: 12 [41264/50000 (83%)]\tLoss: 0.302435\n",
            "Train Epoch: 12 [41744/50000 (83%)]\tLoss: 0.609169\n",
            "Train Epoch: 12 [42224/50000 (84%)]\tLoss: 0.874574\n",
            "Train Epoch: 12 [42704/50000 (85%)]\tLoss: 0.463747\n",
            "Train Epoch: 12 [43184/50000 (86%)]\tLoss: 0.782057\n",
            "Train Epoch: 12 [43664/50000 (87%)]\tLoss: 0.508065\n",
            "Train Epoch: 12 [44144/50000 (88%)]\tLoss: 0.871248\n",
            "Train Epoch: 12 [44624/50000 (89%)]\tLoss: 0.396801\n",
            "Train Epoch: 12 [45104/50000 (90%)]\tLoss: 0.191885\n",
            "Train Epoch: 12 [45584/50000 (91%)]\tLoss: 0.478961\n",
            "Train Epoch: 12 [46064/50000 (92%)]\tLoss: 0.789802\n",
            "Train Epoch: 12 [46544/50000 (93%)]\tLoss: 0.422831\n",
            "Train Epoch: 12 [47024/50000 (94%)]\tLoss: 0.556090\n",
            "Train Epoch: 12 [47504/50000 (95%)]\tLoss: 0.352033\n",
            "Train Epoch: 12 [47984/50000 (96%)]\tLoss: 0.254664\n",
            "Train Epoch: 12 [48464/50000 (97%)]\tLoss: 0.691930\n",
            "Train Epoch: 12 [48944/50000 (98%)]\tLoss: 0.373815\n",
            "Train Epoch: 12 [49424/50000 (99%)]\tLoss: 0.306472\n",
            "Train Epoch: 12 [49904/50000 (100%)]\tLoss: 0.174543\n",
            "---------------------------------------\n",
            "Training time for epoch 12: 201.89 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch12): Average loss: 0.5636, Accuracy: 8102/10000 (81%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 13 [464/50000 (1%)]\tLoss: 0.653661\n",
            "Train Epoch: 13 [944/50000 (2%)]\tLoss: 0.209683\n",
            "Train Epoch: 13 [1424/50000 (3%)]\tLoss: 0.105565\n",
            "Train Epoch: 13 [1904/50000 (4%)]\tLoss: 0.875308\n",
            "Train Epoch: 13 [2384/50000 (5%)]\tLoss: 0.504283\n",
            "Train Epoch: 13 [2864/50000 (6%)]\tLoss: 0.814535\n",
            "Train Epoch: 13 [3344/50000 (7%)]\tLoss: 0.775382\n",
            "Train Epoch: 13 [3824/50000 (8%)]\tLoss: 0.583601\n",
            "Train Epoch: 13 [4304/50000 (9%)]\tLoss: 0.381929\n",
            "Train Epoch: 13 [4784/50000 (10%)]\tLoss: 0.258109\n",
            "Train Epoch: 13 [5264/50000 (11%)]\tLoss: 0.811595\n",
            "Train Epoch: 13 [5744/50000 (11%)]\tLoss: 0.616307\n",
            "Train Epoch: 13 [6224/50000 (12%)]\tLoss: 0.380938\n",
            "Train Epoch: 13 [6704/50000 (13%)]\tLoss: 0.722052\n",
            "Train Epoch: 13 [7184/50000 (14%)]\tLoss: 0.407469\n",
            "Train Epoch: 13 [7664/50000 (15%)]\tLoss: 0.201941\n",
            "Train Epoch: 13 [8144/50000 (16%)]\tLoss: 0.387932\n",
            "Train Epoch: 13 [8624/50000 (17%)]\tLoss: 0.533961\n",
            "Train Epoch: 13 [9104/50000 (18%)]\tLoss: 0.460448\n",
            "Train Epoch: 13 [9584/50000 (19%)]\tLoss: 0.491103\n",
            "Train Epoch: 13 [10064/50000 (20%)]\tLoss: 0.454405\n",
            "Train Epoch: 13 [10544/50000 (21%)]\tLoss: 0.518158\n",
            "Train Epoch: 13 [11024/50000 (22%)]\tLoss: 0.506517\n",
            "Train Epoch: 13 [11504/50000 (23%)]\tLoss: 0.428914\n",
            "Train Epoch: 13 [11984/50000 (24%)]\tLoss: 0.227283\n",
            "Train Epoch: 13 [12464/50000 (25%)]\tLoss: 0.599969\n",
            "Train Epoch: 13 [12944/50000 (26%)]\tLoss: 0.491005\n",
            "Train Epoch: 13 [13424/50000 (27%)]\tLoss: 0.334441\n",
            "Train Epoch: 13 [13904/50000 (28%)]\tLoss: 0.642065\n",
            "Train Epoch: 13 [14384/50000 (29%)]\tLoss: 0.473076\n",
            "Train Epoch: 13 [14864/50000 (30%)]\tLoss: 0.320988\n",
            "Train Epoch: 13 [15344/50000 (31%)]\tLoss: 0.401016\n",
            "Train Epoch: 13 [15824/50000 (32%)]\tLoss: 0.748104\n",
            "Train Epoch: 13 [16304/50000 (33%)]\tLoss: 0.509819\n",
            "Train Epoch: 13 [16784/50000 (34%)]\tLoss: 0.226156\n",
            "Train Epoch: 13 [17264/50000 (35%)]\tLoss: 0.477089\n",
            "Train Epoch: 13 [17744/50000 (35%)]\tLoss: 0.431786\n",
            "Train Epoch: 13 [18224/50000 (36%)]\tLoss: 0.757787\n",
            "Train Epoch: 13 [18704/50000 (37%)]\tLoss: 0.513798\n",
            "Train Epoch: 13 [19184/50000 (38%)]\tLoss: 0.435454\n",
            "Train Epoch: 13 [19664/50000 (39%)]\tLoss: 0.393568\n",
            "Train Epoch: 13 [20144/50000 (40%)]\tLoss: 0.378181\n",
            "Train Epoch: 13 [20624/50000 (41%)]\tLoss: 0.558235\n",
            "Train Epoch: 13 [21104/50000 (42%)]\tLoss: 0.428469\n",
            "Train Epoch: 13 [21584/50000 (43%)]\tLoss: 0.756970\n",
            "Train Epoch: 13 [22064/50000 (44%)]\tLoss: 0.443855\n",
            "Train Epoch: 13 [22544/50000 (45%)]\tLoss: 0.494677\n",
            "Train Epoch: 13 [23024/50000 (46%)]\tLoss: 0.320105\n",
            "Train Epoch: 13 [23504/50000 (47%)]\tLoss: 0.286370\n",
            "Train Epoch: 13 [23984/50000 (48%)]\tLoss: 0.693419\n",
            "Train Epoch: 13 [24464/50000 (49%)]\tLoss: 0.614329\n",
            "Train Epoch: 13 [24944/50000 (50%)]\tLoss: 0.384990\n",
            "Train Epoch: 13 [25424/50000 (51%)]\tLoss: 0.523736\n",
            "Train Epoch: 13 [25904/50000 (52%)]\tLoss: 0.397712\n",
            "Train Epoch: 13 [26384/50000 (53%)]\tLoss: 0.613377\n",
            "Train Epoch: 13 [26864/50000 (54%)]\tLoss: 0.467560\n",
            "Train Epoch: 13 [27344/50000 (55%)]\tLoss: 0.170478\n",
            "Train Epoch: 13 [27824/50000 (56%)]\tLoss: 0.546654\n",
            "Train Epoch: 13 [28304/50000 (57%)]\tLoss: 0.489187\n",
            "Train Epoch: 13 [28784/50000 (58%)]\tLoss: 0.744217\n",
            "Train Epoch: 13 [29264/50000 (59%)]\tLoss: 0.897988\n",
            "Train Epoch: 13 [29744/50000 (59%)]\tLoss: 0.194574\n",
            "Train Epoch: 13 [30224/50000 (60%)]\tLoss: 1.046303\n",
            "Train Epoch: 13 [30704/50000 (61%)]\tLoss: 1.022960\n",
            "Train Epoch: 13 [31184/50000 (62%)]\tLoss: 0.396113\n",
            "Train Epoch: 13 [31664/50000 (63%)]\tLoss: 0.271641\n",
            "Train Epoch: 13 [32144/50000 (64%)]\tLoss: 0.818378\n",
            "Train Epoch: 13 [32624/50000 (65%)]\tLoss: 0.569466\n",
            "Train Epoch: 13 [33104/50000 (66%)]\tLoss: 0.845855\n",
            "Train Epoch: 13 [33584/50000 (67%)]\tLoss: 0.152984\n",
            "Train Epoch: 13 [34064/50000 (68%)]\tLoss: 0.928883\n",
            "Train Epoch: 13 [34544/50000 (69%)]\tLoss: 0.648026\n",
            "Train Epoch: 13 [35024/50000 (70%)]\tLoss: 0.975062\n",
            "Train Epoch: 13 [35504/50000 (71%)]\tLoss: 0.118681\n",
            "Train Epoch: 13 [35984/50000 (72%)]\tLoss: 0.858211\n",
            "Train Epoch: 13 [36464/50000 (73%)]\tLoss: 0.479376\n",
            "Train Epoch: 13 [36944/50000 (74%)]\tLoss: 0.531359\n",
            "Train Epoch: 13 [37424/50000 (75%)]\tLoss: 0.534348\n",
            "Train Epoch: 13 [37904/50000 (76%)]\tLoss: 0.349795\n",
            "Train Epoch: 13 [38384/50000 (77%)]\tLoss: 0.283373\n",
            "Train Epoch: 13 [38864/50000 (78%)]\tLoss: 0.908695\n",
            "Train Epoch: 13 [39344/50000 (79%)]\tLoss: 0.622024\n",
            "Train Epoch: 13 [39824/50000 (80%)]\tLoss: 0.091664\n",
            "Train Epoch: 13 [40304/50000 (81%)]\tLoss: 0.771483\n",
            "Train Epoch: 13 [40784/50000 (82%)]\tLoss: 0.686987\n",
            "Train Epoch: 13 [41264/50000 (83%)]\tLoss: 0.600972\n",
            "Train Epoch: 13 [41744/50000 (83%)]\tLoss: 0.772534\n",
            "Train Epoch: 13 [42224/50000 (84%)]\tLoss: 0.650631\n",
            "Train Epoch: 13 [42704/50000 (85%)]\tLoss: 0.445211\n",
            "Train Epoch: 13 [43184/50000 (86%)]\tLoss: 0.535347\n",
            "Train Epoch: 13 [43664/50000 (87%)]\tLoss: 0.365746\n",
            "Train Epoch: 13 [44144/50000 (88%)]\tLoss: 0.310008\n",
            "Train Epoch: 13 [44624/50000 (89%)]\tLoss: 0.322018\n",
            "Train Epoch: 13 [45104/50000 (90%)]\tLoss: 0.474320\n",
            "Train Epoch: 13 [45584/50000 (91%)]\tLoss: 1.158488\n",
            "Train Epoch: 13 [46064/50000 (92%)]\tLoss: 0.754325\n",
            "Train Epoch: 13 [46544/50000 (93%)]\tLoss: 0.252101\n",
            "Train Epoch: 13 [47024/50000 (94%)]\tLoss: 0.652672\n",
            "Train Epoch: 13 [47504/50000 (95%)]\tLoss: 0.943829\n",
            "Train Epoch: 13 [47984/50000 (96%)]\tLoss: 0.873077\n",
            "Train Epoch: 13 [48464/50000 (97%)]\tLoss: 0.233918\n",
            "Train Epoch: 13 [48944/50000 (98%)]\tLoss: 0.865857\n",
            "Train Epoch: 13 [49424/50000 (99%)]\tLoss: 0.521619\n",
            "Train Epoch: 13 [49904/50000 (100%)]\tLoss: 0.692725\n",
            "---------------------------------------\n",
            "Training time for epoch 13: 199.50 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch13): Average loss: 0.5649, Accuracy: 8095/10000 (81%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 14 [464/50000 (1%)]\tLoss: 0.463293\n",
            "Train Epoch: 14 [944/50000 (2%)]\tLoss: 0.582810\n",
            "Train Epoch: 14 [1424/50000 (3%)]\tLoss: 0.581335\n",
            "Train Epoch: 14 [1904/50000 (4%)]\tLoss: 0.538791\n",
            "Train Epoch: 14 [2384/50000 (5%)]\tLoss: 0.409093\n",
            "Train Epoch: 14 [2864/50000 (6%)]\tLoss: 0.709064\n",
            "Train Epoch: 14 [3344/50000 (7%)]\tLoss: 0.606506\n",
            "Train Epoch: 14 [3824/50000 (8%)]\tLoss: 0.483132\n",
            "Train Epoch: 14 [4304/50000 (9%)]\tLoss: 0.322249\n",
            "Train Epoch: 14 [4784/50000 (10%)]\tLoss: 0.166195\n",
            "Train Epoch: 14 [5264/50000 (11%)]\tLoss: 0.634356\n",
            "Train Epoch: 14 [5744/50000 (11%)]\tLoss: 0.467306\n",
            "Train Epoch: 14 [6224/50000 (12%)]\tLoss: 0.670295\n",
            "Train Epoch: 14 [6704/50000 (13%)]\tLoss: 0.964536\n",
            "Train Epoch: 14 [7184/50000 (14%)]\tLoss: 0.560863\n",
            "Train Epoch: 14 [7664/50000 (15%)]\tLoss: 0.326651\n",
            "Train Epoch: 14 [8144/50000 (16%)]\tLoss: 0.425979\n",
            "Train Epoch: 14 [8624/50000 (17%)]\tLoss: 0.445113\n",
            "Train Epoch: 14 [9104/50000 (18%)]\tLoss: 0.620722\n",
            "Train Epoch: 14 [9584/50000 (19%)]\tLoss: 0.611655\n",
            "Train Epoch: 14 [10064/50000 (20%)]\tLoss: 0.360038\n",
            "Train Epoch: 14 [10544/50000 (21%)]\tLoss: 0.487411\n",
            "Train Epoch: 14 [11024/50000 (22%)]\tLoss: 0.341686\n",
            "Train Epoch: 14 [11504/50000 (23%)]\tLoss: 0.456953\n",
            "Train Epoch: 14 [11984/50000 (24%)]\tLoss: 0.477118\n",
            "Train Epoch: 14 [12464/50000 (25%)]\tLoss: 0.166518\n",
            "Train Epoch: 14 [12944/50000 (26%)]\tLoss: 0.365132\n",
            "Train Epoch: 14 [13424/50000 (27%)]\tLoss: 0.531021\n",
            "Train Epoch: 14 [13904/50000 (28%)]\tLoss: 0.261446\n",
            "Train Epoch: 14 [14384/50000 (29%)]\tLoss: 0.598641\n",
            "Train Epoch: 14 [14864/50000 (30%)]\tLoss: 0.444772\n",
            "Train Epoch: 14 [15344/50000 (31%)]\tLoss: 0.672584\n",
            "Train Epoch: 14 [15824/50000 (32%)]\tLoss: 0.626931\n",
            "Train Epoch: 14 [16304/50000 (33%)]\tLoss: 0.460292\n",
            "Train Epoch: 14 [16784/50000 (34%)]\tLoss: 0.259191\n",
            "Train Epoch: 14 [17264/50000 (35%)]\tLoss: 0.436533\n",
            "Train Epoch: 14 [17744/50000 (35%)]\tLoss: 0.435725\n",
            "Train Epoch: 14 [18224/50000 (36%)]\tLoss: 1.001295\n",
            "Train Epoch: 14 [18704/50000 (37%)]\tLoss: 0.310968\n",
            "Train Epoch: 14 [19184/50000 (38%)]\tLoss: 0.384597\n",
            "Train Epoch: 14 [19664/50000 (39%)]\tLoss: 0.535312\n",
            "Train Epoch: 14 [20144/50000 (40%)]\tLoss: 0.209956\n",
            "Train Epoch: 14 [20624/50000 (41%)]\tLoss: 0.663687\n",
            "Train Epoch: 14 [21104/50000 (42%)]\tLoss: 0.210274\n",
            "Train Epoch: 14 [21584/50000 (43%)]\tLoss: 0.302140\n",
            "Train Epoch: 14 [22064/50000 (44%)]\tLoss: 0.225865\n",
            "Train Epoch: 14 [22544/50000 (45%)]\tLoss: 0.641388\n",
            "Train Epoch: 14 [23024/50000 (46%)]\tLoss: 0.579924\n",
            "Train Epoch: 14 [23504/50000 (47%)]\tLoss: 0.387125\n",
            "Train Epoch: 14 [23984/50000 (48%)]\tLoss: 0.805523\n",
            "Train Epoch: 14 [24464/50000 (49%)]\tLoss: 0.541428\n",
            "Train Epoch: 14 [24944/50000 (50%)]\tLoss: 0.661198\n",
            "Train Epoch: 14 [25424/50000 (51%)]\tLoss: 0.370267\n",
            "Train Epoch: 14 [25904/50000 (52%)]\tLoss: 0.262055\n",
            "Train Epoch: 14 [26384/50000 (53%)]\tLoss: 0.470738\n",
            "Train Epoch: 14 [26864/50000 (54%)]\tLoss: 0.330959\n",
            "Train Epoch: 14 [27344/50000 (55%)]\tLoss: 0.096885\n",
            "Train Epoch: 14 [27824/50000 (56%)]\tLoss: 0.347074\n",
            "Train Epoch: 14 [28304/50000 (57%)]\tLoss: 0.707377\n",
            "Train Epoch: 14 [28784/50000 (58%)]\tLoss: 0.761434\n",
            "Train Epoch: 14 [29264/50000 (59%)]\tLoss: 0.154827\n",
            "Train Epoch: 14 [29744/50000 (59%)]\tLoss: 0.269854\n",
            "Train Epoch: 14 [30224/50000 (60%)]\tLoss: 0.292177\n",
            "Train Epoch: 14 [30704/50000 (61%)]\tLoss: 0.709753\n",
            "Train Epoch: 14 [31184/50000 (62%)]\tLoss: 0.212273\n",
            "Train Epoch: 14 [31664/50000 (63%)]\tLoss: 0.324868\n",
            "Train Epoch: 14 [32144/50000 (64%)]\tLoss: 0.376799\n",
            "Train Epoch: 14 [32624/50000 (65%)]\tLoss: 0.502534\n",
            "Train Epoch: 14 [33104/50000 (66%)]\tLoss: 0.553097\n",
            "Train Epoch: 14 [33584/50000 (67%)]\tLoss: 0.613376\n",
            "Train Epoch: 14 [34064/50000 (68%)]\tLoss: 0.148342\n",
            "Train Epoch: 14 [34544/50000 (69%)]\tLoss: 0.326036\n",
            "Train Epoch: 14 [35024/50000 (70%)]\tLoss: 0.867714\n",
            "Train Epoch: 14 [35504/50000 (71%)]\tLoss: 0.360583\n",
            "Train Epoch: 14 [35984/50000 (72%)]\tLoss: 0.499283\n",
            "Train Epoch: 14 [36464/50000 (73%)]\tLoss: 0.706204\n",
            "Train Epoch: 14 [36944/50000 (74%)]\tLoss: 0.886059\n",
            "Train Epoch: 14 [37424/50000 (75%)]\tLoss: 0.403201\n",
            "Train Epoch: 14 [37904/50000 (76%)]\tLoss: 0.618641\n",
            "Train Epoch: 14 [38384/50000 (77%)]\tLoss: 0.700985\n",
            "Train Epoch: 14 [38864/50000 (78%)]\tLoss: 0.673300\n",
            "Train Epoch: 14 [39344/50000 (79%)]\tLoss: 0.439021\n",
            "Train Epoch: 14 [39824/50000 (80%)]\tLoss: 0.429230\n",
            "Train Epoch: 14 [40304/50000 (81%)]\tLoss: 0.301095\n",
            "Train Epoch: 14 [40784/50000 (82%)]\tLoss: 0.467518\n",
            "Train Epoch: 14 [41264/50000 (83%)]\tLoss: 1.086740\n",
            "Train Epoch: 14 [41744/50000 (83%)]\tLoss: 0.476443\n",
            "Train Epoch: 14 [42224/50000 (84%)]\tLoss: 0.189816\n",
            "Train Epoch: 14 [42704/50000 (85%)]\tLoss: 0.271550\n",
            "Train Epoch: 14 [43184/50000 (86%)]\tLoss: 0.771926\n",
            "Train Epoch: 14 [43664/50000 (87%)]\tLoss: 0.342108\n",
            "Train Epoch: 14 [44144/50000 (88%)]\tLoss: 0.441969\n",
            "Train Epoch: 14 [44624/50000 (89%)]\tLoss: 0.531654\n",
            "Train Epoch: 14 [45104/50000 (90%)]\tLoss: 0.392820\n",
            "Train Epoch: 14 [45584/50000 (91%)]\tLoss: 0.466051\n",
            "Train Epoch: 14 [46064/50000 (92%)]\tLoss: 0.448417\n",
            "Train Epoch: 14 [46544/50000 (93%)]\tLoss: 0.732233\n",
            "Train Epoch: 14 [47024/50000 (94%)]\tLoss: 0.881387\n",
            "Train Epoch: 14 [47504/50000 (95%)]\tLoss: 0.605508\n",
            "Train Epoch: 14 [47984/50000 (96%)]\tLoss: 0.351687\n",
            "Train Epoch: 14 [48464/50000 (97%)]\tLoss: 0.568511\n",
            "Train Epoch: 14 [48944/50000 (98%)]\tLoss: 0.500481\n",
            "Train Epoch: 14 [49424/50000 (99%)]\tLoss: 0.367317\n",
            "Train Epoch: 14 [49904/50000 (100%)]\tLoss: 0.425444\n",
            "---------------------------------------\n",
            "Training time for epoch 14: 199.59 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch14): Average loss: 0.5250, Accuracy: 8238/10000 (82%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 15 [464/50000 (1%)]\tLoss: 0.322509\n",
            "Train Epoch: 15 [944/50000 (2%)]\tLoss: 0.750364\n",
            "Train Epoch: 15 [1424/50000 (3%)]\tLoss: 0.602375\n",
            "Train Epoch: 15 [1904/50000 (4%)]\tLoss: 0.635543\n",
            "Train Epoch: 15 [2384/50000 (5%)]\tLoss: 0.421672\n",
            "Train Epoch: 15 [2864/50000 (6%)]\tLoss: 0.691668\n",
            "Train Epoch: 15 [3344/50000 (7%)]\tLoss: 0.781678\n",
            "Train Epoch: 15 [3824/50000 (8%)]\tLoss: 0.368513\n",
            "Train Epoch: 15 [4304/50000 (9%)]\tLoss: 0.583274\n",
            "Train Epoch: 15 [4784/50000 (10%)]\tLoss: 0.284566\n",
            "Train Epoch: 15 [5264/50000 (11%)]\tLoss: 0.314454\n",
            "Train Epoch: 15 [5744/50000 (11%)]\tLoss: 0.373375\n",
            "Train Epoch: 15 [6224/50000 (12%)]\tLoss: 0.433783\n",
            "Train Epoch: 15 [6704/50000 (13%)]\tLoss: 0.929764\n",
            "Train Epoch: 15 [7184/50000 (14%)]\tLoss: 0.409278\n",
            "Train Epoch: 15 [7664/50000 (15%)]\tLoss: 0.439989\n",
            "Train Epoch: 15 [8144/50000 (16%)]\tLoss: 0.751287\n",
            "Train Epoch: 15 [8624/50000 (17%)]\tLoss: 0.433524\n",
            "Train Epoch: 15 [9104/50000 (18%)]\tLoss: 0.564377\n",
            "Train Epoch: 15 [9584/50000 (19%)]\tLoss: 0.521497\n",
            "Train Epoch: 15 [10064/50000 (20%)]\tLoss: 0.617054\n",
            "Train Epoch: 15 [10544/50000 (21%)]\tLoss: 0.307516\n",
            "Train Epoch: 15 [11024/50000 (22%)]\tLoss: 0.384066\n",
            "Train Epoch: 15 [11504/50000 (23%)]\tLoss: 0.695763\n",
            "Train Epoch: 15 [11984/50000 (24%)]\tLoss: 0.346032\n",
            "Train Epoch: 15 [12464/50000 (25%)]\tLoss: 0.596417\n",
            "Train Epoch: 15 [12944/50000 (26%)]\tLoss: 0.365847\n",
            "Train Epoch: 15 [13424/50000 (27%)]\tLoss: 0.355703\n",
            "Train Epoch: 15 [13904/50000 (28%)]\tLoss: 0.182608\n",
            "Train Epoch: 15 [14384/50000 (29%)]\tLoss: 0.474079\n",
            "Train Epoch: 15 [14864/50000 (30%)]\tLoss: 0.428204\n",
            "Train Epoch: 15 [15344/50000 (31%)]\tLoss: 0.587881\n",
            "Train Epoch: 15 [15824/50000 (32%)]\tLoss: 0.554835\n",
            "Train Epoch: 15 [16304/50000 (33%)]\tLoss: 0.547611\n",
            "Train Epoch: 15 [16784/50000 (34%)]\tLoss: 0.637619\n",
            "Train Epoch: 15 [17264/50000 (35%)]\tLoss: 0.379570\n",
            "Train Epoch: 15 [17744/50000 (35%)]\tLoss: 0.472073\n",
            "Train Epoch: 15 [18224/50000 (36%)]\tLoss: 0.331860\n",
            "Train Epoch: 15 [18704/50000 (37%)]\tLoss: 0.475238\n",
            "Train Epoch: 15 [19184/50000 (38%)]\tLoss: 0.361341\n",
            "Train Epoch: 15 [19664/50000 (39%)]\tLoss: 0.090731\n",
            "Train Epoch: 15 [20144/50000 (40%)]\tLoss: 0.597030\n",
            "Train Epoch: 15 [20624/50000 (41%)]\tLoss: 0.320758\n",
            "Train Epoch: 15 [21104/50000 (42%)]\tLoss: 0.421203\n",
            "Train Epoch: 15 [21584/50000 (43%)]\tLoss: 0.530978\n",
            "Train Epoch: 15 [22064/50000 (44%)]\tLoss: 0.433551\n",
            "Train Epoch: 15 [22544/50000 (45%)]\tLoss: 0.512054\n",
            "Train Epoch: 15 [23024/50000 (46%)]\tLoss: 0.358564\n",
            "Train Epoch: 15 [23504/50000 (47%)]\tLoss: 0.375904\n",
            "Train Epoch: 15 [23984/50000 (48%)]\tLoss: 0.484817\n",
            "Train Epoch: 15 [24464/50000 (49%)]\tLoss: 0.084509\n",
            "Train Epoch: 15 [24944/50000 (50%)]\tLoss: 0.234645\n",
            "Train Epoch: 15 [25424/50000 (51%)]\tLoss: 0.516581\n",
            "Train Epoch: 15 [25904/50000 (52%)]\tLoss: 1.312370\n",
            "Train Epoch: 15 [26384/50000 (53%)]\tLoss: 0.623761\n",
            "Train Epoch: 15 [26864/50000 (54%)]\tLoss: 0.559866\n",
            "Train Epoch: 15 [27344/50000 (55%)]\tLoss: 0.402429\n",
            "Train Epoch: 15 [27824/50000 (56%)]\tLoss: 0.384888\n",
            "Train Epoch: 15 [28304/50000 (57%)]\tLoss: 0.368370\n",
            "Train Epoch: 15 [28784/50000 (58%)]\tLoss: 0.823994\n",
            "Train Epoch: 15 [29264/50000 (59%)]\tLoss: 0.415862\n",
            "Train Epoch: 15 [29744/50000 (59%)]\tLoss: 0.323915\n",
            "Train Epoch: 15 [30224/50000 (60%)]\tLoss: 0.630268\n",
            "Train Epoch: 15 [30704/50000 (61%)]\tLoss: 0.227225\n",
            "Train Epoch: 15 [31184/50000 (62%)]\tLoss: 0.862054\n",
            "Train Epoch: 15 [31664/50000 (63%)]\tLoss: 0.237740\n",
            "Train Epoch: 15 [32144/50000 (64%)]\tLoss: 0.149967\n",
            "Train Epoch: 15 [32624/50000 (65%)]\tLoss: 0.621198\n",
            "Train Epoch: 15 [33104/50000 (66%)]\tLoss: 0.495223\n",
            "Train Epoch: 15 [33584/50000 (67%)]\tLoss: 0.430007\n",
            "Train Epoch: 15 [34064/50000 (68%)]\tLoss: 0.698892\n",
            "Train Epoch: 15 [34544/50000 (69%)]\tLoss: 0.409258\n",
            "Train Epoch: 15 [35024/50000 (70%)]\tLoss: 0.653158\n",
            "Train Epoch: 15 [35504/50000 (71%)]\tLoss: 0.464266\n",
            "Train Epoch: 15 [35984/50000 (72%)]\tLoss: 0.616966\n",
            "Train Epoch: 15 [36464/50000 (73%)]\tLoss: 0.376855\n",
            "Train Epoch: 15 [36944/50000 (74%)]\tLoss: 0.345969\n",
            "Train Epoch: 15 [37424/50000 (75%)]\tLoss: 0.476444\n",
            "Train Epoch: 15 [37904/50000 (76%)]\tLoss: 0.320242\n",
            "Train Epoch: 15 [38384/50000 (77%)]\tLoss: 0.764256\n",
            "Train Epoch: 15 [38864/50000 (78%)]\tLoss: 0.833759\n",
            "Train Epoch: 15 [39344/50000 (79%)]\tLoss: 0.506549\n",
            "Train Epoch: 15 [39824/50000 (80%)]\tLoss: 0.175937\n",
            "Train Epoch: 15 [40304/50000 (81%)]\tLoss: 0.450140\n",
            "Train Epoch: 15 [40784/50000 (82%)]\tLoss: 0.697028\n",
            "Train Epoch: 15 [41264/50000 (83%)]\tLoss: 0.852687\n",
            "Train Epoch: 15 [41744/50000 (83%)]\tLoss: 0.607460\n",
            "Train Epoch: 15 [42224/50000 (84%)]\tLoss: 0.750246\n",
            "Train Epoch: 15 [42704/50000 (85%)]\tLoss: 0.620807\n",
            "Train Epoch: 15 [43184/50000 (86%)]\tLoss: 0.516946\n",
            "Train Epoch: 15 [43664/50000 (87%)]\tLoss: 0.158693\n",
            "Train Epoch: 15 [44144/50000 (88%)]\tLoss: 0.213847\n",
            "Train Epoch: 15 [44624/50000 (89%)]\tLoss: 0.893796\n",
            "Train Epoch: 15 [45104/50000 (90%)]\tLoss: 0.588127\n",
            "Train Epoch: 15 [45584/50000 (91%)]\tLoss: 0.279871\n",
            "Train Epoch: 15 [46064/50000 (92%)]\tLoss: 0.298612\n",
            "Train Epoch: 15 [46544/50000 (93%)]\tLoss: 0.498835\n",
            "Train Epoch: 15 [47024/50000 (94%)]\tLoss: 0.441205\n",
            "Train Epoch: 15 [47504/50000 (95%)]\tLoss: 0.549809\n",
            "Train Epoch: 15 [47984/50000 (96%)]\tLoss: 0.354781\n",
            "Train Epoch: 15 [48464/50000 (97%)]\tLoss: 0.262946\n",
            "Train Epoch: 15 [48944/50000 (98%)]\tLoss: 0.894429\n",
            "Train Epoch: 15 [49424/50000 (99%)]\tLoss: 0.789373\n",
            "Train Epoch: 15 [49904/50000 (100%)]\tLoss: 0.238801\n",
            "---------------------------------------\n",
            "Training time for epoch 15: 199.98 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch15): Average loss: 0.5254, Accuracy: 8198/10000 (82%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "============================================\n",
            "Total training time for 15 epochs: 2999.67 seconds\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of Accuracies : (DCNN)"
      ],
      "metadata": {
        "id": "9SpqTz349gzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DCNN_ACC"
      ],
      "metadata": {
        "id": "p7vlRu1bc8eF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c839790-b2a1-43a1-af44-22dac6574ed3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[58.19,\n",
              " 64.48,\n",
              " 68.39,\n",
              " 71.58,\n",
              " 73.43,\n",
              " 74.96,\n",
              " 76.51,\n",
              " 78.13,\n",
              " 78.44,\n",
              " 79.81,\n",
              " 79.91,\n",
              " 81.02,\n",
              " 80.95,\n",
              " 82.38,\n",
              " 81.98]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model architecture for CIFAR-10\n",
        "class StandardConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StandardConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(64)\n",
        "        self.fc1   = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2   = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 64 * 8 * 8)  # Adjusted for CIFAR-10 image size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "total_training_time = 0.0  # Initialize total training time\n",
        "test_accuracies = []  # Store test accuracies for each epoch\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    global total_training_time  # Use the global variable\n",
        "    model.train()\n",
        "    start_time = time.time()  # Record the start time\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output       = model(data)\n",
        "        loss         = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 30 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "    end_time = time.time()  # Record the end time\n",
        "    elapsed_time = end_time - start_time\n",
        "    total_training_time += elapsed_time  # Update total training time\n",
        "    print('---------------------------------------')\n",
        "    print(f\"Training time for epoch {epoch}: {elapsed_time:.2f} seconds\")\n",
        "    print('---------------------------------------')\n",
        "\n",
        "\n",
        "CNN_ACC= []\n",
        "\n",
        "def test(model, device, test_loader, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct   = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output       = model(data)\n",
        "            test_loss   += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred         = output.max(1, keepdim=True)[1]\n",
        "            correct     += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('-------------------------------------------------------')\n",
        "    print('\\nTest set (epoch{}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        epoch, test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "    print('-------------------------------------------------------')\n",
        "    CNN_ACC.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "standard_model = StandardConvNet().to(device)\n",
        "\n",
        "# Define the optimizer for standard convolution\n",
        "standard_optimizer = optim.SGD(standard_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the standard convolutional neural network\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(standard_model, DEVICE, train_loader, standard_optimizer, epoch)\n",
        "    test(standard_model, DEVICE, test_loader, epoch)\n",
        "\n",
        "print('============================================')\n",
        "print(f\"Total training time for {EPOCHS} epochs (StandardConvNet): {total_training_time:.2f} seconds\")\n",
        "print('============================================')"
      ],
      "metadata": {
        "id": "RLWvX8qjTidh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6025b820-fef6-4d68-c9e3-875ee897eeb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [464/50000 (1%)]\tLoss: 2.225394\n",
            "Train Epoch: 1 [944/50000 (2%)]\tLoss: 1.902153\n",
            "Train Epoch: 1 [1424/50000 (3%)]\tLoss: 2.056979\n",
            "Train Epoch: 1 [1904/50000 (4%)]\tLoss: 2.023248\n",
            "Train Epoch: 1 [2384/50000 (5%)]\tLoss: 1.991672\n",
            "Train Epoch: 1 [2864/50000 (6%)]\tLoss: 1.583189\n",
            "Train Epoch: 1 [3344/50000 (7%)]\tLoss: 1.053714\n",
            "Train Epoch: 1 [3824/50000 (8%)]\tLoss: 1.670575\n",
            "Train Epoch: 1 [4304/50000 (9%)]\tLoss: 1.715505\n",
            "Train Epoch: 1 [4784/50000 (10%)]\tLoss: 1.826304\n",
            "Train Epoch: 1 [5264/50000 (11%)]\tLoss: 1.615642\n",
            "Train Epoch: 1 [5744/50000 (11%)]\tLoss: 1.345321\n",
            "Train Epoch: 1 [6224/50000 (12%)]\tLoss: 1.271609\n",
            "Train Epoch: 1 [6704/50000 (13%)]\tLoss: 1.955062\n",
            "Train Epoch: 1 [7184/50000 (14%)]\tLoss: 1.692585\n",
            "Train Epoch: 1 [7664/50000 (15%)]\tLoss: 1.647936\n",
            "Train Epoch: 1 [8144/50000 (16%)]\tLoss: 1.580677\n",
            "Train Epoch: 1 [8624/50000 (17%)]\tLoss: 1.177172\n",
            "Train Epoch: 1 [9104/50000 (18%)]\tLoss: 1.452598\n",
            "Train Epoch: 1 [9584/50000 (19%)]\tLoss: 1.454796\n",
            "Train Epoch: 1 [10064/50000 (20%)]\tLoss: 1.365168\n",
            "Train Epoch: 1 [10544/50000 (21%)]\tLoss: 0.924121\n",
            "Train Epoch: 1 [11024/50000 (22%)]\tLoss: 1.624455\n",
            "Train Epoch: 1 [11504/50000 (23%)]\tLoss: 1.081935\n",
            "Train Epoch: 1 [11984/50000 (24%)]\tLoss: 1.293220\n",
            "Train Epoch: 1 [12464/50000 (25%)]\tLoss: 1.879263\n",
            "Train Epoch: 1 [12944/50000 (26%)]\tLoss: 1.153440\n",
            "Train Epoch: 1 [13424/50000 (27%)]\tLoss: 1.293877\n",
            "Train Epoch: 1 [13904/50000 (28%)]\tLoss: 1.537051\n",
            "Train Epoch: 1 [14384/50000 (29%)]\tLoss: 1.713208\n",
            "Train Epoch: 1 [14864/50000 (30%)]\tLoss: 1.086622\n",
            "Train Epoch: 1 [15344/50000 (31%)]\tLoss: 1.433763\n",
            "Train Epoch: 1 [15824/50000 (32%)]\tLoss: 1.455982\n",
            "Train Epoch: 1 [16304/50000 (33%)]\tLoss: 1.404867\n",
            "Train Epoch: 1 [16784/50000 (34%)]\tLoss: 1.035997\n",
            "Train Epoch: 1 [17264/50000 (35%)]\tLoss: 1.375561\n",
            "Train Epoch: 1 [17744/50000 (35%)]\tLoss: 1.171345\n",
            "Train Epoch: 1 [18224/50000 (36%)]\tLoss: 1.084596\n",
            "Train Epoch: 1 [18704/50000 (37%)]\tLoss: 1.872087\n",
            "Train Epoch: 1 [19184/50000 (38%)]\tLoss: 1.506234\n",
            "Train Epoch: 1 [19664/50000 (39%)]\tLoss: 1.122973\n",
            "Train Epoch: 1 [20144/50000 (40%)]\tLoss: 1.628776\n",
            "Train Epoch: 1 [20624/50000 (41%)]\tLoss: 1.491915\n",
            "Train Epoch: 1 [21104/50000 (42%)]\tLoss: 1.348937\n",
            "Train Epoch: 1 [21584/50000 (43%)]\tLoss: 1.045231\n",
            "Train Epoch: 1 [22064/50000 (44%)]\tLoss: 0.972948\n",
            "Train Epoch: 1 [22544/50000 (45%)]\tLoss: 1.186039\n",
            "Train Epoch: 1 [23024/50000 (46%)]\tLoss: 1.242958\n",
            "Train Epoch: 1 [23504/50000 (47%)]\tLoss: 1.181672\n",
            "Train Epoch: 1 [23984/50000 (48%)]\tLoss: 1.272029\n",
            "Train Epoch: 1 [24464/50000 (49%)]\tLoss: 0.982840\n",
            "Train Epoch: 1 [24944/50000 (50%)]\tLoss: 1.210128\n",
            "Train Epoch: 1 [25424/50000 (51%)]\tLoss: 0.969125\n",
            "Train Epoch: 1 [25904/50000 (52%)]\tLoss: 1.210352\n",
            "Train Epoch: 1 [26384/50000 (53%)]\tLoss: 0.829445\n",
            "Train Epoch: 1 [26864/50000 (54%)]\tLoss: 1.247685\n",
            "Train Epoch: 1 [27344/50000 (55%)]\tLoss: 1.365336\n",
            "Train Epoch: 1 [27824/50000 (56%)]\tLoss: 1.213263\n",
            "Train Epoch: 1 [28304/50000 (57%)]\tLoss: 0.944331\n",
            "Train Epoch: 1 [28784/50000 (58%)]\tLoss: 1.386554\n",
            "Train Epoch: 1 [29264/50000 (59%)]\tLoss: 1.228068\n",
            "Train Epoch: 1 [29744/50000 (59%)]\tLoss: 1.453757\n",
            "Train Epoch: 1 [30224/50000 (60%)]\tLoss: 1.280748\n",
            "Train Epoch: 1 [30704/50000 (61%)]\tLoss: 1.188365\n",
            "Train Epoch: 1 [31184/50000 (62%)]\tLoss: 1.188347\n",
            "Train Epoch: 1 [31664/50000 (63%)]\tLoss: 0.946302\n",
            "Train Epoch: 1 [32144/50000 (64%)]\tLoss: 1.339484\n",
            "Train Epoch: 1 [32624/50000 (65%)]\tLoss: 1.102800\n",
            "Train Epoch: 1 [33104/50000 (66%)]\tLoss: 0.968363\n",
            "Train Epoch: 1 [33584/50000 (67%)]\tLoss: 1.151038\n",
            "Train Epoch: 1 [34064/50000 (68%)]\tLoss: 0.706579\n",
            "Train Epoch: 1 [34544/50000 (69%)]\tLoss: 1.305029\n",
            "Train Epoch: 1 [35024/50000 (70%)]\tLoss: 1.118943\n",
            "Train Epoch: 1 [35504/50000 (71%)]\tLoss: 0.699442\n",
            "Train Epoch: 1 [35984/50000 (72%)]\tLoss: 0.982520\n",
            "Train Epoch: 1 [36464/50000 (73%)]\tLoss: 1.045975\n",
            "Train Epoch: 1 [36944/50000 (74%)]\tLoss: 1.465396\n",
            "Train Epoch: 1 [37424/50000 (75%)]\tLoss: 0.906181\n",
            "Train Epoch: 1 [37904/50000 (76%)]\tLoss: 1.663207\n",
            "Train Epoch: 1 [38384/50000 (77%)]\tLoss: 1.098303\n",
            "Train Epoch: 1 [38864/50000 (78%)]\tLoss: 0.836642\n",
            "Train Epoch: 1 [39344/50000 (79%)]\tLoss: 1.342881\n",
            "Train Epoch: 1 [39824/50000 (80%)]\tLoss: 1.013894\n",
            "Train Epoch: 1 [40304/50000 (81%)]\tLoss: 1.329009\n",
            "Train Epoch: 1 [40784/50000 (82%)]\tLoss: 1.334555\n",
            "Train Epoch: 1 [41264/50000 (83%)]\tLoss: 1.230470\n",
            "Train Epoch: 1 [41744/50000 (83%)]\tLoss: 1.218261\n",
            "Train Epoch: 1 [42224/50000 (84%)]\tLoss: 1.139399\n",
            "Train Epoch: 1 [42704/50000 (85%)]\tLoss: 1.702377\n",
            "Train Epoch: 1 [43184/50000 (86%)]\tLoss: 1.797830\n",
            "Train Epoch: 1 [43664/50000 (87%)]\tLoss: 1.236947\n",
            "Train Epoch: 1 [44144/50000 (88%)]\tLoss: 1.007959\n",
            "Train Epoch: 1 [44624/50000 (89%)]\tLoss: 0.684858\n",
            "Train Epoch: 1 [45104/50000 (90%)]\tLoss: 0.961747\n",
            "Train Epoch: 1 [45584/50000 (91%)]\tLoss: 0.712875\n",
            "Train Epoch: 1 [46064/50000 (92%)]\tLoss: 1.055804\n",
            "Train Epoch: 1 [46544/50000 (93%)]\tLoss: 1.652567\n",
            "Train Epoch: 1 [47024/50000 (94%)]\tLoss: 0.844789\n",
            "Train Epoch: 1 [47504/50000 (95%)]\tLoss: 1.660390\n",
            "Train Epoch: 1 [47984/50000 (96%)]\tLoss: 0.823193\n",
            "Train Epoch: 1 [48464/50000 (97%)]\tLoss: 0.836280\n",
            "Train Epoch: 1 [48944/50000 (98%)]\tLoss: 0.985658\n",
            "Train Epoch: 1 [49424/50000 (99%)]\tLoss: 1.208399\n",
            "Train Epoch: 1 [49904/50000 (100%)]\tLoss: 1.274915\n",
            "---------------------------------------\n",
            "Training time for epoch 1: 19.92 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch1): Average loss: 1.0345, Accuracy: 6308/10000 (63%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 2 [464/50000 (1%)]\tLoss: 1.040323\n",
            "Train Epoch: 2 [944/50000 (2%)]\tLoss: 0.429468\n",
            "Train Epoch: 2 [1424/50000 (3%)]\tLoss: 0.775051\n",
            "Train Epoch: 2 [1904/50000 (4%)]\tLoss: 1.221844\n",
            "Train Epoch: 2 [2384/50000 (5%)]\tLoss: 1.310402\n",
            "Train Epoch: 2 [2864/50000 (6%)]\tLoss: 0.983324\n",
            "Train Epoch: 2 [3344/50000 (7%)]\tLoss: 1.004907\n",
            "Train Epoch: 2 [3824/50000 (8%)]\tLoss: 1.876324\n",
            "Train Epoch: 2 [4304/50000 (9%)]\tLoss: 0.942212\n",
            "Train Epoch: 2 [4784/50000 (10%)]\tLoss: 0.958111\n",
            "Train Epoch: 2 [5264/50000 (11%)]\tLoss: 0.851283\n",
            "Train Epoch: 2 [5744/50000 (11%)]\tLoss: 1.088474\n",
            "Train Epoch: 2 [6224/50000 (12%)]\tLoss: 0.795140\n",
            "Train Epoch: 2 [6704/50000 (13%)]\tLoss: 0.872240\n",
            "Train Epoch: 2 [7184/50000 (14%)]\tLoss: 0.973141\n",
            "Train Epoch: 2 [7664/50000 (15%)]\tLoss: 1.355882\n",
            "Train Epoch: 2 [8144/50000 (16%)]\tLoss: 1.144883\n",
            "Train Epoch: 2 [8624/50000 (17%)]\tLoss: 0.733582\n",
            "Train Epoch: 2 [9104/50000 (18%)]\tLoss: 1.202549\n",
            "Train Epoch: 2 [9584/50000 (19%)]\tLoss: 0.772770\n",
            "Train Epoch: 2 [10064/50000 (20%)]\tLoss: 0.813468\n",
            "Train Epoch: 2 [10544/50000 (21%)]\tLoss: 1.663597\n",
            "Train Epoch: 2 [11024/50000 (22%)]\tLoss: 1.228199\n",
            "Train Epoch: 2 [11504/50000 (23%)]\tLoss: 1.227310\n",
            "Train Epoch: 2 [11984/50000 (24%)]\tLoss: 1.020895\n",
            "Train Epoch: 2 [12464/50000 (25%)]\tLoss: 1.216203\n",
            "Train Epoch: 2 [12944/50000 (26%)]\tLoss: 1.079239\n",
            "Train Epoch: 2 [13424/50000 (27%)]\tLoss: 0.811786\n",
            "Train Epoch: 2 [13904/50000 (28%)]\tLoss: 1.051598\n",
            "Train Epoch: 2 [14384/50000 (29%)]\tLoss: 1.010968\n",
            "Train Epoch: 2 [14864/50000 (30%)]\tLoss: 0.743262\n",
            "Train Epoch: 2 [15344/50000 (31%)]\tLoss: 1.160731\n",
            "Train Epoch: 2 [15824/50000 (32%)]\tLoss: 1.270654\n",
            "Train Epoch: 2 [16304/50000 (33%)]\tLoss: 0.997755\n",
            "Train Epoch: 2 [16784/50000 (34%)]\tLoss: 1.070221\n",
            "Train Epoch: 2 [17264/50000 (35%)]\tLoss: 1.238821\n",
            "Train Epoch: 2 [17744/50000 (35%)]\tLoss: 1.448875\n",
            "Train Epoch: 2 [18224/50000 (36%)]\tLoss: 0.970419\n",
            "Train Epoch: 2 [18704/50000 (37%)]\tLoss: 1.147285\n",
            "Train Epoch: 2 [19184/50000 (38%)]\tLoss: 0.990832\n",
            "Train Epoch: 2 [19664/50000 (39%)]\tLoss: 1.264290\n",
            "Train Epoch: 2 [20144/50000 (40%)]\tLoss: 1.214448\n",
            "Train Epoch: 2 [20624/50000 (41%)]\tLoss: 0.789761\n",
            "Train Epoch: 2 [21104/50000 (42%)]\tLoss: 1.002819\n",
            "Train Epoch: 2 [21584/50000 (43%)]\tLoss: 0.776799\n",
            "Train Epoch: 2 [22064/50000 (44%)]\tLoss: 0.589690\n",
            "Train Epoch: 2 [22544/50000 (45%)]\tLoss: 1.117841\n",
            "Train Epoch: 2 [23024/50000 (46%)]\tLoss: 0.751478\n",
            "Train Epoch: 2 [23504/50000 (47%)]\tLoss: 0.883552\n",
            "Train Epoch: 2 [23984/50000 (48%)]\tLoss: 0.755136\n",
            "Train Epoch: 2 [24464/50000 (49%)]\tLoss: 0.818093\n",
            "Train Epoch: 2 [24944/50000 (50%)]\tLoss: 0.978227\n",
            "Train Epoch: 2 [25424/50000 (51%)]\tLoss: 0.974439\n",
            "Train Epoch: 2 [25904/50000 (52%)]\tLoss: 0.882326\n",
            "Train Epoch: 2 [26384/50000 (53%)]\tLoss: 0.598231\n",
            "Train Epoch: 2 [26864/50000 (54%)]\tLoss: 0.556600\n",
            "Train Epoch: 2 [27344/50000 (55%)]\tLoss: 0.738465\n",
            "Train Epoch: 2 [27824/50000 (56%)]\tLoss: 0.591362\n",
            "Train Epoch: 2 [28304/50000 (57%)]\tLoss: 0.664189\n",
            "Train Epoch: 2 [28784/50000 (58%)]\tLoss: 1.095581\n",
            "Train Epoch: 2 [29264/50000 (59%)]\tLoss: 0.842614\n",
            "Train Epoch: 2 [29744/50000 (59%)]\tLoss: 1.092491\n",
            "Train Epoch: 2 [30224/50000 (60%)]\tLoss: 0.990718\n",
            "Train Epoch: 2 [30704/50000 (61%)]\tLoss: 1.317544\n",
            "Train Epoch: 2 [31184/50000 (62%)]\tLoss: 1.438261\n",
            "Train Epoch: 2 [31664/50000 (63%)]\tLoss: 0.813635\n",
            "Train Epoch: 2 [32144/50000 (64%)]\tLoss: 0.648430\n",
            "Train Epoch: 2 [32624/50000 (65%)]\tLoss: 0.660347\n",
            "Train Epoch: 2 [33104/50000 (66%)]\tLoss: 1.258942\n",
            "Train Epoch: 2 [33584/50000 (67%)]\tLoss: 1.070006\n",
            "Train Epoch: 2 [34064/50000 (68%)]\tLoss: 0.910248\n",
            "Train Epoch: 2 [34544/50000 (69%)]\tLoss: 1.229071\n",
            "Train Epoch: 2 [35024/50000 (70%)]\tLoss: 0.653098\n",
            "Train Epoch: 2 [35504/50000 (71%)]\tLoss: 1.085580\n",
            "Train Epoch: 2 [35984/50000 (72%)]\tLoss: 1.399643\n",
            "Train Epoch: 2 [36464/50000 (73%)]\tLoss: 1.350674\n",
            "Train Epoch: 2 [36944/50000 (74%)]\tLoss: 1.069413\n",
            "Train Epoch: 2 [37424/50000 (75%)]\tLoss: 0.653874\n",
            "Train Epoch: 2 [37904/50000 (76%)]\tLoss: 1.462188\n",
            "Train Epoch: 2 [38384/50000 (77%)]\tLoss: 1.224737\n",
            "Train Epoch: 2 [38864/50000 (78%)]\tLoss: 0.505641\n",
            "Train Epoch: 2 [39344/50000 (79%)]\tLoss: 1.027734\n",
            "Train Epoch: 2 [39824/50000 (80%)]\tLoss: 1.235162\n",
            "Train Epoch: 2 [40304/50000 (81%)]\tLoss: 1.358097\n",
            "Train Epoch: 2 [40784/50000 (82%)]\tLoss: 1.097006\n",
            "Train Epoch: 2 [41264/50000 (83%)]\tLoss: 0.817270\n",
            "Train Epoch: 2 [41744/50000 (83%)]\tLoss: 0.749990\n",
            "Train Epoch: 2 [42224/50000 (84%)]\tLoss: 0.570660\n",
            "Train Epoch: 2 [42704/50000 (85%)]\tLoss: 1.135518\n",
            "Train Epoch: 2 [43184/50000 (86%)]\tLoss: 1.260445\n",
            "Train Epoch: 2 [43664/50000 (87%)]\tLoss: 1.969553\n",
            "Train Epoch: 2 [44144/50000 (88%)]\tLoss: 0.738023\n",
            "Train Epoch: 2 [44624/50000 (89%)]\tLoss: 0.893313\n",
            "Train Epoch: 2 [45104/50000 (90%)]\tLoss: 1.368858\n",
            "Train Epoch: 2 [45584/50000 (91%)]\tLoss: 0.921524\n",
            "Train Epoch: 2 [46064/50000 (92%)]\tLoss: 0.742524\n",
            "Train Epoch: 2 [46544/50000 (93%)]\tLoss: 0.787172\n",
            "Train Epoch: 2 [47024/50000 (94%)]\tLoss: 0.764362\n",
            "Train Epoch: 2 [47504/50000 (95%)]\tLoss: 0.714555\n",
            "Train Epoch: 2 [47984/50000 (96%)]\tLoss: 0.668847\n",
            "Train Epoch: 2 [48464/50000 (97%)]\tLoss: 0.889632\n",
            "Train Epoch: 2 [48944/50000 (98%)]\tLoss: 1.172746\n",
            "Train Epoch: 2 [49424/50000 (99%)]\tLoss: 1.178985\n",
            "Train Epoch: 2 [49904/50000 (100%)]\tLoss: 0.479858\n",
            "---------------------------------------\n",
            "Training time for epoch 2: 19.74 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch2): Average loss: 0.9373, Accuracy: 6719/10000 (67%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 3 [464/50000 (1%)]\tLoss: 0.659820\n",
            "Train Epoch: 3 [944/50000 (2%)]\tLoss: 0.920247\n",
            "Train Epoch: 3 [1424/50000 (3%)]\tLoss: 0.830090\n",
            "Train Epoch: 3 [1904/50000 (4%)]\tLoss: 1.019984\n",
            "Train Epoch: 3 [2384/50000 (5%)]\tLoss: 0.752687\n",
            "Train Epoch: 3 [2864/50000 (6%)]\tLoss: 0.840424\n",
            "Train Epoch: 3 [3344/50000 (7%)]\tLoss: 1.050751\n",
            "Train Epoch: 3 [3824/50000 (8%)]\tLoss: 1.353023\n",
            "Train Epoch: 3 [4304/50000 (9%)]\tLoss: 0.567120\n",
            "Train Epoch: 3 [4784/50000 (10%)]\tLoss: 1.649265\n",
            "Train Epoch: 3 [5264/50000 (11%)]\tLoss: 0.493670\n",
            "Train Epoch: 3 [5744/50000 (11%)]\tLoss: 0.695347\n",
            "Train Epoch: 3 [6224/50000 (12%)]\tLoss: 0.887319\n",
            "Train Epoch: 3 [6704/50000 (13%)]\tLoss: 0.703073\n",
            "Train Epoch: 3 [7184/50000 (14%)]\tLoss: 0.778734\n",
            "Train Epoch: 3 [7664/50000 (15%)]\tLoss: 0.481276\n",
            "Train Epoch: 3 [8144/50000 (16%)]\tLoss: 1.102465\n",
            "Train Epoch: 3 [8624/50000 (17%)]\tLoss: 0.961096\n",
            "Train Epoch: 3 [9104/50000 (18%)]\tLoss: 0.941836\n",
            "Train Epoch: 3 [9584/50000 (19%)]\tLoss: 0.932501\n",
            "Train Epoch: 3 [10064/50000 (20%)]\tLoss: 0.707653\n",
            "Train Epoch: 3 [10544/50000 (21%)]\tLoss: 0.869992\n",
            "Train Epoch: 3 [11024/50000 (22%)]\tLoss: 0.461803\n",
            "Train Epoch: 3 [11504/50000 (23%)]\tLoss: 1.056034\n",
            "Train Epoch: 3 [11984/50000 (24%)]\tLoss: 0.894093\n",
            "Train Epoch: 3 [12464/50000 (25%)]\tLoss: 1.012159\n",
            "Train Epoch: 3 [12944/50000 (26%)]\tLoss: 0.539612\n",
            "Train Epoch: 3 [13424/50000 (27%)]\tLoss: 1.346628\n",
            "Train Epoch: 3 [13904/50000 (28%)]\tLoss: 0.762743\n",
            "Train Epoch: 3 [14384/50000 (29%)]\tLoss: 1.616292\n",
            "Train Epoch: 3 [14864/50000 (30%)]\tLoss: 0.647406\n",
            "Train Epoch: 3 [15344/50000 (31%)]\tLoss: 0.667155\n",
            "Train Epoch: 3 [15824/50000 (32%)]\tLoss: 1.025479\n",
            "Train Epoch: 3 [16304/50000 (33%)]\tLoss: 0.797921\n",
            "Train Epoch: 3 [16784/50000 (34%)]\tLoss: 0.802006\n",
            "Train Epoch: 3 [17264/50000 (35%)]\tLoss: 0.644516\n",
            "Train Epoch: 3 [17744/50000 (35%)]\tLoss: 0.433874\n",
            "Train Epoch: 3 [18224/50000 (36%)]\tLoss: 0.363929\n",
            "Train Epoch: 3 [18704/50000 (37%)]\tLoss: 0.719802\n",
            "Train Epoch: 3 [19184/50000 (38%)]\tLoss: 0.498927\n",
            "Train Epoch: 3 [19664/50000 (39%)]\tLoss: 0.538293\n",
            "Train Epoch: 3 [20144/50000 (40%)]\tLoss: 0.322809\n",
            "Train Epoch: 3 [20624/50000 (41%)]\tLoss: 0.623538\n",
            "Train Epoch: 3 [21104/50000 (42%)]\tLoss: 0.927198\n",
            "Train Epoch: 3 [21584/50000 (43%)]\tLoss: 0.744216\n",
            "Train Epoch: 3 [22064/50000 (44%)]\tLoss: 0.247230\n",
            "Train Epoch: 3 [22544/50000 (45%)]\tLoss: 0.660314\n",
            "Train Epoch: 3 [23024/50000 (46%)]\tLoss: 1.215864\n",
            "Train Epoch: 3 [23504/50000 (47%)]\tLoss: 1.084815\n",
            "Train Epoch: 3 [23984/50000 (48%)]\tLoss: 0.705407\n",
            "Train Epoch: 3 [24464/50000 (49%)]\tLoss: 0.933627\n",
            "Train Epoch: 3 [24944/50000 (50%)]\tLoss: 0.673414\n",
            "Train Epoch: 3 [25424/50000 (51%)]\tLoss: 0.637033\n",
            "Train Epoch: 3 [25904/50000 (52%)]\tLoss: 1.126913\n",
            "Train Epoch: 3 [26384/50000 (53%)]\tLoss: 0.974889\n",
            "Train Epoch: 3 [26864/50000 (54%)]\tLoss: 0.654734\n",
            "Train Epoch: 3 [27344/50000 (55%)]\tLoss: 0.700567\n",
            "Train Epoch: 3 [27824/50000 (56%)]\tLoss: 1.233228\n",
            "Train Epoch: 3 [28304/50000 (57%)]\tLoss: 0.654633\n",
            "Train Epoch: 3 [28784/50000 (58%)]\tLoss: 0.689283\n",
            "Train Epoch: 3 [29264/50000 (59%)]\tLoss: 0.682450\n",
            "Train Epoch: 3 [29744/50000 (59%)]\tLoss: 0.965763\n",
            "Train Epoch: 3 [30224/50000 (60%)]\tLoss: 0.949909\n",
            "Train Epoch: 3 [30704/50000 (61%)]\tLoss: 0.847522\n",
            "Train Epoch: 3 [31184/50000 (62%)]\tLoss: 0.942718\n",
            "Train Epoch: 3 [31664/50000 (63%)]\tLoss: 0.829714\n",
            "Train Epoch: 3 [32144/50000 (64%)]\tLoss: 0.912530\n",
            "Train Epoch: 3 [32624/50000 (65%)]\tLoss: 1.221828\n",
            "Train Epoch: 3 [33104/50000 (66%)]\tLoss: 0.683565\n",
            "Train Epoch: 3 [33584/50000 (67%)]\tLoss: 1.072870\n",
            "Train Epoch: 3 [34064/50000 (68%)]\tLoss: 0.738659\n",
            "Train Epoch: 3 [34544/50000 (69%)]\tLoss: 0.691330\n",
            "Train Epoch: 3 [35024/50000 (70%)]\tLoss: 0.503347\n",
            "Train Epoch: 3 [35504/50000 (71%)]\tLoss: 0.701725\n",
            "Train Epoch: 3 [35984/50000 (72%)]\tLoss: 0.640645\n",
            "Train Epoch: 3 [36464/50000 (73%)]\tLoss: 0.619951\n",
            "Train Epoch: 3 [36944/50000 (74%)]\tLoss: 1.183456\n",
            "Train Epoch: 3 [37424/50000 (75%)]\tLoss: 0.604097\n",
            "Train Epoch: 3 [37904/50000 (76%)]\tLoss: 1.305631\n",
            "Train Epoch: 3 [38384/50000 (77%)]\tLoss: 1.049232\n",
            "Train Epoch: 3 [38864/50000 (78%)]\tLoss: 0.915796\n",
            "Train Epoch: 3 [39344/50000 (79%)]\tLoss: 0.636929\n",
            "Train Epoch: 3 [39824/50000 (80%)]\tLoss: 0.966117\n",
            "Train Epoch: 3 [40304/50000 (81%)]\tLoss: 0.432251\n",
            "Train Epoch: 3 [40784/50000 (82%)]\tLoss: 0.597724\n",
            "Train Epoch: 3 [41264/50000 (83%)]\tLoss: 0.803100\n",
            "Train Epoch: 3 [41744/50000 (83%)]\tLoss: 1.128094\n",
            "Train Epoch: 3 [42224/50000 (84%)]\tLoss: 0.823779\n",
            "Train Epoch: 3 [42704/50000 (85%)]\tLoss: 0.749940\n",
            "Train Epoch: 3 [43184/50000 (86%)]\tLoss: 1.243223\n",
            "Train Epoch: 3 [43664/50000 (87%)]\tLoss: 0.851720\n",
            "Train Epoch: 3 [44144/50000 (88%)]\tLoss: 0.800979\n",
            "Train Epoch: 3 [44624/50000 (89%)]\tLoss: 0.572106\n",
            "Train Epoch: 3 [45104/50000 (90%)]\tLoss: 0.924209\n",
            "Train Epoch: 3 [45584/50000 (91%)]\tLoss: 0.770934\n",
            "Train Epoch: 3 [46064/50000 (92%)]\tLoss: 0.513691\n",
            "Train Epoch: 3 [46544/50000 (93%)]\tLoss: 0.610780\n",
            "Train Epoch: 3 [47024/50000 (94%)]\tLoss: 1.151696\n",
            "Train Epoch: 3 [47504/50000 (95%)]\tLoss: 0.747400\n",
            "Train Epoch: 3 [47984/50000 (96%)]\tLoss: 0.582361\n",
            "Train Epoch: 3 [48464/50000 (97%)]\tLoss: 0.578601\n",
            "Train Epoch: 3 [48944/50000 (98%)]\tLoss: 1.025429\n",
            "Train Epoch: 3 [49424/50000 (99%)]\tLoss: 0.584040\n",
            "Train Epoch: 3 [49904/50000 (100%)]\tLoss: 0.612427\n",
            "---------------------------------------\n",
            "Training time for epoch 3: 20.10 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch3): Average loss: 0.8803, Accuracy: 6920/10000 (69%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 4 [464/50000 (1%)]\tLoss: 0.733806\n",
            "Train Epoch: 4 [944/50000 (2%)]\tLoss: 0.688148\n",
            "Train Epoch: 4 [1424/50000 (3%)]\tLoss: 0.511673\n",
            "Train Epoch: 4 [1904/50000 (4%)]\tLoss: 0.644536\n",
            "Train Epoch: 4 [2384/50000 (5%)]\tLoss: 0.597105\n",
            "Train Epoch: 4 [2864/50000 (6%)]\tLoss: 0.761311\n",
            "Train Epoch: 4 [3344/50000 (7%)]\tLoss: 0.549851\n",
            "Train Epoch: 4 [3824/50000 (8%)]\tLoss: 0.787771\n",
            "Train Epoch: 4 [4304/50000 (9%)]\tLoss: 1.147197\n",
            "Train Epoch: 4 [4784/50000 (10%)]\tLoss: 0.455194\n",
            "Train Epoch: 4 [5264/50000 (11%)]\tLoss: 0.364425\n",
            "Train Epoch: 4 [5744/50000 (11%)]\tLoss: 0.409362\n",
            "Train Epoch: 4 [6224/50000 (12%)]\tLoss: 0.627046\n",
            "Train Epoch: 4 [6704/50000 (13%)]\tLoss: 0.594473\n",
            "Train Epoch: 4 [7184/50000 (14%)]\tLoss: 0.747551\n",
            "Train Epoch: 4 [7664/50000 (15%)]\tLoss: 0.722011\n",
            "Train Epoch: 4 [8144/50000 (16%)]\tLoss: 0.923407\n",
            "Train Epoch: 4 [8624/50000 (17%)]\tLoss: 1.088338\n",
            "Train Epoch: 4 [9104/50000 (18%)]\tLoss: 0.719751\n",
            "Train Epoch: 4 [9584/50000 (19%)]\tLoss: 1.036354\n",
            "Train Epoch: 4 [10064/50000 (20%)]\tLoss: 1.136555\n",
            "Train Epoch: 4 [10544/50000 (21%)]\tLoss: 0.467717\n",
            "Train Epoch: 4 [11024/50000 (22%)]\tLoss: 0.329722\n",
            "Train Epoch: 4 [11504/50000 (23%)]\tLoss: 0.394105\n",
            "Train Epoch: 4 [11984/50000 (24%)]\tLoss: 1.032871\n",
            "Train Epoch: 4 [12464/50000 (25%)]\tLoss: 0.956269\n",
            "Train Epoch: 4 [12944/50000 (26%)]\tLoss: 0.781917\n",
            "Train Epoch: 4 [13424/50000 (27%)]\tLoss: 0.637511\n",
            "Train Epoch: 4 [13904/50000 (28%)]\tLoss: 0.834620\n",
            "Train Epoch: 4 [14384/50000 (29%)]\tLoss: 0.564785\n",
            "Train Epoch: 4 [14864/50000 (30%)]\tLoss: 0.842499\n",
            "Train Epoch: 4 [15344/50000 (31%)]\tLoss: 0.588225\n",
            "Train Epoch: 4 [15824/50000 (32%)]\tLoss: 0.915133\n",
            "Train Epoch: 4 [16304/50000 (33%)]\tLoss: 1.021294\n",
            "Train Epoch: 4 [16784/50000 (34%)]\tLoss: 0.581747\n",
            "Train Epoch: 4 [17264/50000 (35%)]\tLoss: 0.896099\n",
            "Train Epoch: 4 [17744/50000 (35%)]\tLoss: 0.571730\n",
            "Train Epoch: 4 [18224/50000 (36%)]\tLoss: 0.957628\n",
            "Train Epoch: 4 [18704/50000 (37%)]\tLoss: 0.748696\n",
            "Train Epoch: 4 [19184/50000 (38%)]\tLoss: 0.612279\n",
            "Train Epoch: 4 [19664/50000 (39%)]\tLoss: 0.496690\n",
            "Train Epoch: 4 [20144/50000 (40%)]\tLoss: 0.472108\n",
            "Train Epoch: 4 [20624/50000 (41%)]\tLoss: 0.447330\n",
            "Train Epoch: 4 [21104/50000 (42%)]\tLoss: 0.954712\n",
            "Train Epoch: 4 [21584/50000 (43%)]\tLoss: 0.440145\n",
            "Train Epoch: 4 [22064/50000 (44%)]\tLoss: 0.544224\n",
            "Train Epoch: 4 [22544/50000 (45%)]\tLoss: 0.689232\n",
            "Train Epoch: 4 [23024/50000 (46%)]\tLoss: 0.730209\n",
            "Train Epoch: 4 [23504/50000 (47%)]\tLoss: 1.089041\n",
            "Train Epoch: 4 [23984/50000 (48%)]\tLoss: 0.679743\n",
            "Train Epoch: 4 [24464/50000 (49%)]\tLoss: 0.959618\n",
            "Train Epoch: 4 [24944/50000 (50%)]\tLoss: 0.612669\n",
            "Train Epoch: 4 [25424/50000 (51%)]\tLoss: 0.750059\n",
            "Train Epoch: 4 [25904/50000 (52%)]\tLoss: 0.460388\n",
            "Train Epoch: 4 [26384/50000 (53%)]\tLoss: 0.666949\n",
            "Train Epoch: 4 [26864/50000 (54%)]\tLoss: 0.540012\n",
            "Train Epoch: 4 [27344/50000 (55%)]\tLoss: 0.642509\n",
            "Train Epoch: 4 [27824/50000 (56%)]\tLoss: 1.060402\n",
            "Train Epoch: 4 [28304/50000 (57%)]\tLoss: 0.669174\n",
            "Train Epoch: 4 [28784/50000 (58%)]\tLoss: 0.741155\n",
            "Train Epoch: 4 [29264/50000 (59%)]\tLoss: 0.682324\n",
            "Train Epoch: 4 [29744/50000 (59%)]\tLoss: 0.545217\n",
            "Train Epoch: 4 [30224/50000 (60%)]\tLoss: 0.479717\n",
            "Train Epoch: 4 [30704/50000 (61%)]\tLoss: 0.877917\n",
            "Train Epoch: 4 [31184/50000 (62%)]\tLoss: 0.930930\n",
            "Train Epoch: 4 [31664/50000 (63%)]\tLoss: 1.154005\n",
            "Train Epoch: 4 [32144/50000 (64%)]\tLoss: 0.464214\n",
            "Train Epoch: 4 [32624/50000 (65%)]\tLoss: 0.659695\n",
            "Train Epoch: 4 [33104/50000 (66%)]\tLoss: 0.721588\n",
            "Train Epoch: 4 [33584/50000 (67%)]\tLoss: 0.836986\n",
            "Train Epoch: 4 [34064/50000 (68%)]\tLoss: 0.671760\n",
            "Train Epoch: 4 [34544/50000 (69%)]\tLoss: 0.557631\n",
            "Train Epoch: 4 [35024/50000 (70%)]\tLoss: 0.887938\n",
            "Train Epoch: 4 [35504/50000 (71%)]\tLoss: 0.455558\n",
            "Train Epoch: 4 [35984/50000 (72%)]\tLoss: 0.821758\n",
            "Train Epoch: 4 [36464/50000 (73%)]\tLoss: 0.615092\n",
            "Train Epoch: 4 [36944/50000 (74%)]\tLoss: 0.423513\n",
            "Train Epoch: 4 [37424/50000 (75%)]\tLoss: 0.282211\n",
            "Train Epoch: 4 [37904/50000 (76%)]\tLoss: 0.585632\n",
            "Train Epoch: 4 [38384/50000 (77%)]\tLoss: 1.242108\n",
            "Train Epoch: 4 [38864/50000 (78%)]\tLoss: 0.904520\n",
            "Train Epoch: 4 [39344/50000 (79%)]\tLoss: 0.612406\n",
            "Train Epoch: 4 [39824/50000 (80%)]\tLoss: 0.531074\n",
            "Train Epoch: 4 [40304/50000 (81%)]\tLoss: 1.100914\n",
            "Train Epoch: 4 [40784/50000 (82%)]\tLoss: 0.946760\n",
            "Train Epoch: 4 [41264/50000 (83%)]\tLoss: 0.613824\n",
            "Train Epoch: 4 [41744/50000 (83%)]\tLoss: 1.012828\n",
            "Train Epoch: 4 [42224/50000 (84%)]\tLoss: 0.710789\n",
            "Train Epoch: 4 [42704/50000 (85%)]\tLoss: 0.707887\n",
            "Train Epoch: 4 [43184/50000 (86%)]\tLoss: 1.032088\n",
            "Train Epoch: 4 [43664/50000 (87%)]\tLoss: 0.596071\n",
            "Train Epoch: 4 [44144/50000 (88%)]\tLoss: 1.222740\n",
            "Train Epoch: 4 [44624/50000 (89%)]\tLoss: 0.780404\n",
            "Train Epoch: 4 [45104/50000 (90%)]\tLoss: 0.648084\n",
            "Train Epoch: 4 [45584/50000 (91%)]\tLoss: 0.857298\n",
            "Train Epoch: 4 [46064/50000 (92%)]\tLoss: 0.922489\n",
            "Train Epoch: 4 [46544/50000 (93%)]\tLoss: 0.584452\n",
            "Train Epoch: 4 [47024/50000 (94%)]\tLoss: 0.380967\n",
            "Train Epoch: 4 [47504/50000 (95%)]\tLoss: 0.371654\n",
            "Train Epoch: 4 [47984/50000 (96%)]\tLoss: 1.464133\n",
            "Train Epoch: 4 [48464/50000 (97%)]\tLoss: 0.734051\n",
            "Train Epoch: 4 [48944/50000 (98%)]\tLoss: 0.754367\n",
            "Train Epoch: 4 [49424/50000 (99%)]\tLoss: 0.687250\n",
            "Train Epoch: 4 [49904/50000 (100%)]\tLoss: 0.648308\n",
            "---------------------------------------\n",
            "Training time for epoch 4: 20.46 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch4): Average loss: 0.8071, Accuracy: 7207/10000 (72%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 5 [464/50000 (1%)]\tLoss: 0.777705\n",
            "Train Epoch: 5 [944/50000 (2%)]\tLoss: 0.392804\n",
            "Train Epoch: 5 [1424/50000 (3%)]\tLoss: 0.416765\n",
            "Train Epoch: 5 [1904/50000 (4%)]\tLoss: 1.263852\n",
            "Train Epoch: 5 [2384/50000 (5%)]\tLoss: 0.784517\n",
            "Train Epoch: 5 [2864/50000 (6%)]\tLoss: 0.798311\n",
            "Train Epoch: 5 [3344/50000 (7%)]\tLoss: 0.708032\n",
            "Train Epoch: 5 [3824/50000 (8%)]\tLoss: 0.239027\n",
            "Train Epoch: 5 [4304/50000 (9%)]\tLoss: 0.534963\n",
            "Train Epoch: 5 [4784/50000 (10%)]\tLoss: 0.394055\n",
            "Train Epoch: 5 [5264/50000 (11%)]\tLoss: 0.318226\n",
            "Train Epoch: 5 [5744/50000 (11%)]\tLoss: 0.959619\n",
            "Train Epoch: 5 [6224/50000 (12%)]\tLoss: 0.433936\n",
            "Train Epoch: 5 [6704/50000 (13%)]\tLoss: 1.042423\n",
            "Train Epoch: 5 [7184/50000 (14%)]\tLoss: 0.778960\n",
            "Train Epoch: 5 [7664/50000 (15%)]\tLoss: 0.449744\n",
            "Train Epoch: 5 [8144/50000 (16%)]\tLoss: 0.719638\n",
            "Train Epoch: 5 [8624/50000 (17%)]\tLoss: 0.611176\n",
            "Train Epoch: 5 [9104/50000 (18%)]\tLoss: 0.419005\n",
            "Train Epoch: 5 [9584/50000 (19%)]\tLoss: 0.525313\n",
            "Train Epoch: 5 [10064/50000 (20%)]\tLoss: 0.643224\n",
            "Train Epoch: 5 [10544/50000 (21%)]\tLoss: 0.413100\n",
            "Train Epoch: 5 [11024/50000 (22%)]\tLoss: 0.542587\n",
            "Train Epoch: 5 [11504/50000 (23%)]\tLoss: 0.882513\n",
            "Train Epoch: 5 [11984/50000 (24%)]\tLoss: 0.854912\n",
            "Train Epoch: 5 [12464/50000 (25%)]\tLoss: 0.645666\n",
            "Train Epoch: 5 [12944/50000 (26%)]\tLoss: 0.699459\n",
            "Train Epoch: 5 [13424/50000 (27%)]\tLoss: 0.302003\n",
            "Train Epoch: 5 [13904/50000 (28%)]\tLoss: 0.385409\n",
            "Train Epoch: 5 [14384/50000 (29%)]\tLoss: 0.705852\n",
            "Train Epoch: 5 [14864/50000 (30%)]\tLoss: 0.934565\n",
            "Train Epoch: 5 [15344/50000 (31%)]\tLoss: 0.660405\n",
            "Train Epoch: 5 [15824/50000 (32%)]\tLoss: 0.347900\n",
            "Train Epoch: 5 [16304/50000 (33%)]\tLoss: 0.701520\n",
            "Train Epoch: 5 [16784/50000 (34%)]\tLoss: 0.503891\n",
            "Train Epoch: 5 [17264/50000 (35%)]\tLoss: 0.550173\n",
            "Train Epoch: 5 [17744/50000 (35%)]\tLoss: 0.545596\n",
            "Train Epoch: 5 [18224/50000 (36%)]\tLoss: 0.217836\n",
            "Train Epoch: 5 [18704/50000 (37%)]\tLoss: 0.440382\n",
            "Train Epoch: 5 [19184/50000 (38%)]\tLoss: 0.631959\n",
            "Train Epoch: 5 [19664/50000 (39%)]\tLoss: 0.311729\n",
            "Train Epoch: 5 [20144/50000 (40%)]\tLoss: 0.703276\n",
            "Train Epoch: 5 [20624/50000 (41%)]\tLoss: 0.837601\n",
            "Train Epoch: 5 [21104/50000 (42%)]\tLoss: 0.566079\n",
            "Train Epoch: 5 [21584/50000 (43%)]\tLoss: 0.454505\n",
            "Train Epoch: 5 [22064/50000 (44%)]\tLoss: 0.668346\n",
            "Train Epoch: 5 [22544/50000 (45%)]\tLoss: 0.888131\n",
            "Train Epoch: 5 [23024/50000 (46%)]\tLoss: 0.857552\n",
            "Train Epoch: 5 [23504/50000 (47%)]\tLoss: 0.671416\n",
            "Train Epoch: 5 [23984/50000 (48%)]\tLoss: 0.237234\n",
            "Train Epoch: 5 [24464/50000 (49%)]\tLoss: 0.447169\n",
            "Train Epoch: 5 [24944/50000 (50%)]\tLoss: 0.561271\n",
            "Train Epoch: 5 [25424/50000 (51%)]\tLoss: 0.509783\n",
            "Train Epoch: 5 [25904/50000 (52%)]\tLoss: 0.781718\n",
            "Train Epoch: 5 [26384/50000 (53%)]\tLoss: 0.639054\n",
            "Train Epoch: 5 [26864/50000 (54%)]\tLoss: 0.655233\n",
            "Train Epoch: 5 [27344/50000 (55%)]\tLoss: 0.272864\n",
            "Train Epoch: 5 [27824/50000 (56%)]\tLoss: 0.651732\n",
            "Train Epoch: 5 [28304/50000 (57%)]\tLoss: 1.065103\n",
            "Train Epoch: 5 [28784/50000 (58%)]\tLoss: 0.282951\n",
            "Train Epoch: 5 [29264/50000 (59%)]\tLoss: 0.575656\n",
            "Train Epoch: 5 [29744/50000 (59%)]\tLoss: 0.367114\n",
            "Train Epoch: 5 [30224/50000 (60%)]\tLoss: 0.747416\n",
            "Train Epoch: 5 [30704/50000 (61%)]\tLoss: 0.663966\n",
            "Train Epoch: 5 [31184/50000 (62%)]\tLoss: 0.262801\n",
            "Train Epoch: 5 [31664/50000 (63%)]\tLoss: 0.768178\n",
            "Train Epoch: 5 [32144/50000 (64%)]\tLoss: 0.612404\n",
            "Train Epoch: 5 [32624/50000 (65%)]\tLoss: 0.828994\n",
            "Train Epoch: 5 [33104/50000 (66%)]\tLoss: 1.069775\n",
            "Train Epoch: 5 [33584/50000 (67%)]\tLoss: 0.413857\n",
            "Train Epoch: 5 [34064/50000 (68%)]\tLoss: 1.120736\n",
            "Train Epoch: 5 [34544/50000 (69%)]\tLoss: 0.568271\n",
            "Train Epoch: 5 [35024/50000 (70%)]\tLoss: 1.210941\n",
            "Train Epoch: 5 [35504/50000 (71%)]\tLoss: 0.821143\n",
            "Train Epoch: 5 [35984/50000 (72%)]\tLoss: 0.647580\n",
            "Train Epoch: 5 [36464/50000 (73%)]\tLoss: 0.426326\n",
            "Train Epoch: 5 [36944/50000 (74%)]\tLoss: 0.550321\n",
            "Train Epoch: 5 [37424/50000 (75%)]\tLoss: 0.555829\n",
            "Train Epoch: 5 [37904/50000 (76%)]\tLoss: 0.983658\n",
            "Train Epoch: 5 [38384/50000 (77%)]\tLoss: 0.278860\n",
            "Train Epoch: 5 [38864/50000 (78%)]\tLoss: 0.430321\n",
            "Train Epoch: 5 [39344/50000 (79%)]\tLoss: 0.974772\n",
            "Train Epoch: 5 [39824/50000 (80%)]\tLoss: 0.418819\n",
            "Train Epoch: 5 [40304/50000 (81%)]\tLoss: 0.320794\n",
            "Train Epoch: 5 [40784/50000 (82%)]\tLoss: 0.965736\n",
            "Train Epoch: 5 [41264/50000 (83%)]\tLoss: 0.606097\n",
            "Train Epoch: 5 [41744/50000 (83%)]\tLoss: 0.963457\n",
            "Train Epoch: 5 [42224/50000 (84%)]\tLoss: 0.390785\n",
            "Train Epoch: 5 [42704/50000 (85%)]\tLoss: 0.762908\n",
            "Train Epoch: 5 [43184/50000 (86%)]\tLoss: 0.700483\n",
            "Train Epoch: 5 [43664/50000 (87%)]\tLoss: 0.684172\n",
            "Train Epoch: 5 [44144/50000 (88%)]\tLoss: 0.476374\n",
            "Train Epoch: 5 [44624/50000 (89%)]\tLoss: 0.470517\n",
            "Train Epoch: 5 [45104/50000 (90%)]\tLoss: 0.811783\n",
            "Train Epoch: 5 [45584/50000 (91%)]\tLoss: 0.867652\n",
            "Train Epoch: 5 [46064/50000 (92%)]\tLoss: 0.420483\n",
            "Train Epoch: 5 [46544/50000 (93%)]\tLoss: 0.391468\n",
            "Train Epoch: 5 [47024/50000 (94%)]\tLoss: 0.547634\n",
            "Train Epoch: 5 [47504/50000 (95%)]\tLoss: 0.652541\n",
            "Train Epoch: 5 [47984/50000 (96%)]\tLoss: 0.560813\n",
            "Train Epoch: 5 [48464/50000 (97%)]\tLoss: 0.594477\n",
            "Train Epoch: 5 [48944/50000 (98%)]\tLoss: 0.487655\n",
            "Train Epoch: 5 [49424/50000 (99%)]\tLoss: 1.132987\n",
            "Train Epoch: 5 [49904/50000 (100%)]\tLoss: 0.415623\n",
            "---------------------------------------\n",
            "Training time for epoch 5: 20.78 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch5): Average loss: 0.7786, Accuracy: 7309/10000 (73%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 6 [464/50000 (1%)]\tLoss: 0.782502\n",
            "Train Epoch: 6 [944/50000 (2%)]\tLoss: 0.698898\n",
            "Train Epoch: 6 [1424/50000 (3%)]\tLoss: 0.541125\n",
            "Train Epoch: 6 [1904/50000 (4%)]\tLoss: 0.444861\n",
            "Train Epoch: 6 [2384/50000 (5%)]\tLoss: 0.598920\n",
            "Train Epoch: 6 [2864/50000 (6%)]\tLoss: 0.520924\n",
            "Train Epoch: 6 [3344/50000 (7%)]\tLoss: 0.845374\n",
            "Train Epoch: 6 [3824/50000 (8%)]\tLoss: 0.690412\n",
            "Train Epoch: 6 [4304/50000 (9%)]\tLoss: 0.591425\n",
            "Train Epoch: 6 [4784/50000 (10%)]\tLoss: 0.434464\n",
            "Train Epoch: 6 [5264/50000 (11%)]\tLoss: 0.378253\n",
            "Train Epoch: 6 [5744/50000 (11%)]\tLoss: 0.714650\n",
            "Train Epoch: 6 [6224/50000 (12%)]\tLoss: 0.316198\n",
            "Train Epoch: 6 [6704/50000 (13%)]\tLoss: 0.240755\n",
            "Train Epoch: 6 [7184/50000 (14%)]\tLoss: 0.779657\n",
            "Train Epoch: 6 [7664/50000 (15%)]\tLoss: 0.804780\n",
            "Train Epoch: 6 [8144/50000 (16%)]\tLoss: 0.328383\n",
            "Train Epoch: 6 [8624/50000 (17%)]\tLoss: 0.456391\n",
            "Train Epoch: 6 [9104/50000 (18%)]\tLoss: 0.493008\n",
            "Train Epoch: 6 [9584/50000 (19%)]\tLoss: 0.442028\n",
            "Train Epoch: 6 [10064/50000 (20%)]\tLoss: 0.723317\n",
            "Train Epoch: 6 [10544/50000 (21%)]\tLoss: 0.519499\n",
            "Train Epoch: 6 [11024/50000 (22%)]\tLoss: 0.739697\n",
            "Train Epoch: 6 [11504/50000 (23%)]\tLoss: 0.816301\n",
            "Train Epoch: 6 [11984/50000 (24%)]\tLoss: 0.637183\n",
            "Train Epoch: 6 [12464/50000 (25%)]\tLoss: 0.889221\n",
            "Train Epoch: 6 [12944/50000 (26%)]\tLoss: 0.517785\n",
            "Train Epoch: 6 [13424/50000 (27%)]\tLoss: 0.761960\n",
            "Train Epoch: 6 [13904/50000 (28%)]\tLoss: 0.265266\n",
            "Train Epoch: 6 [14384/50000 (29%)]\tLoss: 0.446175\n",
            "Train Epoch: 6 [14864/50000 (30%)]\tLoss: 0.829019\n",
            "Train Epoch: 6 [15344/50000 (31%)]\tLoss: 0.606222\n",
            "Train Epoch: 6 [15824/50000 (32%)]\tLoss: 0.681434\n",
            "Train Epoch: 6 [16304/50000 (33%)]\tLoss: 1.521338\n",
            "Train Epoch: 6 [16784/50000 (34%)]\tLoss: 0.706027\n",
            "Train Epoch: 6 [17264/50000 (35%)]\tLoss: 0.953303\n",
            "Train Epoch: 6 [17744/50000 (35%)]\tLoss: 0.828732\n",
            "Train Epoch: 6 [18224/50000 (36%)]\tLoss: 0.309875\n",
            "Train Epoch: 6 [18704/50000 (37%)]\tLoss: 0.587483\n",
            "Train Epoch: 6 [19184/50000 (38%)]\tLoss: 0.593874\n",
            "Train Epoch: 6 [19664/50000 (39%)]\tLoss: 0.538405\n",
            "Train Epoch: 6 [20144/50000 (40%)]\tLoss: 0.785314\n",
            "Train Epoch: 6 [20624/50000 (41%)]\tLoss: 0.633056\n",
            "Train Epoch: 6 [21104/50000 (42%)]\tLoss: 0.625404\n",
            "Train Epoch: 6 [21584/50000 (43%)]\tLoss: 0.579021\n",
            "Train Epoch: 6 [22064/50000 (44%)]\tLoss: 1.232333\n",
            "Train Epoch: 6 [22544/50000 (45%)]\tLoss: 0.221409\n",
            "Train Epoch: 6 [23024/50000 (46%)]\tLoss: 0.969657\n",
            "Train Epoch: 6 [23504/50000 (47%)]\tLoss: 0.324138\n",
            "Train Epoch: 6 [23984/50000 (48%)]\tLoss: 0.327591\n",
            "Train Epoch: 6 [24464/50000 (49%)]\tLoss: 0.560009\n",
            "Train Epoch: 6 [24944/50000 (50%)]\tLoss: 0.389266\n",
            "Train Epoch: 6 [25424/50000 (51%)]\tLoss: 0.261697\n",
            "Train Epoch: 6 [25904/50000 (52%)]\tLoss: 0.375951\n",
            "Train Epoch: 6 [26384/50000 (53%)]\tLoss: 1.199850\n",
            "Train Epoch: 6 [26864/50000 (54%)]\tLoss: 0.404514\n",
            "Train Epoch: 6 [27344/50000 (55%)]\tLoss: 0.467146\n",
            "Train Epoch: 6 [27824/50000 (56%)]\tLoss: 0.235169\n",
            "Train Epoch: 6 [28304/50000 (57%)]\tLoss: 0.783219\n",
            "Train Epoch: 6 [28784/50000 (58%)]\tLoss: 0.487929\n",
            "Train Epoch: 6 [29264/50000 (59%)]\tLoss: 0.669770\n",
            "Train Epoch: 6 [29744/50000 (59%)]\tLoss: 0.581153\n",
            "Train Epoch: 6 [30224/50000 (60%)]\tLoss: 0.430505\n",
            "Train Epoch: 6 [30704/50000 (61%)]\tLoss: 0.857207\n",
            "Train Epoch: 6 [31184/50000 (62%)]\tLoss: 0.494892\n",
            "Train Epoch: 6 [31664/50000 (63%)]\tLoss: 0.291021\n",
            "Train Epoch: 6 [32144/50000 (64%)]\tLoss: 0.609939\n",
            "Train Epoch: 6 [32624/50000 (65%)]\tLoss: 0.701546\n",
            "Train Epoch: 6 [33104/50000 (66%)]\tLoss: 0.665117\n",
            "Train Epoch: 6 [33584/50000 (67%)]\tLoss: 0.494722\n",
            "Train Epoch: 6 [34064/50000 (68%)]\tLoss: 0.223073\n",
            "Train Epoch: 6 [34544/50000 (69%)]\tLoss: 0.617281\n",
            "Train Epoch: 6 [35024/50000 (70%)]\tLoss: 0.600026\n",
            "Train Epoch: 6 [35504/50000 (71%)]\tLoss: 0.790200\n",
            "Train Epoch: 6 [35984/50000 (72%)]\tLoss: 0.698215\n",
            "Train Epoch: 6 [36464/50000 (73%)]\tLoss: 0.570802\n",
            "Train Epoch: 6 [36944/50000 (74%)]\tLoss: 0.778515\n",
            "Train Epoch: 6 [37424/50000 (75%)]\tLoss: 0.629501\n",
            "Train Epoch: 6 [37904/50000 (76%)]\tLoss: 0.443075\n",
            "Train Epoch: 6 [38384/50000 (77%)]\tLoss: 0.486766\n",
            "Train Epoch: 6 [38864/50000 (78%)]\tLoss: 0.409215\n",
            "Train Epoch: 6 [39344/50000 (79%)]\tLoss: 0.644957\n",
            "Train Epoch: 6 [39824/50000 (80%)]\tLoss: 0.999609\n",
            "Train Epoch: 6 [40304/50000 (81%)]\tLoss: 0.742707\n",
            "Train Epoch: 6 [40784/50000 (82%)]\tLoss: 0.698975\n",
            "Train Epoch: 6 [41264/50000 (83%)]\tLoss: 0.473194\n",
            "Train Epoch: 6 [41744/50000 (83%)]\tLoss: 0.556018\n",
            "Train Epoch: 6 [42224/50000 (84%)]\tLoss: 0.582004\n",
            "Train Epoch: 6 [42704/50000 (85%)]\tLoss: 0.531897\n",
            "Train Epoch: 6 [43184/50000 (86%)]\tLoss: 0.782586\n",
            "Train Epoch: 6 [43664/50000 (87%)]\tLoss: 0.856297\n",
            "Train Epoch: 6 [44144/50000 (88%)]\tLoss: 0.425160\n",
            "Train Epoch: 6 [44624/50000 (89%)]\tLoss: 0.475892\n",
            "Train Epoch: 6 [45104/50000 (90%)]\tLoss: 0.712463\n",
            "Train Epoch: 6 [45584/50000 (91%)]\tLoss: 0.531495\n",
            "Train Epoch: 6 [46064/50000 (92%)]\tLoss: 0.612062\n",
            "Train Epoch: 6 [46544/50000 (93%)]\tLoss: 0.340478\n",
            "Train Epoch: 6 [47024/50000 (94%)]\tLoss: 0.523272\n",
            "Train Epoch: 6 [47504/50000 (95%)]\tLoss: 0.544041\n",
            "Train Epoch: 6 [47984/50000 (96%)]\tLoss: 0.457541\n",
            "Train Epoch: 6 [48464/50000 (97%)]\tLoss: 0.522600\n",
            "Train Epoch: 6 [48944/50000 (98%)]\tLoss: 0.240875\n",
            "Train Epoch: 6 [49424/50000 (99%)]\tLoss: 0.992874\n",
            "Train Epoch: 6 [49904/50000 (100%)]\tLoss: 0.170726\n",
            "---------------------------------------\n",
            "Training time for epoch 6: 20.73 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch6): Average loss: 0.8092, Accuracy: 7255/10000 (73%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 7 [464/50000 (1%)]\tLoss: 0.535707\n",
            "Train Epoch: 7 [944/50000 (2%)]\tLoss: 0.215334\n",
            "Train Epoch: 7 [1424/50000 (3%)]\tLoss: 0.676983\n",
            "Train Epoch: 7 [1904/50000 (4%)]\tLoss: 0.382057\n",
            "Train Epoch: 7 [2384/50000 (5%)]\tLoss: 0.630497\n",
            "Train Epoch: 7 [2864/50000 (6%)]\tLoss: 0.772830\n",
            "Train Epoch: 7 [3344/50000 (7%)]\tLoss: 0.878914\n",
            "Train Epoch: 7 [3824/50000 (8%)]\tLoss: 0.241543\n",
            "Train Epoch: 7 [4304/50000 (9%)]\tLoss: 0.486412\n",
            "Train Epoch: 7 [4784/50000 (10%)]\tLoss: 0.148722\n",
            "Train Epoch: 7 [5264/50000 (11%)]\tLoss: 0.254406\n",
            "Train Epoch: 7 [5744/50000 (11%)]\tLoss: 0.549019\n",
            "Train Epoch: 7 [6224/50000 (12%)]\tLoss: 0.211260\n",
            "Train Epoch: 7 [6704/50000 (13%)]\tLoss: 0.313474\n",
            "Train Epoch: 7 [7184/50000 (14%)]\tLoss: 0.597323\n",
            "Train Epoch: 7 [7664/50000 (15%)]\tLoss: 0.580205\n",
            "Train Epoch: 7 [8144/50000 (16%)]\tLoss: 0.983026\n",
            "Train Epoch: 7 [8624/50000 (17%)]\tLoss: 0.378267\n",
            "Train Epoch: 7 [9104/50000 (18%)]\tLoss: 0.618462\n",
            "Train Epoch: 7 [9584/50000 (19%)]\tLoss: 0.365543\n",
            "Train Epoch: 7 [10064/50000 (20%)]\tLoss: 0.487112\n",
            "Train Epoch: 7 [10544/50000 (21%)]\tLoss: 0.627819\n",
            "Train Epoch: 7 [11024/50000 (22%)]\tLoss: 0.294006\n",
            "Train Epoch: 7 [11504/50000 (23%)]\tLoss: 0.343611\n",
            "Train Epoch: 7 [11984/50000 (24%)]\tLoss: 0.627731\n",
            "Train Epoch: 7 [12464/50000 (25%)]\tLoss: 0.140512\n",
            "Train Epoch: 7 [12944/50000 (26%)]\tLoss: 0.278153\n",
            "Train Epoch: 7 [13424/50000 (27%)]\tLoss: 0.637410\n",
            "Train Epoch: 7 [13904/50000 (28%)]\tLoss: 0.305578\n",
            "Train Epoch: 7 [14384/50000 (29%)]\tLoss: 0.445395\n",
            "Train Epoch: 7 [14864/50000 (30%)]\tLoss: 0.214844\n",
            "Train Epoch: 7 [15344/50000 (31%)]\tLoss: 0.276817\n",
            "Train Epoch: 7 [15824/50000 (32%)]\tLoss: 0.519044\n",
            "Train Epoch: 7 [16304/50000 (33%)]\tLoss: 0.854218\n",
            "Train Epoch: 7 [16784/50000 (34%)]\tLoss: 0.642582\n",
            "Train Epoch: 7 [17264/50000 (35%)]\tLoss: 0.407571\n",
            "Train Epoch: 7 [17744/50000 (35%)]\tLoss: 0.529482\n",
            "Train Epoch: 7 [18224/50000 (36%)]\tLoss: 0.389312\n",
            "Train Epoch: 7 [18704/50000 (37%)]\tLoss: 0.535035\n",
            "Train Epoch: 7 [19184/50000 (38%)]\tLoss: 0.482906\n",
            "Train Epoch: 7 [19664/50000 (39%)]\tLoss: 1.157376\n",
            "Train Epoch: 7 [20144/50000 (40%)]\tLoss: 0.514740\n",
            "Train Epoch: 7 [20624/50000 (41%)]\tLoss: 0.392480\n",
            "Train Epoch: 7 [21104/50000 (42%)]\tLoss: 0.620166\n",
            "Train Epoch: 7 [21584/50000 (43%)]\tLoss: 0.263018\n",
            "Train Epoch: 7 [22064/50000 (44%)]\tLoss: 0.402867\n",
            "Train Epoch: 7 [22544/50000 (45%)]\tLoss: 0.240375\n",
            "Train Epoch: 7 [23024/50000 (46%)]\tLoss: 0.272240\n",
            "Train Epoch: 7 [23504/50000 (47%)]\tLoss: 0.594736\n",
            "Train Epoch: 7 [23984/50000 (48%)]\tLoss: 0.352487\n",
            "Train Epoch: 7 [24464/50000 (49%)]\tLoss: 0.604019\n",
            "Train Epoch: 7 [24944/50000 (50%)]\tLoss: 0.787993\n",
            "Train Epoch: 7 [25424/50000 (51%)]\tLoss: 0.367338\n",
            "Train Epoch: 7 [25904/50000 (52%)]\tLoss: 0.878923\n",
            "Train Epoch: 7 [26384/50000 (53%)]\tLoss: 0.644670\n",
            "Train Epoch: 7 [26864/50000 (54%)]\tLoss: 0.272373\n",
            "Train Epoch: 7 [27344/50000 (55%)]\tLoss: 0.394329\n",
            "Train Epoch: 7 [27824/50000 (56%)]\tLoss: 0.474715\n",
            "Train Epoch: 7 [28304/50000 (57%)]\tLoss: 0.456316\n",
            "Train Epoch: 7 [28784/50000 (58%)]\tLoss: 0.335948\n",
            "Train Epoch: 7 [29264/50000 (59%)]\tLoss: 0.536719\n",
            "Train Epoch: 7 [29744/50000 (59%)]\tLoss: 0.502772\n",
            "Train Epoch: 7 [30224/50000 (60%)]\tLoss: 0.462784\n",
            "Train Epoch: 7 [30704/50000 (61%)]\tLoss: 0.751642\n",
            "Train Epoch: 7 [31184/50000 (62%)]\tLoss: 0.655851\n",
            "Train Epoch: 7 [31664/50000 (63%)]\tLoss: 0.634338\n",
            "Train Epoch: 7 [32144/50000 (64%)]\tLoss: 0.494090\n",
            "Train Epoch: 7 [32624/50000 (65%)]\tLoss: 0.411553\n",
            "Train Epoch: 7 [33104/50000 (66%)]\tLoss: 0.216422\n",
            "Train Epoch: 7 [33584/50000 (67%)]\tLoss: 0.528506\n",
            "Train Epoch: 7 [34064/50000 (68%)]\tLoss: 0.963902\n",
            "Train Epoch: 7 [34544/50000 (69%)]\tLoss: 1.021362\n",
            "Train Epoch: 7 [35024/50000 (70%)]\tLoss: 0.185392\n",
            "Train Epoch: 7 [35504/50000 (71%)]\tLoss: 1.022117\n",
            "Train Epoch: 7 [35984/50000 (72%)]\tLoss: 0.375695\n",
            "Train Epoch: 7 [36464/50000 (73%)]\tLoss: 0.354446\n",
            "Train Epoch: 7 [36944/50000 (74%)]\tLoss: 0.311887\n",
            "Train Epoch: 7 [37424/50000 (75%)]\tLoss: 0.605983\n",
            "Train Epoch: 7 [37904/50000 (76%)]\tLoss: 0.566835\n",
            "Train Epoch: 7 [38384/50000 (77%)]\tLoss: 0.421055\n",
            "Train Epoch: 7 [38864/50000 (78%)]\tLoss: 0.561441\n",
            "Train Epoch: 7 [39344/50000 (79%)]\tLoss: 0.617357\n",
            "Train Epoch: 7 [39824/50000 (80%)]\tLoss: 0.481478\n",
            "Train Epoch: 7 [40304/50000 (81%)]\tLoss: 0.899385\n",
            "Train Epoch: 7 [40784/50000 (82%)]\tLoss: 1.046796\n",
            "Train Epoch: 7 [41264/50000 (83%)]\tLoss: 0.549261\n",
            "Train Epoch: 7 [41744/50000 (83%)]\tLoss: 0.384810\n",
            "Train Epoch: 7 [42224/50000 (84%)]\tLoss: 0.405407\n",
            "Train Epoch: 7 [42704/50000 (85%)]\tLoss: 0.522324\n",
            "Train Epoch: 7 [43184/50000 (86%)]\tLoss: 0.404243\n",
            "Train Epoch: 7 [43664/50000 (87%)]\tLoss: 0.628984\n",
            "Train Epoch: 7 [44144/50000 (88%)]\tLoss: 0.672335\n",
            "Train Epoch: 7 [44624/50000 (89%)]\tLoss: 0.762516\n",
            "Train Epoch: 7 [45104/50000 (90%)]\tLoss: 0.258733\n",
            "Train Epoch: 7 [45584/50000 (91%)]\tLoss: 0.466636\n",
            "Train Epoch: 7 [46064/50000 (92%)]\tLoss: 0.442493\n",
            "Train Epoch: 7 [46544/50000 (93%)]\tLoss: 0.665612\n",
            "Train Epoch: 7 [47024/50000 (94%)]\tLoss: 0.315926\n",
            "Train Epoch: 7 [47504/50000 (95%)]\tLoss: 0.469642\n",
            "Train Epoch: 7 [47984/50000 (96%)]\tLoss: 0.598612\n",
            "Train Epoch: 7 [48464/50000 (97%)]\tLoss: 0.523018\n",
            "Train Epoch: 7 [48944/50000 (98%)]\tLoss: 1.077409\n",
            "Train Epoch: 7 [49424/50000 (99%)]\tLoss: 0.374622\n",
            "Train Epoch: 7 [49904/50000 (100%)]\tLoss: 0.269973\n",
            "---------------------------------------\n",
            "Training time for epoch 7: 20.35 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch7): Average loss: 0.7627, Accuracy: 7389/10000 (74%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 8 [464/50000 (1%)]\tLoss: 0.287442\n",
            "Train Epoch: 8 [944/50000 (2%)]\tLoss: 0.225272\n",
            "Train Epoch: 8 [1424/50000 (3%)]\tLoss: 0.096273\n",
            "Train Epoch: 8 [1904/50000 (4%)]\tLoss: 0.620653\n",
            "Train Epoch: 8 [2384/50000 (5%)]\tLoss: 0.185478\n",
            "Train Epoch: 8 [2864/50000 (6%)]\tLoss: 0.393231\n",
            "Train Epoch: 8 [3344/50000 (7%)]\tLoss: 0.629326\n",
            "Train Epoch: 8 [3824/50000 (8%)]\tLoss: 0.191051\n",
            "Train Epoch: 8 [4304/50000 (9%)]\tLoss: 0.245964\n",
            "Train Epoch: 8 [4784/50000 (10%)]\tLoss: 0.256101\n",
            "Train Epoch: 8 [5264/50000 (11%)]\tLoss: 0.294631\n",
            "Train Epoch: 8 [5744/50000 (11%)]\tLoss: 0.702215\n",
            "Train Epoch: 8 [6224/50000 (12%)]\tLoss: 0.497561\n",
            "Train Epoch: 8 [6704/50000 (13%)]\tLoss: 0.384987\n",
            "Train Epoch: 8 [7184/50000 (14%)]\tLoss: 0.058804\n",
            "Train Epoch: 8 [7664/50000 (15%)]\tLoss: 1.107626\n",
            "Train Epoch: 8 [8144/50000 (16%)]\tLoss: 0.186051\n",
            "Train Epoch: 8 [8624/50000 (17%)]\tLoss: 0.521853\n",
            "Train Epoch: 8 [9104/50000 (18%)]\tLoss: 0.115738\n",
            "Train Epoch: 8 [9584/50000 (19%)]\tLoss: 0.671610\n",
            "Train Epoch: 8 [10064/50000 (20%)]\tLoss: 0.339100\n",
            "Train Epoch: 8 [10544/50000 (21%)]\tLoss: 0.345403\n",
            "Train Epoch: 8 [11024/50000 (22%)]\tLoss: 0.504333\n",
            "Train Epoch: 8 [11504/50000 (23%)]\tLoss: 0.354273\n",
            "Train Epoch: 8 [11984/50000 (24%)]\tLoss: 0.446065\n",
            "Train Epoch: 8 [12464/50000 (25%)]\tLoss: 0.946873\n",
            "Train Epoch: 8 [12944/50000 (26%)]\tLoss: 0.295253\n",
            "Train Epoch: 8 [13424/50000 (27%)]\tLoss: 0.420829\n",
            "Train Epoch: 8 [13904/50000 (28%)]\tLoss: 0.569591\n",
            "Train Epoch: 8 [14384/50000 (29%)]\tLoss: 0.279390\n",
            "Train Epoch: 8 [14864/50000 (30%)]\tLoss: 0.570640\n",
            "Train Epoch: 8 [15344/50000 (31%)]\tLoss: 0.289552\n",
            "Train Epoch: 8 [15824/50000 (32%)]\tLoss: 0.189211\n",
            "Train Epoch: 8 [16304/50000 (33%)]\tLoss: 0.512752\n",
            "Train Epoch: 8 [16784/50000 (34%)]\tLoss: 0.429909\n",
            "Train Epoch: 8 [17264/50000 (35%)]\tLoss: 0.292915\n",
            "Train Epoch: 8 [17744/50000 (35%)]\tLoss: 0.241553\n",
            "Train Epoch: 8 [18224/50000 (36%)]\tLoss: 0.396135\n",
            "Train Epoch: 8 [18704/50000 (37%)]\tLoss: 0.610804\n",
            "Train Epoch: 8 [19184/50000 (38%)]\tLoss: 0.284552\n",
            "Train Epoch: 8 [19664/50000 (39%)]\tLoss: 0.293272\n",
            "Train Epoch: 8 [20144/50000 (40%)]\tLoss: 0.534748\n",
            "Train Epoch: 8 [20624/50000 (41%)]\tLoss: 0.586332\n",
            "Train Epoch: 8 [21104/50000 (42%)]\tLoss: 0.476004\n",
            "Train Epoch: 8 [21584/50000 (43%)]\tLoss: 0.439596\n",
            "Train Epoch: 8 [22064/50000 (44%)]\tLoss: 0.676524\n",
            "Train Epoch: 8 [22544/50000 (45%)]\tLoss: 0.878051\n",
            "Train Epoch: 8 [23024/50000 (46%)]\tLoss: 0.410243\n",
            "Train Epoch: 8 [23504/50000 (47%)]\tLoss: 0.470529\n",
            "Train Epoch: 8 [23984/50000 (48%)]\tLoss: 0.596125\n",
            "Train Epoch: 8 [24464/50000 (49%)]\tLoss: 0.540255\n",
            "Train Epoch: 8 [24944/50000 (50%)]\tLoss: 0.463087\n",
            "Train Epoch: 8 [25424/50000 (51%)]\tLoss: 0.180612\n",
            "Train Epoch: 8 [25904/50000 (52%)]\tLoss: 0.336980\n",
            "Train Epoch: 8 [26384/50000 (53%)]\tLoss: 0.321877\n",
            "Train Epoch: 8 [26864/50000 (54%)]\tLoss: 0.215402\n",
            "Train Epoch: 8 [27344/50000 (55%)]\tLoss: 0.337533\n",
            "Train Epoch: 8 [27824/50000 (56%)]\tLoss: 0.158312\n",
            "Train Epoch: 8 [28304/50000 (57%)]\tLoss: 0.102677\n",
            "Train Epoch: 8 [28784/50000 (58%)]\tLoss: 0.358672\n",
            "Train Epoch: 8 [29264/50000 (59%)]\tLoss: 0.579088\n",
            "Train Epoch: 8 [29744/50000 (59%)]\tLoss: 0.330636\n",
            "Train Epoch: 8 [30224/50000 (60%)]\tLoss: 0.387429\n",
            "Train Epoch: 8 [30704/50000 (61%)]\tLoss: 0.117975\n",
            "Train Epoch: 8 [31184/50000 (62%)]\tLoss: 0.516406\n",
            "Train Epoch: 8 [31664/50000 (63%)]\tLoss: 0.206512\n",
            "Train Epoch: 8 [32144/50000 (64%)]\tLoss: 0.430920\n",
            "Train Epoch: 8 [32624/50000 (65%)]\tLoss: 0.309350\n",
            "Train Epoch: 8 [33104/50000 (66%)]\tLoss: 0.354100\n",
            "Train Epoch: 8 [33584/50000 (67%)]\tLoss: 0.416134\n",
            "Train Epoch: 8 [34064/50000 (68%)]\tLoss: 0.393579\n",
            "Train Epoch: 8 [34544/50000 (69%)]\tLoss: 0.224069\n",
            "Train Epoch: 8 [35024/50000 (70%)]\tLoss: 0.670710\n",
            "Train Epoch: 8 [35504/50000 (71%)]\tLoss: 0.531537\n",
            "Train Epoch: 8 [35984/50000 (72%)]\tLoss: 0.285415\n",
            "Train Epoch: 8 [36464/50000 (73%)]\tLoss: 0.734916\n",
            "Train Epoch: 8 [36944/50000 (74%)]\tLoss: 0.346450\n",
            "Train Epoch: 8 [37424/50000 (75%)]\tLoss: 0.458673\n",
            "Train Epoch: 8 [37904/50000 (76%)]\tLoss: 0.215952\n",
            "Train Epoch: 8 [38384/50000 (77%)]\tLoss: 0.536439\n",
            "Train Epoch: 8 [38864/50000 (78%)]\tLoss: 0.397816\n",
            "Train Epoch: 8 [39344/50000 (79%)]\tLoss: 0.521562\n",
            "Train Epoch: 8 [39824/50000 (80%)]\tLoss: 0.603158\n",
            "Train Epoch: 8 [40304/50000 (81%)]\tLoss: 0.399677\n",
            "Train Epoch: 8 [40784/50000 (82%)]\tLoss: 0.518918\n",
            "Train Epoch: 8 [41264/50000 (83%)]\tLoss: 0.463563\n",
            "Train Epoch: 8 [41744/50000 (83%)]\tLoss: 0.344357\n",
            "Train Epoch: 8 [42224/50000 (84%)]\tLoss: 0.340930\n",
            "Train Epoch: 8 [42704/50000 (85%)]\tLoss: 1.000071\n",
            "Train Epoch: 8 [43184/50000 (86%)]\tLoss: 0.668361\n",
            "Train Epoch: 8 [43664/50000 (87%)]\tLoss: 1.251418\n",
            "Train Epoch: 8 [44144/50000 (88%)]\tLoss: 0.222126\n",
            "Train Epoch: 8 [44624/50000 (89%)]\tLoss: 0.205625\n",
            "Train Epoch: 8 [45104/50000 (90%)]\tLoss: 0.292087\n",
            "Train Epoch: 8 [45584/50000 (91%)]\tLoss: 0.475031\n",
            "Train Epoch: 8 [46064/50000 (92%)]\tLoss: 0.613248\n",
            "Train Epoch: 8 [46544/50000 (93%)]\tLoss: 0.216929\n",
            "Train Epoch: 8 [47024/50000 (94%)]\tLoss: 0.837884\n",
            "Train Epoch: 8 [47504/50000 (95%)]\tLoss: 0.513411\n",
            "Train Epoch: 8 [47984/50000 (96%)]\tLoss: 0.604901\n",
            "Train Epoch: 8 [48464/50000 (97%)]\tLoss: 0.564097\n",
            "Train Epoch: 8 [48944/50000 (98%)]\tLoss: 0.519546\n",
            "Train Epoch: 8 [49424/50000 (99%)]\tLoss: 0.626848\n",
            "Train Epoch: 8 [49904/50000 (100%)]\tLoss: 0.528943\n",
            "---------------------------------------\n",
            "Training time for epoch 8: 21.40 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch8): Average loss: 0.7645, Accuracy: 7457/10000 (75%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 9 [464/50000 (1%)]\tLoss: 0.501197\n",
            "Train Epoch: 9 [944/50000 (2%)]\tLoss: 0.509353\n",
            "Train Epoch: 9 [1424/50000 (3%)]\tLoss: 0.117677\n",
            "Train Epoch: 9 [1904/50000 (4%)]\tLoss: 0.474120\n",
            "Train Epoch: 9 [2384/50000 (5%)]\tLoss: 0.318986\n",
            "Train Epoch: 9 [2864/50000 (6%)]\tLoss: 0.236190\n",
            "Train Epoch: 9 [3344/50000 (7%)]\tLoss: 0.500323\n",
            "Train Epoch: 9 [3824/50000 (8%)]\tLoss: 0.537345\n",
            "Train Epoch: 9 [4304/50000 (9%)]\tLoss: 0.269785\n",
            "Train Epoch: 9 [4784/50000 (10%)]\tLoss: 0.350719\n",
            "Train Epoch: 9 [5264/50000 (11%)]\tLoss: 0.202307\n",
            "Train Epoch: 9 [5744/50000 (11%)]\tLoss: 0.235334\n",
            "Train Epoch: 9 [6224/50000 (12%)]\tLoss: 0.514117\n",
            "Train Epoch: 9 [6704/50000 (13%)]\tLoss: 0.795427\n",
            "Train Epoch: 9 [7184/50000 (14%)]\tLoss: 0.638936\n",
            "Train Epoch: 9 [7664/50000 (15%)]\tLoss: 0.332519\n",
            "Train Epoch: 9 [8144/50000 (16%)]\tLoss: 0.244295\n",
            "Train Epoch: 9 [8624/50000 (17%)]\tLoss: 0.218136\n",
            "Train Epoch: 9 [9104/50000 (18%)]\tLoss: 0.667812\n",
            "Train Epoch: 9 [9584/50000 (19%)]\tLoss: 0.422839\n",
            "Train Epoch: 9 [10064/50000 (20%)]\tLoss: 0.386605\n",
            "Train Epoch: 9 [10544/50000 (21%)]\tLoss: 0.648674\n",
            "Train Epoch: 9 [11024/50000 (22%)]\tLoss: 0.172781\n",
            "Train Epoch: 9 [11504/50000 (23%)]\tLoss: 0.436851\n",
            "Train Epoch: 9 [11984/50000 (24%)]\tLoss: 0.313329\n",
            "Train Epoch: 9 [12464/50000 (25%)]\tLoss: 0.082587\n",
            "Train Epoch: 9 [12944/50000 (26%)]\tLoss: 0.498644\n",
            "Train Epoch: 9 [13424/50000 (27%)]\tLoss: 0.102944\n",
            "Train Epoch: 9 [13904/50000 (28%)]\tLoss: 0.266995\n",
            "Train Epoch: 9 [14384/50000 (29%)]\tLoss: 0.333159\n",
            "Train Epoch: 9 [14864/50000 (30%)]\tLoss: 0.475943\n",
            "Train Epoch: 9 [15344/50000 (31%)]\tLoss: 0.480157\n",
            "Train Epoch: 9 [15824/50000 (32%)]\tLoss: 0.403138\n",
            "Train Epoch: 9 [16304/50000 (33%)]\tLoss: 0.689279\n",
            "Train Epoch: 9 [16784/50000 (34%)]\tLoss: 0.664686\n",
            "Train Epoch: 9 [17264/50000 (35%)]\tLoss: 0.359415\n",
            "Train Epoch: 9 [17744/50000 (35%)]\tLoss: 0.282156\n",
            "Train Epoch: 9 [18224/50000 (36%)]\tLoss: 0.309778\n",
            "Train Epoch: 9 [18704/50000 (37%)]\tLoss: 0.672469\n",
            "Train Epoch: 9 [19184/50000 (38%)]\tLoss: 0.379371\n",
            "Train Epoch: 9 [19664/50000 (39%)]\tLoss: 0.602121\n",
            "Train Epoch: 9 [20144/50000 (40%)]\tLoss: 0.134989\n",
            "Train Epoch: 9 [20624/50000 (41%)]\tLoss: 0.322896\n",
            "Train Epoch: 9 [21104/50000 (42%)]\tLoss: 0.784700\n",
            "Train Epoch: 9 [21584/50000 (43%)]\tLoss: 0.804570\n",
            "Train Epoch: 9 [22064/50000 (44%)]\tLoss: 0.510308\n",
            "Train Epoch: 9 [22544/50000 (45%)]\tLoss: 0.096707\n",
            "Train Epoch: 9 [23024/50000 (46%)]\tLoss: 0.537831\n",
            "Train Epoch: 9 [23504/50000 (47%)]\tLoss: 0.396674\n",
            "Train Epoch: 9 [23984/50000 (48%)]\tLoss: 0.148035\n",
            "Train Epoch: 9 [24464/50000 (49%)]\tLoss: 0.120389\n",
            "Train Epoch: 9 [24944/50000 (50%)]\tLoss: 0.120632\n",
            "Train Epoch: 9 [25424/50000 (51%)]\tLoss: 0.804890\n",
            "Train Epoch: 9 [25904/50000 (52%)]\tLoss: 0.246943\n",
            "Train Epoch: 9 [26384/50000 (53%)]\tLoss: 0.175200\n",
            "Train Epoch: 9 [26864/50000 (54%)]\tLoss: 0.320717\n",
            "Train Epoch: 9 [27344/50000 (55%)]\tLoss: 0.527123\n",
            "Train Epoch: 9 [27824/50000 (56%)]\tLoss: 0.622985\n",
            "Train Epoch: 9 [28304/50000 (57%)]\tLoss: 0.157132\n",
            "Train Epoch: 9 [28784/50000 (58%)]\tLoss: 0.454810\n",
            "Train Epoch: 9 [29264/50000 (59%)]\tLoss: 0.651606\n",
            "Train Epoch: 9 [29744/50000 (59%)]\tLoss: 0.598888\n",
            "Train Epoch: 9 [30224/50000 (60%)]\tLoss: 0.501114\n",
            "Train Epoch: 9 [30704/50000 (61%)]\tLoss: 0.428271\n",
            "Train Epoch: 9 [31184/50000 (62%)]\tLoss: 0.362440\n",
            "Train Epoch: 9 [31664/50000 (63%)]\tLoss: 0.401695\n",
            "Train Epoch: 9 [32144/50000 (64%)]\tLoss: 0.810836\n",
            "Train Epoch: 9 [32624/50000 (65%)]\tLoss: 0.628812\n",
            "Train Epoch: 9 [33104/50000 (66%)]\tLoss: 0.280918\n",
            "Train Epoch: 9 [33584/50000 (67%)]\tLoss: 0.206127\n",
            "Train Epoch: 9 [34064/50000 (68%)]\tLoss: 0.212165\n",
            "Train Epoch: 9 [34544/50000 (69%)]\tLoss: 0.620685\n",
            "Train Epoch: 9 [35024/50000 (70%)]\tLoss: 0.472315\n",
            "Train Epoch: 9 [35504/50000 (71%)]\tLoss: 0.317578\n",
            "Train Epoch: 9 [35984/50000 (72%)]\tLoss: 0.059404\n",
            "Train Epoch: 9 [36464/50000 (73%)]\tLoss: 0.179330\n",
            "Train Epoch: 9 [36944/50000 (74%)]\tLoss: 0.635255\n",
            "Train Epoch: 9 [37424/50000 (75%)]\tLoss: 0.554224\n",
            "Train Epoch: 9 [37904/50000 (76%)]\tLoss: 0.142345\n",
            "Train Epoch: 9 [38384/50000 (77%)]\tLoss: 0.082365\n",
            "Train Epoch: 9 [38864/50000 (78%)]\tLoss: 0.219211\n",
            "Train Epoch: 9 [39344/50000 (79%)]\tLoss: 0.503488\n",
            "Train Epoch: 9 [39824/50000 (80%)]\tLoss: 0.249838\n",
            "Train Epoch: 9 [40304/50000 (81%)]\tLoss: 0.055303\n",
            "Train Epoch: 9 [40784/50000 (82%)]\tLoss: 0.176164\n",
            "Train Epoch: 9 [41264/50000 (83%)]\tLoss: 0.169513\n",
            "Train Epoch: 9 [41744/50000 (83%)]\tLoss: 0.093689\n",
            "Train Epoch: 9 [42224/50000 (84%)]\tLoss: 0.109151\n",
            "Train Epoch: 9 [42704/50000 (85%)]\tLoss: 0.701150\n",
            "Train Epoch: 9 [43184/50000 (86%)]\tLoss: 0.509923\n",
            "Train Epoch: 9 [43664/50000 (87%)]\tLoss: 0.055304\n",
            "Train Epoch: 9 [44144/50000 (88%)]\tLoss: 0.433238\n",
            "Train Epoch: 9 [44624/50000 (89%)]\tLoss: 0.288847\n",
            "Train Epoch: 9 [45104/50000 (90%)]\tLoss: 0.273046\n",
            "Train Epoch: 9 [45584/50000 (91%)]\tLoss: 0.438690\n",
            "Train Epoch: 9 [46064/50000 (92%)]\tLoss: 0.345606\n",
            "Train Epoch: 9 [46544/50000 (93%)]\tLoss: 0.215958\n",
            "Train Epoch: 9 [47024/50000 (94%)]\tLoss: 1.098444\n",
            "Train Epoch: 9 [47504/50000 (95%)]\tLoss: 0.542366\n",
            "Train Epoch: 9 [47984/50000 (96%)]\tLoss: 0.336395\n",
            "Train Epoch: 9 [48464/50000 (97%)]\tLoss: 0.742541\n",
            "Train Epoch: 9 [48944/50000 (98%)]\tLoss: 0.170260\n",
            "Train Epoch: 9 [49424/50000 (99%)]\tLoss: 0.757998\n",
            "Train Epoch: 9 [49904/50000 (100%)]\tLoss: 0.817834\n",
            "---------------------------------------\n",
            "Training time for epoch 9: 19.87 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch9): Average loss: 0.8246, Accuracy: 7345/10000 (73%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 10 [464/50000 (1%)]\tLoss: 0.592140\n",
            "Train Epoch: 10 [944/50000 (2%)]\tLoss: 0.134693\n",
            "Train Epoch: 10 [1424/50000 (3%)]\tLoss: 0.475860\n",
            "Train Epoch: 10 [1904/50000 (4%)]\tLoss: 0.118202\n",
            "Train Epoch: 10 [2384/50000 (5%)]\tLoss: 0.455481\n",
            "Train Epoch: 10 [2864/50000 (6%)]\tLoss: 0.076551\n",
            "Train Epoch: 10 [3344/50000 (7%)]\tLoss: 0.392899\n",
            "Train Epoch: 10 [3824/50000 (8%)]\tLoss: 0.230064\n",
            "Train Epoch: 10 [4304/50000 (9%)]\tLoss: 0.174266\n",
            "Train Epoch: 10 [4784/50000 (10%)]\tLoss: 0.226430\n",
            "Train Epoch: 10 [5264/50000 (11%)]\tLoss: 0.233769\n",
            "Train Epoch: 10 [5744/50000 (11%)]\tLoss: 0.210413\n",
            "Train Epoch: 10 [6224/50000 (12%)]\tLoss: 0.322290\n",
            "Train Epoch: 10 [6704/50000 (13%)]\tLoss: 0.166600\n",
            "Train Epoch: 10 [7184/50000 (14%)]\tLoss: 0.289772\n",
            "Train Epoch: 10 [7664/50000 (15%)]\tLoss: 0.243288\n",
            "Train Epoch: 10 [8144/50000 (16%)]\tLoss: 0.130500\n",
            "Train Epoch: 10 [8624/50000 (17%)]\tLoss: 0.258054\n",
            "Train Epoch: 10 [9104/50000 (18%)]\tLoss: 0.559120\n",
            "Train Epoch: 10 [9584/50000 (19%)]\tLoss: 0.295395\n",
            "Train Epoch: 10 [10064/50000 (20%)]\tLoss: 0.321976\n",
            "Train Epoch: 10 [10544/50000 (21%)]\tLoss: 0.323405\n",
            "Train Epoch: 10 [11024/50000 (22%)]\tLoss: 0.724279\n",
            "Train Epoch: 10 [11504/50000 (23%)]\tLoss: 0.143508\n",
            "Train Epoch: 10 [11984/50000 (24%)]\tLoss: 0.486674\n",
            "Train Epoch: 10 [12464/50000 (25%)]\tLoss: 0.158928\n",
            "Train Epoch: 10 [12944/50000 (26%)]\tLoss: 0.279313\n",
            "Train Epoch: 10 [13424/50000 (27%)]\tLoss: 0.409270\n",
            "Train Epoch: 10 [13904/50000 (28%)]\tLoss: 0.133231\n",
            "Train Epoch: 10 [14384/50000 (29%)]\tLoss: 0.334799\n",
            "Train Epoch: 10 [14864/50000 (30%)]\tLoss: 0.492006\n",
            "Train Epoch: 10 [15344/50000 (31%)]\tLoss: 0.133648\n",
            "Train Epoch: 10 [15824/50000 (32%)]\tLoss: 0.152833\n",
            "Train Epoch: 10 [16304/50000 (33%)]\tLoss: 0.340908\n",
            "Train Epoch: 10 [16784/50000 (34%)]\tLoss: 0.141788\n",
            "Train Epoch: 10 [17264/50000 (35%)]\tLoss: 0.672086\n",
            "Train Epoch: 10 [17744/50000 (35%)]\tLoss: 0.328223\n",
            "Train Epoch: 10 [18224/50000 (36%)]\tLoss: 0.194888\n",
            "Train Epoch: 10 [18704/50000 (37%)]\tLoss: 0.597069\n",
            "Train Epoch: 10 [19184/50000 (38%)]\tLoss: 0.549643\n",
            "Train Epoch: 10 [19664/50000 (39%)]\tLoss: 0.136719\n",
            "Train Epoch: 10 [20144/50000 (40%)]\tLoss: 0.234751\n",
            "Train Epoch: 10 [20624/50000 (41%)]\tLoss: 0.325950\n",
            "Train Epoch: 10 [21104/50000 (42%)]\tLoss: 0.457454\n",
            "Train Epoch: 10 [21584/50000 (43%)]\tLoss: 0.437476\n",
            "Train Epoch: 10 [22064/50000 (44%)]\tLoss: 0.112731\n",
            "Train Epoch: 10 [22544/50000 (45%)]\tLoss: 0.260645\n",
            "Train Epoch: 10 [23024/50000 (46%)]\tLoss: 0.320955\n",
            "Train Epoch: 10 [23504/50000 (47%)]\tLoss: 0.307155\n",
            "Train Epoch: 10 [23984/50000 (48%)]\tLoss: 0.591920\n",
            "Train Epoch: 10 [24464/50000 (49%)]\tLoss: 0.147943\n",
            "Train Epoch: 10 [24944/50000 (50%)]\tLoss: 0.596371\n",
            "Train Epoch: 10 [25424/50000 (51%)]\tLoss: 0.326909\n",
            "Train Epoch: 10 [25904/50000 (52%)]\tLoss: 0.567917\n",
            "Train Epoch: 10 [26384/50000 (53%)]\tLoss: 0.250210\n",
            "Train Epoch: 10 [26864/50000 (54%)]\tLoss: 0.285499\n",
            "Train Epoch: 10 [27344/50000 (55%)]\tLoss: 0.303172\n",
            "Train Epoch: 10 [27824/50000 (56%)]\tLoss: 0.353375\n",
            "Train Epoch: 10 [28304/50000 (57%)]\tLoss: 0.318909\n",
            "Train Epoch: 10 [28784/50000 (58%)]\tLoss: 0.398641\n",
            "Train Epoch: 10 [29264/50000 (59%)]\tLoss: 0.245881\n",
            "Train Epoch: 10 [29744/50000 (59%)]\tLoss: 0.182470\n",
            "Train Epoch: 10 [30224/50000 (60%)]\tLoss: 0.384429\n",
            "Train Epoch: 10 [30704/50000 (61%)]\tLoss: 0.164271\n",
            "Train Epoch: 10 [31184/50000 (62%)]\tLoss: 0.606239\n",
            "Train Epoch: 10 [31664/50000 (63%)]\tLoss: 0.339766\n",
            "Train Epoch: 10 [32144/50000 (64%)]\tLoss: 0.239331\n",
            "Train Epoch: 10 [32624/50000 (65%)]\tLoss: 0.409596\n",
            "Train Epoch: 10 [33104/50000 (66%)]\tLoss: 0.376395\n",
            "Train Epoch: 10 [33584/50000 (67%)]\tLoss: 0.666810\n",
            "Train Epoch: 10 [34064/50000 (68%)]\tLoss: 0.122670\n",
            "Train Epoch: 10 [34544/50000 (69%)]\tLoss: 0.340916\n",
            "Train Epoch: 10 [35024/50000 (70%)]\tLoss: 0.126290\n",
            "Train Epoch: 10 [35504/50000 (71%)]\tLoss: 0.572963\n",
            "Train Epoch: 10 [35984/50000 (72%)]\tLoss: 0.371137\n",
            "Train Epoch: 10 [36464/50000 (73%)]\tLoss: 0.406399\n",
            "Train Epoch: 10 [36944/50000 (74%)]\tLoss: 0.213963\n",
            "Train Epoch: 10 [37424/50000 (75%)]\tLoss: 0.365320\n",
            "Train Epoch: 10 [37904/50000 (76%)]\tLoss: 0.329305\n",
            "Train Epoch: 10 [38384/50000 (77%)]\tLoss: 0.230213\n",
            "Train Epoch: 10 [38864/50000 (78%)]\tLoss: 0.702219\n",
            "Train Epoch: 10 [39344/50000 (79%)]\tLoss: 0.340629\n",
            "Train Epoch: 10 [39824/50000 (80%)]\tLoss: 0.253887\n",
            "Train Epoch: 10 [40304/50000 (81%)]\tLoss: 0.565080\n",
            "Train Epoch: 10 [40784/50000 (82%)]\tLoss: 0.337538\n",
            "Train Epoch: 10 [41264/50000 (83%)]\tLoss: 0.307748\n",
            "Train Epoch: 10 [41744/50000 (83%)]\tLoss: 0.506493\n",
            "Train Epoch: 10 [42224/50000 (84%)]\tLoss: 0.198051\n",
            "Train Epoch: 10 [42704/50000 (85%)]\tLoss: 0.206950\n",
            "Train Epoch: 10 [43184/50000 (86%)]\tLoss: 0.358887\n",
            "Train Epoch: 10 [43664/50000 (87%)]\tLoss: 0.414735\n",
            "Train Epoch: 10 [44144/50000 (88%)]\tLoss: 0.299039\n",
            "Train Epoch: 10 [44624/50000 (89%)]\tLoss: 0.831927\n",
            "Train Epoch: 10 [45104/50000 (90%)]\tLoss: 0.603033\n",
            "Train Epoch: 10 [45584/50000 (91%)]\tLoss: 0.388025\n",
            "Train Epoch: 10 [46064/50000 (92%)]\tLoss: 0.481850\n",
            "Train Epoch: 10 [46544/50000 (93%)]\tLoss: 0.342134\n",
            "Train Epoch: 10 [47024/50000 (94%)]\tLoss: 0.460398\n",
            "Train Epoch: 10 [47504/50000 (95%)]\tLoss: 0.485864\n",
            "Train Epoch: 10 [47984/50000 (96%)]\tLoss: 0.291832\n",
            "Train Epoch: 10 [48464/50000 (97%)]\tLoss: 0.384883\n",
            "Train Epoch: 10 [48944/50000 (98%)]\tLoss: 0.335754\n",
            "Train Epoch: 10 [49424/50000 (99%)]\tLoss: 0.359978\n",
            "Train Epoch: 10 [49904/50000 (100%)]\tLoss: 0.423637\n",
            "---------------------------------------\n",
            "Training time for epoch 10: 20.73 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch10): Average loss: 0.8473, Accuracy: 7361/10000 (74%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 11 [464/50000 (1%)]\tLoss: 0.039999\n",
            "Train Epoch: 11 [944/50000 (2%)]\tLoss: 0.292259\n",
            "Train Epoch: 11 [1424/50000 (3%)]\tLoss: 0.328993\n",
            "Train Epoch: 11 [1904/50000 (4%)]\tLoss: 0.252307\n",
            "Train Epoch: 11 [2384/50000 (5%)]\tLoss: 0.296647\n",
            "Train Epoch: 11 [2864/50000 (6%)]\tLoss: 0.105659\n",
            "Train Epoch: 11 [3344/50000 (7%)]\tLoss: 0.057452\n",
            "Train Epoch: 11 [3824/50000 (8%)]\tLoss: 0.346610\n",
            "Train Epoch: 11 [4304/50000 (9%)]\tLoss: 0.161647\n",
            "Train Epoch: 11 [4784/50000 (10%)]\tLoss: 0.140894\n",
            "Train Epoch: 11 [5264/50000 (11%)]\tLoss: 0.394853\n",
            "Train Epoch: 11 [5744/50000 (11%)]\tLoss: 0.090852\n",
            "Train Epoch: 11 [6224/50000 (12%)]\tLoss: 0.474209\n",
            "Train Epoch: 11 [6704/50000 (13%)]\tLoss: 0.416100\n",
            "Train Epoch: 11 [7184/50000 (14%)]\tLoss: 0.205474\n",
            "Train Epoch: 11 [7664/50000 (15%)]\tLoss: 0.045127\n",
            "Train Epoch: 11 [8144/50000 (16%)]\tLoss: 0.146711\n",
            "Train Epoch: 11 [8624/50000 (17%)]\tLoss: 0.296703\n",
            "Train Epoch: 11 [9104/50000 (18%)]\tLoss: 0.027165\n",
            "Train Epoch: 11 [9584/50000 (19%)]\tLoss: 0.163472\n",
            "Train Epoch: 11 [10064/50000 (20%)]\tLoss: 0.218046\n",
            "Train Epoch: 11 [10544/50000 (21%)]\tLoss: 0.297658\n",
            "Train Epoch: 11 [11024/50000 (22%)]\tLoss: 0.281149\n",
            "Train Epoch: 11 [11504/50000 (23%)]\tLoss: 0.174132\n",
            "Train Epoch: 11 [11984/50000 (24%)]\tLoss: 0.111717\n",
            "Train Epoch: 11 [12464/50000 (25%)]\tLoss: 0.325943\n",
            "Train Epoch: 11 [12944/50000 (26%)]\tLoss: 0.377477\n",
            "Train Epoch: 11 [13424/50000 (27%)]\tLoss: 0.204295\n",
            "Train Epoch: 11 [13904/50000 (28%)]\tLoss: 0.384537\n",
            "Train Epoch: 11 [14384/50000 (29%)]\tLoss: 0.145435\n",
            "Train Epoch: 11 [14864/50000 (30%)]\tLoss: 0.134248\n",
            "Train Epoch: 11 [15344/50000 (31%)]\tLoss: 0.243666\n",
            "Train Epoch: 11 [15824/50000 (32%)]\tLoss: 0.188795\n",
            "Train Epoch: 11 [16304/50000 (33%)]\tLoss: 0.557135\n",
            "Train Epoch: 11 [16784/50000 (34%)]\tLoss: 0.266958\n",
            "Train Epoch: 11 [17264/50000 (35%)]\tLoss: 0.088439\n",
            "Train Epoch: 11 [17744/50000 (35%)]\tLoss: 0.441230\n",
            "Train Epoch: 11 [18224/50000 (36%)]\tLoss: 0.207447\n",
            "Train Epoch: 11 [18704/50000 (37%)]\tLoss: 0.305771\n",
            "Train Epoch: 11 [19184/50000 (38%)]\tLoss: 0.472789\n",
            "Train Epoch: 11 [19664/50000 (39%)]\tLoss: 0.380187\n",
            "Train Epoch: 11 [20144/50000 (40%)]\tLoss: 0.363501\n",
            "Train Epoch: 11 [20624/50000 (41%)]\tLoss: 0.310491\n",
            "Train Epoch: 11 [21104/50000 (42%)]\tLoss: 0.221767\n",
            "Train Epoch: 11 [21584/50000 (43%)]\tLoss: 0.253214\n",
            "Train Epoch: 11 [22064/50000 (44%)]\tLoss: 0.160885\n",
            "Train Epoch: 11 [22544/50000 (45%)]\tLoss: 0.302914\n",
            "Train Epoch: 11 [23024/50000 (46%)]\tLoss: 0.263732\n",
            "Train Epoch: 11 [23504/50000 (47%)]\tLoss: 0.321348\n",
            "Train Epoch: 11 [23984/50000 (48%)]\tLoss: 0.281959\n",
            "Train Epoch: 11 [24464/50000 (49%)]\tLoss: 0.116833\n",
            "Train Epoch: 11 [24944/50000 (50%)]\tLoss: 0.139867\n",
            "Train Epoch: 11 [25424/50000 (51%)]\tLoss: 0.147717\n",
            "Train Epoch: 11 [25904/50000 (52%)]\tLoss: 0.334528\n",
            "Train Epoch: 11 [26384/50000 (53%)]\tLoss: 0.291296\n",
            "Train Epoch: 11 [26864/50000 (54%)]\tLoss: 0.337674\n",
            "Train Epoch: 11 [27344/50000 (55%)]\tLoss: 0.257119\n",
            "Train Epoch: 11 [27824/50000 (56%)]\tLoss: 0.135364\n",
            "Train Epoch: 11 [28304/50000 (57%)]\tLoss: 0.121161\n",
            "Train Epoch: 11 [28784/50000 (58%)]\tLoss: 0.288104\n",
            "Train Epoch: 11 [29264/50000 (59%)]\tLoss: 0.260131\n",
            "Train Epoch: 11 [29744/50000 (59%)]\tLoss: 0.585024\n",
            "Train Epoch: 11 [30224/50000 (60%)]\tLoss: 0.062448\n",
            "Train Epoch: 11 [30704/50000 (61%)]\tLoss: 0.389246\n",
            "Train Epoch: 11 [31184/50000 (62%)]\tLoss: 0.458344\n",
            "Train Epoch: 11 [31664/50000 (63%)]\tLoss: 0.259603\n",
            "Train Epoch: 11 [32144/50000 (64%)]\tLoss: 0.493191\n",
            "Train Epoch: 11 [32624/50000 (65%)]\tLoss: 0.766958\n",
            "Train Epoch: 11 [33104/50000 (66%)]\tLoss: 0.268465\n",
            "Train Epoch: 11 [33584/50000 (67%)]\tLoss: 0.323755\n",
            "Train Epoch: 11 [34064/50000 (68%)]\tLoss: 0.220704\n",
            "Train Epoch: 11 [34544/50000 (69%)]\tLoss: 0.431228\n",
            "Train Epoch: 11 [35024/50000 (70%)]\tLoss: 0.620053\n",
            "Train Epoch: 11 [35504/50000 (71%)]\tLoss: 0.058884\n",
            "Train Epoch: 11 [35984/50000 (72%)]\tLoss: 0.171700\n",
            "Train Epoch: 11 [36464/50000 (73%)]\tLoss: 0.793558\n",
            "Train Epoch: 11 [36944/50000 (74%)]\tLoss: 0.138784\n",
            "Train Epoch: 11 [37424/50000 (75%)]\tLoss: 0.331020\n",
            "Train Epoch: 11 [37904/50000 (76%)]\tLoss: 0.350901\n",
            "Train Epoch: 11 [38384/50000 (77%)]\tLoss: 0.210682\n",
            "Train Epoch: 11 [38864/50000 (78%)]\tLoss: 0.243310\n",
            "Train Epoch: 11 [39344/50000 (79%)]\tLoss: 0.352850\n",
            "Train Epoch: 11 [39824/50000 (80%)]\tLoss: 0.187098\n",
            "Train Epoch: 11 [40304/50000 (81%)]\tLoss: 0.301011\n",
            "Train Epoch: 11 [40784/50000 (82%)]\tLoss: 0.347148\n",
            "Train Epoch: 11 [41264/50000 (83%)]\tLoss: 0.375596\n",
            "Train Epoch: 11 [41744/50000 (83%)]\tLoss: 0.383281\n",
            "Train Epoch: 11 [42224/50000 (84%)]\tLoss: 0.297269\n",
            "Train Epoch: 11 [42704/50000 (85%)]\tLoss: 0.580383\n",
            "Train Epoch: 11 [43184/50000 (86%)]\tLoss: 0.170713\n",
            "Train Epoch: 11 [43664/50000 (87%)]\tLoss: 0.154143\n",
            "Train Epoch: 11 [44144/50000 (88%)]\tLoss: 0.038461\n",
            "Train Epoch: 11 [44624/50000 (89%)]\tLoss: 0.185430\n",
            "Train Epoch: 11 [45104/50000 (90%)]\tLoss: 0.194415\n",
            "Train Epoch: 11 [45584/50000 (91%)]\tLoss: 0.178073\n",
            "Train Epoch: 11 [46064/50000 (92%)]\tLoss: 0.200488\n",
            "Train Epoch: 11 [46544/50000 (93%)]\tLoss: 0.146434\n",
            "Train Epoch: 11 [47024/50000 (94%)]\tLoss: 0.269244\n",
            "Train Epoch: 11 [47504/50000 (95%)]\tLoss: 0.304226\n",
            "Train Epoch: 11 [47984/50000 (96%)]\tLoss: 0.245830\n",
            "Train Epoch: 11 [48464/50000 (97%)]\tLoss: 0.265425\n",
            "Train Epoch: 11 [48944/50000 (98%)]\tLoss: 0.787388\n",
            "Train Epoch: 11 [49424/50000 (99%)]\tLoss: 0.144232\n",
            "Train Epoch: 11 [49904/50000 (100%)]\tLoss: 0.564276\n",
            "---------------------------------------\n",
            "Training time for epoch 11: 20.56 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch11): Average loss: 0.8212, Accuracy: 7542/10000 (75%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 12 [464/50000 (1%)]\tLoss: 0.342491\n",
            "Train Epoch: 12 [944/50000 (2%)]\tLoss: 0.191150\n",
            "Train Epoch: 12 [1424/50000 (3%)]\tLoss: 0.039821\n",
            "Train Epoch: 12 [1904/50000 (4%)]\tLoss: 0.311996\n",
            "Train Epoch: 12 [2384/50000 (5%)]\tLoss: 0.239754\n",
            "Train Epoch: 12 [2864/50000 (6%)]\tLoss: 0.271778\n",
            "Train Epoch: 12 [3344/50000 (7%)]\tLoss: 0.122741\n",
            "Train Epoch: 12 [3824/50000 (8%)]\tLoss: 0.117054\n",
            "Train Epoch: 12 [4304/50000 (9%)]\tLoss: 0.173857\n",
            "Train Epoch: 12 [4784/50000 (10%)]\tLoss: 0.407929\n",
            "Train Epoch: 12 [5264/50000 (11%)]\tLoss: 0.290204\n",
            "Train Epoch: 12 [5744/50000 (11%)]\tLoss: 0.206962\n",
            "Train Epoch: 12 [6224/50000 (12%)]\tLoss: 0.168398\n",
            "Train Epoch: 12 [6704/50000 (13%)]\tLoss: 0.129583\n",
            "Train Epoch: 12 [7184/50000 (14%)]\tLoss: 0.070963\n",
            "Train Epoch: 12 [7664/50000 (15%)]\tLoss: 0.138668\n",
            "Train Epoch: 12 [8144/50000 (16%)]\tLoss: 0.190589\n",
            "Train Epoch: 12 [8624/50000 (17%)]\tLoss: 0.152330\n",
            "Train Epoch: 12 [9104/50000 (18%)]\tLoss: 0.224773\n",
            "Train Epoch: 12 [9584/50000 (19%)]\tLoss: 0.262496\n",
            "Train Epoch: 12 [10064/50000 (20%)]\tLoss: 0.327903\n",
            "Train Epoch: 12 [10544/50000 (21%)]\tLoss: 0.534201\n",
            "Train Epoch: 12 [11024/50000 (22%)]\tLoss: 0.119548\n",
            "Train Epoch: 12 [11504/50000 (23%)]\tLoss: 0.876875\n",
            "Train Epoch: 12 [11984/50000 (24%)]\tLoss: 0.093494\n",
            "Train Epoch: 12 [12464/50000 (25%)]\tLoss: 0.431114\n",
            "Train Epoch: 12 [12944/50000 (26%)]\tLoss: 0.189561\n",
            "Train Epoch: 12 [13424/50000 (27%)]\tLoss: 0.461888\n",
            "Train Epoch: 12 [13904/50000 (28%)]\tLoss: 0.142237\n",
            "Train Epoch: 12 [14384/50000 (29%)]\tLoss: 0.378982\n",
            "Train Epoch: 12 [14864/50000 (30%)]\tLoss: 0.131600\n",
            "Train Epoch: 12 [15344/50000 (31%)]\tLoss: 0.086326\n",
            "Train Epoch: 12 [15824/50000 (32%)]\tLoss: 0.030559\n",
            "Train Epoch: 12 [16304/50000 (33%)]\tLoss: 0.126635\n",
            "Train Epoch: 12 [16784/50000 (34%)]\tLoss: 0.049387\n",
            "Train Epoch: 12 [17264/50000 (35%)]\tLoss: 0.405545\n",
            "Train Epoch: 12 [17744/50000 (35%)]\tLoss: 0.158824\n",
            "Train Epoch: 12 [18224/50000 (36%)]\tLoss: 0.231004\n",
            "Train Epoch: 12 [18704/50000 (37%)]\tLoss: 0.113530\n",
            "Train Epoch: 12 [19184/50000 (38%)]\tLoss: 0.303225\n",
            "Train Epoch: 12 [19664/50000 (39%)]\tLoss: 0.070976\n",
            "Train Epoch: 12 [20144/50000 (40%)]\tLoss: 0.269398\n",
            "Train Epoch: 12 [20624/50000 (41%)]\tLoss: 0.256298\n",
            "Train Epoch: 12 [21104/50000 (42%)]\tLoss: 0.247760\n",
            "Train Epoch: 12 [21584/50000 (43%)]\tLoss: 0.255585\n",
            "Train Epoch: 12 [22064/50000 (44%)]\tLoss: 0.461846\n",
            "Train Epoch: 12 [22544/50000 (45%)]\tLoss: 0.208210\n",
            "Train Epoch: 12 [23024/50000 (46%)]\tLoss: 0.493827\n",
            "Train Epoch: 12 [23504/50000 (47%)]\tLoss: 0.272759\n",
            "Train Epoch: 12 [23984/50000 (48%)]\tLoss: 0.150826\n",
            "Train Epoch: 12 [24464/50000 (49%)]\tLoss: 0.037083\n",
            "Train Epoch: 12 [24944/50000 (50%)]\tLoss: 0.226454\n",
            "Train Epoch: 12 [25424/50000 (51%)]\tLoss: 0.150803\n",
            "Train Epoch: 12 [25904/50000 (52%)]\tLoss: 0.131801\n",
            "Train Epoch: 12 [26384/50000 (53%)]\tLoss: 0.104577\n",
            "Train Epoch: 12 [26864/50000 (54%)]\tLoss: 0.245814\n",
            "Train Epoch: 12 [27344/50000 (55%)]\tLoss: 0.473967\n",
            "Train Epoch: 12 [27824/50000 (56%)]\tLoss: 0.069903\n",
            "Train Epoch: 12 [28304/50000 (57%)]\tLoss: 0.551141\n",
            "Train Epoch: 12 [28784/50000 (58%)]\tLoss: 0.141507\n",
            "Train Epoch: 12 [29264/50000 (59%)]\tLoss: 0.294275\n",
            "Train Epoch: 12 [29744/50000 (59%)]\tLoss: 0.210570\n",
            "Train Epoch: 12 [30224/50000 (60%)]\tLoss: 0.122646\n",
            "Train Epoch: 12 [30704/50000 (61%)]\tLoss: 0.186457\n",
            "Train Epoch: 12 [31184/50000 (62%)]\tLoss: 0.247214\n",
            "Train Epoch: 12 [31664/50000 (63%)]\tLoss: 0.088921\n",
            "Train Epoch: 12 [32144/50000 (64%)]\tLoss: 0.237105\n",
            "Train Epoch: 12 [32624/50000 (65%)]\tLoss: 0.023047\n",
            "Train Epoch: 12 [33104/50000 (66%)]\tLoss: 0.424453\n",
            "Train Epoch: 12 [33584/50000 (67%)]\tLoss: 0.185075\n",
            "Train Epoch: 12 [34064/50000 (68%)]\tLoss: 0.130719\n",
            "Train Epoch: 12 [34544/50000 (69%)]\tLoss: 0.305313\n",
            "Train Epoch: 12 [35024/50000 (70%)]\tLoss: 0.540532\n",
            "Train Epoch: 12 [35504/50000 (71%)]\tLoss: 0.458823\n",
            "Train Epoch: 12 [35984/50000 (72%)]\tLoss: 0.518482\n",
            "Train Epoch: 12 [36464/50000 (73%)]\tLoss: 0.315452\n",
            "Train Epoch: 12 [36944/50000 (74%)]\tLoss: 0.016686\n",
            "Train Epoch: 12 [37424/50000 (75%)]\tLoss: 0.909242\n",
            "Train Epoch: 12 [37904/50000 (76%)]\tLoss: 0.113394\n",
            "Train Epoch: 12 [38384/50000 (77%)]\tLoss: 0.057691\n",
            "Train Epoch: 12 [38864/50000 (78%)]\tLoss: 0.304032\n",
            "Train Epoch: 12 [39344/50000 (79%)]\tLoss: 0.078794\n",
            "Train Epoch: 12 [39824/50000 (80%)]\tLoss: 0.423514\n",
            "Train Epoch: 12 [40304/50000 (81%)]\tLoss: 0.811816\n",
            "Train Epoch: 12 [40784/50000 (82%)]\tLoss: 0.243621\n",
            "Train Epoch: 12 [41264/50000 (83%)]\tLoss: 0.156819\n",
            "Train Epoch: 12 [41744/50000 (83%)]\tLoss: 0.175150\n",
            "Train Epoch: 12 [42224/50000 (84%)]\tLoss: 0.154899\n",
            "Train Epoch: 12 [42704/50000 (85%)]\tLoss: 0.225455\n",
            "Train Epoch: 12 [43184/50000 (86%)]\tLoss: 0.101079\n",
            "Train Epoch: 12 [43664/50000 (87%)]\tLoss: 0.381359\n",
            "Train Epoch: 12 [44144/50000 (88%)]\tLoss: 0.128009\n",
            "Train Epoch: 12 [44624/50000 (89%)]\tLoss: 0.207884\n",
            "Train Epoch: 12 [45104/50000 (90%)]\tLoss: 0.199161\n",
            "Train Epoch: 12 [45584/50000 (91%)]\tLoss: 0.747708\n",
            "Train Epoch: 12 [46064/50000 (92%)]\tLoss: 0.385921\n",
            "Train Epoch: 12 [46544/50000 (93%)]\tLoss: 0.298321\n",
            "Train Epoch: 12 [47024/50000 (94%)]\tLoss: 0.440772\n",
            "Train Epoch: 12 [47504/50000 (95%)]\tLoss: 0.236402\n",
            "Train Epoch: 12 [47984/50000 (96%)]\tLoss: 0.659222\n",
            "Train Epoch: 12 [48464/50000 (97%)]\tLoss: 0.341004\n",
            "Train Epoch: 12 [48944/50000 (98%)]\tLoss: 0.480178\n",
            "Train Epoch: 12 [49424/50000 (99%)]\tLoss: 0.222837\n",
            "Train Epoch: 12 [49904/50000 (100%)]\tLoss: 0.764945\n",
            "---------------------------------------\n",
            "Training time for epoch 12: 20.81 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch12): Average loss: 0.8858, Accuracy: 7430/10000 (74%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 13 [464/50000 (1%)]\tLoss: 0.087293\n",
            "Train Epoch: 13 [944/50000 (2%)]\tLoss: 0.109839\n",
            "Train Epoch: 13 [1424/50000 (3%)]\tLoss: 0.158701\n",
            "Train Epoch: 13 [1904/50000 (4%)]\tLoss: 0.142602\n",
            "Train Epoch: 13 [2384/50000 (5%)]\tLoss: 0.095074\n",
            "Train Epoch: 13 [2864/50000 (6%)]\tLoss: 0.399680\n",
            "Train Epoch: 13 [3344/50000 (7%)]\tLoss: 0.166379\n",
            "Train Epoch: 13 [3824/50000 (8%)]\tLoss: 0.250692\n",
            "Train Epoch: 13 [4304/50000 (9%)]\tLoss: 0.289393\n",
            "Train Epoch: 13 [4784/50000 (10%)]\tLoss: 0.008353\n",
            "Train Epoch: 13 [5264/50000 (11%)]\tLoss: 0.095498\n",
            "Train Epoch: 13 [5744/50000 (11%)]\tLoss: 0.233236\n",
            "Train Epoch: 13 [6224/50000 (12%)]\tLoss: 0.051898\n",
            "Train Epoch: 13 [6704/50000 (13%)]\tLoss: 0.047563\n",
            "Train Epoch: 13 [7184/50000 (14%)]\tLoss: 0.471678\n",
            "Train Epoch: 13 [7664/50000 (15%)]\tLoss: 0.031319\n",
            "Train Epoch: 13 [8144/50000 (16%)]\tLoss: 0.135374\n",
            "Train Epoch: 13 [8624/50000 (17%)]\tLoss: 0.125132\n",
            "Train Epoch: 13 [9104/50000 (18%)]\tLoss: 0.182411\n",
            "Train Epoch: 13 [9584/50000 (19%)]\tLoss: 0.192981\n",
            "Train Epoch: 13 [10064/50000 (20%)]\tLoss: 0.036446\n",
            "Train Epoch: 13 [10544/50000 (21%)]\tLoss: 0.319039\n",
            "Train Epoch: 13 [11024/50000 (22%)]\tLoss: 0.155787\n",
            "Train Epoch: 13 [11504/50000 (23%)]\tLoss: 0.136501\n",
            "Train Epoch: 13 [11984/50000 (24%)]\tLoss: 0.042173\n",
            "Train Epoch: 13 [12464/50000 (25%)]\tLoss: 0.310012\n",
            "Train Epoch: 13 [12944/50000 (26%)]\tLoss: 0.259827\n",
            "Train Epoch: 13 [13424/50000 (27%)]\tLoss: 0.030464\n",
            "Train Epoch: 13 [13904/50000 (28%)]\tLoss: 0.125494\n",
            "Train Epoch: 13 [14384/50000 (29%)]\tLoss: 0.139264\n",
            "Train Epoch: 13 [14864/50000 (30%)]\tLoss: 0.071305\n",
            "Train Epoch: 13 [15344/50000 (31%)]\tLoss: 0.037801\n",
            "Train Epoch: 13 [15824/50000 (32%)]\tLoss: 0.184603\n",
            "Train Epoch: 13 [16304/50000 (33%)]\tLoss: 0.226111\n",
            "Train Epoch: 13 [16784/50000 (34%)]\tLoss: 0.123697\n",
            "Train Epoch: 13 [17264/50000 (35%)]\tLoss: 0.028389\n",
            "Train Epoch: 13 [17744/50000 (35%)]\tLoss: 0.440345\n",
            "Train Epoch: 13 [18224/50000 (36%)]\tLoss: 0.160363\n",
            "Train Epoch: 13 [18704/50000 (37%)]\tLoss: 0.269893\n",
            "Train Epoch: 13 [19184/50000 (38%)]\tLoss: 0.029647\n",
            "Train Epoch: 13 [19664/50000 (39%)]\tLoss: 0.042905\n",
            "Train Epoch: 13 [20144/50000 (40%)]\tLoss: 0.141092\n",
            "Train Epoch: 13 [20624/50000 (41%)]\tLoss: 0.113570\n",
            "Train Epoch: 13 [21104/50000 (42%)]\tLoss: 0.286551\n",
            "Train Epoch: 13 [21584/50000 (43%)]\tLoss: 0.394562\n",
            "Train Epoch: 13 [22064/50000 (44%)]\tLoss: 0.157790\n",
            "Train Epoch: 13 [22544/50000 (45%)]\tLoss: 0.288938\n",
            "Train Epoch: 13 [23024/50000 (46%)]\tLoss: 0.060494\n",
            "Train Epoch: 13 [23504/50000 (47%)]\tLoss: 0.468722\n",
            "Train Epoch: 13 [23984/50000 (48%)]\tLoss: 0.232170\n",
            "Train Epoch: 13 [24464/50000 (49%)]\tLoss: 0.123241\n",
            "Train Epoch: 13 [24944/50000 (50%)]\tLoss: 0.089386\n",
            "Train Epoch: 13 [25424/50000 (51%)]\tLoss: 0.348920\n",
            "Train Epoch: 13 [25904/50000 (52%)]\tLoss: 0.274447\n",
            "Train Epoch: 13 [26384/50000 (53%)]\tLoss: 0.217749\n",
            "Train Epoch: 13 [26864/50000 (54%)]\tLoss: 0.201507\n",
            "Train Epoch: 13 [27344/50000 (55%)]\tLoss: 0.097373\n",
            "Train Epoch: 13 [27824/50000 (56%)]\tLoss: 0.152365\n",
            "Train Epoch: 13 [28304/50000 (57%)]\tLoss: 0.107108\n",
            "Train Epoch: 13 [28784/50000 (58%)]\tLoss: 0.229828\n",
            "Train Epoch: 13 [29264/50000 (59%)]\tLoss: 0.088110\n",
            "Train Epoch: 13 [29744/50000 (59%)]\tLoss: 0.246206\n",
            "Train Epoch: 13 [30224/50000 (60%)]\tLoss: 0.041178\n",
            "Train Epoch: 13 [30704/50000 (61%)]\tLoss: 0.203196\n",
            "Train Epoch: 13 [31184/50000 (62%)]\tLoss: 0.201183\n",
            "Train Epoch: 13 [31664/50000 (63%)]\tLoss: 0.363099\n",
            "Train Epoch: 13 [32144/50000 (64%)]\tLoss: 0.149145\n",
            "Train Epoch: 13 [32624/50000 (65%)]\tLoss: 0.127505\n",
            "Train Epoch: 13 [33104/50000 (66%)]\tLoss: 0.236025\n",
            "Train Epoch: 13 [33584/50000 (67%)]\tLoss: 0.360496\n",
            "Train Epoch: 13 [34064/50000 (68%)]\tLoss: 0.145133\n",
            "Train Epoch: 13 [34544/50000 (69%)]\tLoss: 0.092971\n",
            "Train Epoch: 13 [35024/50000 (70%)]\tLoss: 0.090659\n",
            "Train Epoch: 13 [35504/50000 (71%)]\tLoss: 0.396715\n",
            "Train Epoch: 13 [35984/50000 (72%)]\tLoss: 0.049780\n",
            "Train Epoch: 13 [36464/50000 (73%)]\tLoss: 0.084073\n",
            "Train Epoch: 13 [36944/50000 (74%)]\tLoss: 0.173376\n",
            "Train Epoch: 13 [37424/50000 (75%)]\tLoss: 0.281362\n",
            "Train Epoch: 13 [37904/50000 (76%)]\tLoss: 0.164946\n",
            "Train Epoch: 13 [38384/50000 (77%)]\tLoss: 0.193416\n",
            "Train Epoch: 13 [38864/50000 (78%)]\tLoss: 0.328738\n",
            "Train Epoch: 13 [39344/50000 (79%)]\tLoss: 0.247153\n",
            "Train Epoch: 13 [39824/50000 (80%)]\tLoss: 0.019137\n",
            "Train Epoch: 13 [40304/50000 (81%)]\tLoss: 0.185664\n",
            "Train Epoch: 13 [40784/50000 (82%)]\tLoss: 0.042442\n",
            "Train Epoch: 13 [41264/50000 (83%)]\tLoss: 0.059430\n",
            "Train Epoch: 13 [41744/50000 (83%)]\tLoss: 0.089503\n",
            "Train Epoch: 13 [42224/50000 (84%)]\tLoss: 0.223188\n",
            "Train Epoch: 13 [42704/50000 (85%)]\tLoss: 0.363936\n",
            "Train Epoch: 13 [43184/50000 (86%)]\tLoss: 0.389147\n",
            "Train Epoch: 13 [43664/50000 (87%)]\tLoss: 0.114369\n",
            "Train Epoch: 13 [44144/50000 (88%)]\tLoss: 0.371614\n",
            "Train Epoch: 13 [44624/50000 (89%)]\tLoss: 0.163976\n",
            "Train Epoch: 13 [45104/50000 (90%)]\tLoss: 0.467246\n",
            "Train Epoch: 13 [45584/50000 (91%)]\tLoss: 0.050396\n",
            "Train Epoch: 13 [46064/50000 (92%)]\tLoss: 0.127668\n",
            "Train Epoch: 13 [46544/50000 (93%)]\tLoss: 0.019878\n",
            "Train Epoch: 13 [47024/50000 (94%)]\tLoss: 0.326712\n",
            "Train Epoch: 13 [47504/50000 (95%)]\tLoss: 0.150378\n",
            "Train Epoch: 13 [47984/50000 (96%)]\tLoss: 0.131326\n",
            "Train Epoch: 13 [48464/50000 (97%)]\tLoss: 0.222400\n",
            "Train Epoch: 13 [48944/50000 (98%)]\tLoss: 0.029743\n",
            "Train Epoch: 13 [49424/50000 (99%)]\tLoss: 0.111736\n",
            "Train Epoch: 13 [49904/50000 (100%)]\tLoss: 0.598232\n",
            "---------------------------------------\n",
            "Training time for epoch 13: 20.53 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch13): Average loss: 0.9746, Accuracy: 7450/10000 (74%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 14 [464/50000 (1%)]\tLoss: 0.136390\n",
            "Train Epoch: 14 [944/50000 (2%)]\tLoss: 0.065961\n",
            "Train Epoch: 14 [1424/50000 (3%)]\tLoss: 0.189426\n",
            "Train Epoch: 14 [1904/50000 (4%)]\tLoss: 0.066917\n",
            "Train Epoch: 14 [2384/50000 (5%)]\tLoss: 0.067328\n",
            "Train Epoch: 14 [2864/50000 (6%)]\tLoss: 0.255575\n",
            "Train Epoch: 14 [3344/50000 (7%)]\tLoss: 0.123146\n",
            "Train Epoch: 14 [3824/50000 (8%)]\tLoss: 0.075225\n",
            "Train Epoch: 14 [4304/50000 (9%)]\tLoss: 0.101689\n",
            "Train Epoch: 14 [4784/50000 (10%)]\tLoss: 0.379496\n",
            "Train Epoch: 14 [5264/50000 (11%)]\tLoss: 0.073512\n",
            "Train Epoch: 14 [5744/50000 (11%)]\tLoss: 0.094478\n",
            "Train Epoch: 14 [6224/50000 (12%)]\tLoss: 0.094330\n",
            "Train Epoch: 14 [6704/50000 (13%)]\tLoss: 0.149030\n",
            "Train Epoch: 14 [7184/50000 (14%)]\tLoss: 0.146624\n",
            "Train Epoch: 14 [7664/50000 (15%)]\tLoss: 0.291786\n",
            "Train Epoch: 14 [8144/50000 (16%)]\tLoss: 0.044504\n",
            "Train Epoch: 14 [8624/50000 (17%)]\tLoss: 0.109452\n",
            "Train Epoch: 14 [9104/50000 (18%)]\tLoss: 0.398810\n",
            "Train Epoch: 14 [9584/50000 (19%)]\tLoss: 0.164551\n",
            "Train Epoch: 14 [10064/50000 (20%)]\tLoss: 0.187715\n",
            "Train Epoch: 14 [10544/50000 (21%)]\tLoss: 0.078458\n",
            "Train Epoch: 14 [11024/50000 (22%)]\tLoss: 0.040426\n",
            "Train Epoch: 14 [11504/50000 (23%)]\tLoss: 0.034872\n",
            "Train Epoch: 14 [11984/50000 (24%)]\tLoss: 0.039112\n",
            "Train Epoch: 14 [12464/50000 (25%)]\tLoss: 0.585031\n",
            "Train Epoch: 14 [12944/50000 (26%)]\tLoss: 0.045249\n",
            "Train Epoch: 14 [13424/50000 (27%)]\tLoss: 0.082803\n",
            "Train Epoch: 14 [13904/50000 (28%)]\tLoss: 0.160427\n",
            "Train Epoch: 14 [14384/50000 (29%)]\tLoss: 0.021469\n",
            "Train Epoch: 14 [14864/50000 (30%)]\tLoss: 0.209779\n",
            "Train Epoch: 14 [15344/50000 (31%)]\tLoss: 0.111497\n",
            "Train Epoch: 14 [15824/50000 (32%)]\tLoss: 0.324313\n",
            "Train Epoch: 14 [16304/50000 (33%)]\tLoss: 0.076807\n",
            "Train Epoch: 14 [16784/50000 (34%)]\tLoss: 0.135765\n",
            "Train Epoch: 14 [17264/50000 (35%)]\tLoss: 0.081763\n",
            "Train Epoch: 14 [17744/50000 (35%)]\tLoss: 0.312254\n",
            "Train Epoch: 14 [18224/50000 (36%)]\tLoss: 0.242113\n",
            "Train Epoch: 14 [18704/50000 (37%)]\tLoss: 0.179826\n",
            "Train Epoch: 14 [19184/50000 (38%)]\tLoss: 0.053720\n",
            "Train Epoch: 14 [19664/50000 (39%)]\tLoss: 0.150418\n",
            "Train Epoch: 14 [20144/50000 (40%)]\tLoss: 0.096374\n",
            "Train Epoch: 14 [20624/50000 (41%)]\tLoss: 0.193816\n",
            "Train Epoch: 14 [21104/50000 (42%)]\tLoss: 0.039008\n",
            "Train Epoch: 14 [21584/50000 (43%)]\tLoss: 0.152706\n",
            "Train Epoch: 14 [22064/50000 (44%)]\tLoss: 0.082070\n",
            "Train Epoch: 14 [22544/50000 (45%)]\tLoss: 0.111540\n",
            "Train Epoch: 14 [23024/50000 (46%)]\tLoss: 0.199992\n",
            "Train Epoch: 14 [23504/50000 (47%)]\tLoss: 0.186645\n",
            "Train Epoch: 14 [23984/50000 (48%)]\tLoss: 0.176976\n",
            "Train Epoch: 14 [24464/50000 (49%)]\tLoss: 0.072002\n",
            "Train Epoch: 14 [24944/50000 (50%)]\tLoss: 0.168348\n",
            "Train Epoch: 14 [25424/50000 (51%)]\tLoss: 0.152587\n",
            "Train Epoch: 14 [25904/50000 (52%)]\tLoss: 0.275662\n",
            "Train Epoch: 14 [26384/50000 (53%)]\tLoss: 0.337960\n",
            "Train Epoch: 14 [26864/50000 (54%)]\tLoss: 0.066382\n",
            "Train Epoch: 14 [27344/50000 (55%)]\tLoss: 0.105508\n",
            "Train Epoch: 14 [27824/50000 (56%)]\tLoss: 0.108528\n",
            "Train Epoch: 14 [28304/50000 (57%)]\tLoss: 0.014468\n",
            "Train Epoch: 14 [28784/50000 (58%)]\tLoss: 0.021851\n",
            "Train Epoch: 14 [29264/50000 (59%)]\tLoss: 0.075550\n",
            "Train Epoch: 14 [29744/50000 (59%)]\tLoss: 0.046820\n",
            "Train Epoch: 14 [30224/50000 (60%)]\tLoss: 0.037293\n",
            "Train Epoch: 14 [30704/50000 (61%)]\tLoss: 0.214895\n",
            "Train Epoch: 14 [31184/50000 (62%)]\tLoss: 0.144563\n",
            "Train Epoch: 14 [31664/50000 (63%)]\tLoss: 0.126178\n",
            "Train Epoch: 14 [32144/50000 (64%)]\tLoss: 0.104151\n",
            "Train Epoch: 14 [32624/50000 (65%)]\tLoss: 0.168206\n",
            "Train Epoch: 14 [33104/50000 (66%)]\tLoss: 0.168932\n",
            "Train Epoch: 14 [33584/50000 (67%)]\tLoss: 0.299439\n",
            "Train Epoch: 14 [34064/50000 (68%)]\tLoss: 0.095189\n",
            "Train Epoch: 14 [34544/50000 (69%)]\tLoss: 0.126425\n",
            "Train Epoch: 14 [35024/50000 (70%)]\tLoss: 0.107069\n",
            "Train Epoch: 14 [35504/50000 (71%)]\tLoss: 0.110073\n",
            "Train Epoch: 14 [35984/50000 (72%)]\tLoss: 0.173083\n",
            "Train Epoch: 14 [36464/50000 (73%)]\tLoss: 0.097384\n",
            "Train Epoch: 14 [36944/50000 (74%)]\tLoss: 0.030731\n",
            "Train Epoch: 14 [37424/50000 (75%)]\tLoss: 0.107384\n",
            "Train Epoch: 14 [37904/50000 (76%)]\tLoss: 0.219081\n",
            "Train Epoch: 14 [38384/50000 (77%)]\tLoss: 0.094133\n",
            "Train Epoch: 14 [38864/50000 (78%)]\tLoss: 0.042189\n",
            "Train Epoch: 14 [39344/50000 (79%)]\tLoss: 0.167312\n",
            "Train Epoch: 14 [39824/50000 (80%)]\tLoss: 0.044510\n",
            "Train Epoch: 14 [40304/50000 (81%)]\tLoss: 0.055540\n",
            "Train Epoch: 14 [40784/50000 (82%)]\tLoss: 0.134408\n",
            "Train Epoch: 14 [41264/50000 (83%)]\tLoss: 0.054092\n",
            "Train Epoch: 14 [41744/50000 (83%)]\tLoss: 0.185526\n",
            "Train Epoch: 14 [42224/50000 (84%)]\tLoss: 0.264236\n",
            "Train Epoch: 14 [42704/50000 (85%)]\tLoss: 0.149268\n",
            "Train Epoch: 14 [43184/50000 (86%)]\tLoss: 0.554771\n",
            "Train Epoch: 14 [43664/50000 (87%)]\tLoss: 0.091687\n",
            "Train Epoch: 14 [44144/50000 (88%)]\tLoss: 0.168728\n",
            "Train Epoch: 14 [44624/50000 (89%)]\tLoss: 0.075516\n",
            "Train Epoch: 14 [45104/50000 (90%)]\tLoss: 0.259727\n",
            "Train Epoch: 14 [45584/50000 (91%)]\tLoss: 0.048769\n",
            "Train Epoch: 14 [46064/50000 (92%)]\tLoss: 0.080836\n",
            "Train Epoch: 14 [46544/50000 (93%)]\tLoss: 0.149452\n",
            "Train Epoch: 14 [47024/50000 (94%)]\tLoss: 0.133030\n",
            "Train Epoch: 14 [47504/50000 (95%)]\tLoss: 0.119080\n",
            "Train Epoch: 14 [47984/50000 (96%)]\tLoss: 0.399266\n",
            "Train Epoch: 14 [48464/50000 (97%)]\tLoss: 0.319121\n",
            "Train Epoch: 14 [48944/50000 (98%)]\tLoss: 0.138169\n",
            "Train Epoch: 14 [49424/50000 (99%)]\tLoss: 0.356431\n",
            "Train Epoch: 14 [49904/50000 (100%)]\tLoss: 0.054491\n",
            "---------------------------------------\n",
            "Training time for epoch 14: 19.67 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch14): Average loss: 0.9718, Accuracy: 7495/10000 (75%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "Train Epoch: 15 [464/50000 (1%)]\tLoss: 0.084566\n",
            "Train Epoch: 15 [944/50000 (2%)]\tLoss: 0.010978\n",
            "Train Epoch: 15 [1424/50000 (3%)]\tLoss: 0.242404\n",
            "Train Epoch: 15 [1904/50000 (4%)]\tLoss: 0.118116\n",
            "Train Epoch: 15 [2384/50000 (5%)]\tLoss: 0.166748\n",
            "Train Epoch: 15 [2864/50000 (6%)]\tLoss: 0.153943\n",
            "Train Epoch: 15 [3344/50000 (7%)]\tLoss: 0.045997\n",
            "Train Epoch: 15 [3824/50000 (8%)]\tLoss: 0.036329\n",
            "Train Epoch: 15 [4304/50000 (9%)]\tLoss: 0.020350\n",
            "Train Epoch: 15 [4784/50000 (10%)]\tLoss: 0.174957\n",
            "Train Epoch: 15 [5264/50000 (11%)]\tLoss: 0.098452\n",
            "Train Epoch: 15 [5744/50000 (11%)]\tLoss: 0.109151\n",
            "Train Epoch: 15 [6224/50000 (12%)]\tLoss: 0.117369\n",
            "Train Epoch: 15 [6704/50000 (13%)]\tLoss: 0.052141\n",
            "Train Epoch: 15 [7184/50000 (14%)]\tLoss: 0.113246\n",
            "Train Epoch: 15 [7664/50000 (15%)]\tLoss: 0.106047\n",
            "Train Epoch: 15 [8144/50000 (16%)]\tLoss: 0.042552\n",
            "Train Epoch: 15 [8624/50000 (17%)]\tLoss: 0.213204\n",
            "Train Epoch: 15 [9104/50000 (18%)]\tLoss: 0.151880\n",
            "Train Epoch: 15 [9584/50000 (19%)]\tLoss: 0.061241\n",
            "Train Epoch: 15 [10064/50000 (20%)]\tLoss: 0.060570\n",
            "Train Epoch: 15 [10544/50000 (21%)]\tLoss: 0.135866\n",
            "Train Epoch: 15 [11024/50000 (22%)]\tLoss: 0.397259\n",
            "Train Epoch: 15 [11504/50000 (23%)]\tLoss: 0.041126\n",
            "Train Epoch: 15 [11984/50000 (24%)]\tLoss: 0.073596\n",
            "Train Epoch: 15 [12464/50000 (25%)]\tLoss: 0.061835\n",
            "Train Epoch: 15 [12944/50000 (26%)]\tLoss: 0.068682\n",
            "Train Epoch: 15 [13424/50000 (27%)]\tLoss: 0.103967\n",
            "Train Epoch: 15 [13904/50000 (28%)]\tLoss: 0.094660\n",
            "Train Epoch: 15 [14384/50000 (29%)]\tLoss: 0.177600\n",
            "Train Epoch: 15 [14864/50000 (30%)]\tLoss: 0.058556\n",
            "Train Epoch: 15 [15344/50000 (31%)]\tLoss: 0.050061\n",
            "Train Epoch: 15 [15824/50000 (32%)]\tLoss: 0.078633\n",
            "Train Epoch: 15 [16304/50000 (33%)]\tLoss: 0.007287\n",
            "Train Epoch: 15 [16784/50000 (34%)]\tLoss: 0.264544\n",
            "Train Epoch: 15 [17264/50000 (35%)]\tLoss: 0.354257\n",
            "Train Epoch: 15 [17744/50000 (35%)]\tLoss: 0.025837\n",
            "Train Epoch: 15 [18224/50000 (36%)]\tLoss: 0.150170\n",
            "Train Epoch: 15 [18704/50000 (37%)]\tLoss: 0.071945\n",
            "Train Epoch: 15 [19184/50000 (38%)]\tLoss: 0.163707\n",
            "Train Epoch: 15 [19664/50000 (39%)]\tLoss: 0.116627\n",
            "Train Epoch: 15 [20144/50000 (40%)]\tLoss: 0.154084\n",
            "Train Epoch: 15 [20624/50000 (41%)]\tLoss: 0.025530\n",
            "Train Epoch: 15 [21104/50000 (42%)]\tLoss: 0.022658\n",
            "Train Epoch: 15 [21584/50000 (43%)]\tLoss: 0.035483\n",
            "Train Epoch: 15 [22064/50000 (44%)]\tLoss: 0.057289\n",
            "Train Epoch: 15 [22544/50000 (45%)]\tLoss: 0.068404\n",
            "Train Epoch: 15 [23024/50000 (46%)]\tLoss: 0.186799\n",
            "Train Epoch: 15 [23504/50000 (47%)]\tLoss: 0.016215\n",
            "Train Epoch: 15 [23984/50000 (48%)]\tLoss: 0.120951\n",
            "Train Epoch: 15 [24464/50000 (49%)]\tLoss: 0.052948\n",
            "Train Epoch: 15 [24944/50000 (50%)]\tLoss: 0.066052\n",
            "Train Epoch: 15 [25424/50000 (51%)]\tLoss: 0.201362\n",
            "Train Epoch: 15 [25904/50000 (52%)]\tLoss: 0.084973\n",
            "Train Epoch: 15 [26384/50000 (53%)]\tLoss: 0.138325\n",
            "Train Epoch: 15 [26864/50000 (54%)]\tLoss: 0.176993\n",
            "Train Epoch: 15 [27344/50000 (55%)]\tLoss: 0.131469\n",
            "Train Epoch: 15 [27824/50000 (56%)]\tLoss: 0.061959\n",
            "Train Epoch: 15 [28304/50000 (57%)]\tLoss: 0.119638\n",
            "Train Epoch: 15 [28784/50000 (58%)]\tLoss: 0.065507\n",
            "Train Epoch: 15 [29264/50000 (59%)]\tLoss: 0.056405\n",
            "Train Epoch: 15 [29744/50000 (59%)]\tLoss: 0.055141\n",
            "Train Epoch: 15 [30224/50000 (60%)]\tLoss: 0.061806\n",
            "Train Epoch: 15 [30704/50000 (61%)]\tLoss: 0.258940\n",
            "Train Epoch: 15 [31184/50000 (62%)]\tLoss: 0.074468\n",
            "Train Epoch: 15 [31664/50000 (63%)]\tLoss: 0.062608\n",
            "Train Epoch: 15 [32144/50000 (64%)]\tLoss: 0.243813\n",
            "Train Epoch: 15 [32624/50000 (65%)]\tLoss: 0.061178\n",
            "Train Epoch: 15 [33104/50000 (66%)]\tLoss: 0.159421\n",
            "Train Epoch: 15 [33584/50000 (67%)]\tLoss: 0.270090\n",
            "Train Epoch: 15 [34064/50000 (68%)]\tLoss: 0.088915\n",
            "Train Epoch: 15 [34544/50000 (69%)]\tLoss: 0.063617\n",
            "Train Epoch: 15 [35024/50000 (70%)]\tLoss: 0.007333\n",
            "Train Epoch: 15 [35504/50000 (71%)]\tLoss: 0.134211\n",
            "Train Epoch: 15 [35984/50000 (72%)]\tLoss: 0.137704\n",
            "Train Epoch: 15 [36464/50000 (73%)]\tLoss: 0.089978\n",
            "Train Epoch: 15 [36944/50000 (74%)]\tLoss: 0.127351\n",
            "Train Epoch: 15 [37424/50000 (75%)]\tLoss: 0.092400\n",
            "Train Epoch: 15 [37904/50000 (76%)]\tLoss: 0.402037\n",
            "Train Epoch: 15 [38384/50000 (77%)]\tLoss: 0.169441\n",
            "Train Epoch: 15 [38864/50000 (78%)]\tLoss: 0.185828\n",
            "Train Epoch: 15 [39344/50000 (79%)]\tLoss: 0.143351\n",
            "Train Epoch: 15 [39824/50000 (80%)]\tLoss: 0.010362\n",
            "Train Epoch: 15 [40304/50000 (81%)]\tLoss: 0.128370\n",
            "Train Epoch: 15 [40784/50000 (82%)]\tLoss: 0.128694\n",
            "Train Epoch: 15 [41264/50000 (83%)]\tLoss: 0.180554\n",
            "Train Epoch: 15 [41744/50000 (83%)]\tLoss: 0.279887\n",
            "Train Epoch: 15 [42224/50000 (84%)]\tLoss: 0.278220\n",
            "Train Epoch: 15 [42704/50000 (85%)]\tLoss: 0.058625\n",
            "Train Epoch: 15 [43184/50000 (86%)]\tLoss: 0.247632\n",
            "Train Epoch: 15 [43664/50000 (87%)]\tLoss: 0.192475\n",
            "Train Epoch: 15 [44144/50000 (88%)]\tLoss: 0.232240\n",
            "Train Epoch: 15 [44624/50000 (89%)]\tLoss: 0.108592\n",
            "Train Epoch: 15 [45104/50000 (90%)]\tLoss: 0.112952\n",
            "Train Epoch: 15 [45584/50000 (91%)]\tLoss: 0.256879\n",
            "Train Epoch: 15 [46064/50000 (92%)]\tLoss: 0.072042\n",
            "Train Epoch: 15 [46544/50000 (93%)]\tLoss: 0.255785\n",
            "Train Epoch: 15 [47024/50000 (94%)]\tLoss: 0.019750\n",
            "Train Epoch: 15 [47504/50000 (95%)]\tLoss: 0.022589\n",
            "Train Epoch: 15 [47984/50000 (96%)]\tLoss: 0.048872\n",
            "Train Epoch: 15 [48464/50000 (97%)]\tLoss: 0.056298\n",
            "Train Epoch: 15 [48944/50000 (98%)]\tLoss: 0.040813\n",
            "Train Epoch: 15 [49424/50000 (99%)]\tLoss: 0.053065\n",
            "Train Epoch: 15 [49904/50000 (100%)]\tLoss: 0.077174\n",
            "---------------------------------------\n",
            "Training time for epoch 15: 19.85 seconds\n",
            "---------------------------------------\n",
            "-------------------------------------------------------\n",
            "\n",
            "Test set (epoch15): Average loss: 1.0250, Accuracy: 7521/10000 (75%)\n",
            "\n",
            "-------------------------------------------------------\n",
            "============================================\n",
            "Total training time for 15 epochs (StandardConvNet): 305.50 seconds\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of Accuracies : ( Normal CNN)"
      ],
      "metadata": {
        "id": "1Q9js24p9oo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_ACC"
      ],
      "metadata": {
        "id": "d6yToww5LJnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b6967b-da76-42d0-d0d8-3a42bec42e2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[63.08,\n",
              " 67.19,\n",
              " 69.2,\n",
              " 72.07,\n",
              " 73.09,\n",
              " 72.55,\n",
              " 73.89,\n",
              " 74.57,\n",
              " 73.45,\n",
              " 73.61,\n",
              " 75.42,\n",
              " 74.3,\n",
              " 74.5,\n",
              " 74.95,\n",
              " 75.21]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plotting\n",
        "plt.plot(range(1, 16), CNN_ACC , color='blue', marker = '*' , label='Normal Convolution Acc')\n",
        "plt.plot(range(1, 16), DCNN_ACC, color ='red' , marker = '*' , label='Deformable Convolution Acc')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Values')\n",
        "plt.title ('Plot of Accuracies')\n",
        "plt.legend()  # Display legend based on labels\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rGYuKdvdvgaL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "0e6c84ae-e081-4158-dfa2-7083d3b22f7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total execution time for each of the scenarios is printed in the last line of their respective code blocks. As evident and observed, it is true that the Deformable Convolution provides us with more flexibility, but achieving this flexibility comes at the cost of significantly increased computation time, often several times more. (However, it is essential to consider that we developed the code from scratch here, and using pre-built packages might offer a more optimized solution, potentially requiring less time.)"
      ],
      "metadata": {
        "id": "nkW7UAKx8YAA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HvByXjGOT2zi"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}